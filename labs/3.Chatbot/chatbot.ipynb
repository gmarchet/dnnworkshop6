{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for NLP - Creating a chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Library Imports\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve training data\n",
    "with open('train_qa.txt', 'rb') as f:\n",
    "    train_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve test data\n",
    "with open('test_qa.txt', 'rb') as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of training instances\n",
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of test instances\n",
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Sandra',\n",
       "  'went',\n",
       "  'back',\n",
       "  'to',\n",
       "  'the',\n",
       "  'hallway',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'office',\n",
       "  '.'],\n",
       " ['Is', 'Sandra', 'in', 'the', 'office', '?'],\n",
       " 'yes')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example of one of the instances\n",
    "train_data[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sandra went back to the hallway . Sandra moved to the office .'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[10][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Sandra in the office ?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[10][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yes'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[10][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we need to create a vocabulary with our data\n",
    "#For this we will use the training data only to - On the video it uses both\n",
    "#train and test \n",
    "#Might have to use training and test later, as the dataset has very\n",
    "#few words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we will build a set of all the words in the dataset:\n",
    "vocab = set()\n",
    "for story, question, answer in train_data:\n",
    "    vocab = vocab.union(set(story)) #Set returns unique words in the sentence\n",
    "                                    #Union returns the unique common elements from a two sets\n",
    "    vocab = vocab.union(set(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add('no')\n",
    "vocab.add('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate len and add 1 for Keras placeholder - Placeholders are used to feed in the data to the network. \n",
    "#They need a data type, and have optional shape arguements.\n",
    "#They will be empty at first, and then the data will get fed into the placeholder\n",
    "vocab_len = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we are going to calculate the longest story and the longest question\n",
    "#We need this for the Keras pad sequences. \n",
    "#Keras training layers expect all of the input to have the same length, so \n",
    "#we need to pad \n",
    "all_data = test_data + train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_story_lens = [len(data[0]) for data in all_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_story_len = (max(all_story_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_question_len = max([len(data[1]) for data in all_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will go through a manual process of how to vectorize the data, and then we will create a function that does this automatically for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an instance of the tokenizer object:\n",
    "tokenizer = Tokenizer(filters = [])\n",
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sandra': 1,\n",
       " 'discarded': 2,\n",
       " 'hallway': 3,\n",
       " 'went': 4,\n",
       " 'office': 5,\n",
       " 'milk': 6,\n",
       " 'back': 7,\n",
       " 'left': 8,\n",
       " 'got': 9,\n",
       " 'travelled': 10,\n",
       " 'there': 11,\n",
       " 'yes': 12,\n",
       " 'dropped': 13,\n",
       " 'moved': 14,\n",
       " 'picked': 15,\n",
       " 'the': 16,\n",
       " 'to': 17,\n",
       " '.': 18,\n",
       " 'journeyed': 19,\n",
       " 'up': 20,\n",
       " 'john': 21,\n",
       " 'is': 22,\n",
       " '?': 23,\n",
       " 'grabbed': 24,\n",
       " 'in': 25,\n",
       " 'garden': 26,\n",
       " 'bathroom': 27,\n",
       " 'kitchen': 28,\n",
       " 'put': 29,\n",
       " 'bedroom': 30,\n",
       " 'mary': 31,\n",
       " 'football': 32,\n",
       " 'no': 33,\n",
       " 'daniel': 34,\n",
       " 'down': 35,\n",
       " 'took': 36,\n",
       " 'apple': 37}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dictionary that maps every word in our vocab to an index\n",
    "# It has been automatically lowercased\n",
    "#This tokenizer can give different indexes for different words depending on when we run it\n",
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize the stories, questions and answers:\n",
    "train_story_text = []\n",
    "train_question_text = []\n",
    "train_answers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating each of the elements\n",
    "for story,question,answer in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_question_text.append(question) \n",
    "    train_answers.append(answer)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coverting the text into the indexes \n",
    "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function for vectorizing the stories, questions and answers:\n",
    "def vectorize_stories(data,word_index = tokenizer.word_index, max_story_len = max_story_len, max_question_len = max_question_len):\n",
    "    #vectorized stories:\n",
    "    X = []\n",
    "    #vectorized questions:\n",
    "    Xq = []\n",
    "    #vectorized answers:\n",
    "    Y = []\n",
    "    \n",
    "    for story, question, answer in data:\n",
    "        #Getting indexes for each word in the story\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        #Getting indexes for each word in the story\n",
    "        xq = [word_index[word.lower()] for word in question]\n",
    "        #For the answers\n",
    "        y = np.zeros(len(word_index) + 1) #Index 0 Reserved when padding the sequences\n",
    "        y[word_index[answer]] = 1\n",
    "        \n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "        \n",
    "    #Now we have to pad these sequences:\n",
    "    return(pad_sequences(X,maxlen=max_story_len), pad_sequences(Xq, maxlen=max_question_len), np.array(Y))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, questions_train, answers_train = vectorize_stories(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test, questions_test, answers_test = vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0, 31, 14, 17, 16, 27, 18,  1, 19, 17,\n",
       "       16, 30, 18], dtype=int32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mary',\n",
       " 'moved',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bathroom',\n",
       " '.',\n",
       " 'Sandra',\n",
       " 'journeyed',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bedroom',\n",
       " '.']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_story_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[31, 14, 17, 16, 27, 18, 1, 19, 17, 16, 30, 18]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_story_seq[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Input, Activation, Dense, Permute, Dropout, add, dot, concatenate, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to create the placeholders \n",
    "#The Input function is used to create a keras tensor\n",
    "#PLACEHOLDER shape = (max_story_len,batch_size)\n",
    "#These are our placeholder for the inputs, ready to recieve batches of the stories and the questions\n",
    "input_sequence = Input((max_story_len,)) #As we dont know batch size yet\n",
    "question = Input((max_question_len,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create input encoder M:\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_len,output_dim = 64)) #From paper\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "\n",
    "#Outputs: (Samples, story_maxlen,embedding_dim) -- Gives a list of the lenght of the samples where each item has the\n",
    "#lenght of the max story lenght and every word is embedded in the embbeding dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create input encoder C:\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_len,output_dim = max_question_len)) #From paper\n",
    "input_encoder_c.add(Dropout(0.3))\n",
    "\n",
    "#Outputs: (samples, story_maxlen, max_question_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create question encoder:\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_len,output_dim = 64,input_length=max_question_len)) #From paper\n",
    "question_encoder.add(Dropout(0.3))\n",
    "\n",
    "#Outputs: (samples, question_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now lets encode the sequences, passing the placeholders into our encoders:\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use dot product to compute similarity between input encoded m and question \n",
    "#Like in the paper:\n",
    "match = dot([input_encoded_m,question_encoded], axes = (2,2))\n",
    "match = Activation('softmax')(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the response we want to add this match with the ouput of input_encoded_c\n",
    "response = add([match,input_encoded_c])\n",
    "response = Permute((2,1))(response) #Permute Layer: permutes dimensions of input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Once we have the response we can concatenate it with the question encoded:\n",
    "answer = concatenate([response, question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate/Identity:0' shape=(None, 6, 220) dtype=float32>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the answer tensor with a RNN (LSTM)\n",
    "answer = LSTM(32)(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regularization with dropout:\n",
    "answer = Dropout(0.5)(answer)\n",
    "#Output layer:\n",
    "answer = Dense(vocab_len)(answer) #Output shape: (Samples, Vocab_size) #Yes or no and all 0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we need to output a probability distribution for the vocab, using softmax:\n",
    "answer = Activation('softmax')(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we build the final model:\n",
    "model = Model([input_sequence,question], answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "#Categorical instead of binary cross entropy as because of the way we are training\n",
    "#we could actually see any of the words from the vocab as output\n",
    "#however, we should only see yes or no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 156)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         multiple             2432        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 6, 64)        2432        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 156, 6)       0           sequential[1][0]                 \n",
      "                                                                 sequential_2[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 156, 6)       0           dot[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       multiple             228         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 156, 6)       0           activation[0][0]                 \n",
      "                                                                 sequential_1[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, 6, 156)       0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 220)       0           permute[0][0]                    \n",
      "                                                                 sequential_2[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 32)           32384       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32)           0           lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 38)           1254        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 38)           0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "10000/10000 [==============================] - 6s 621us/sample - loss: 0.9415 - accuracy: 0.5065 - val_loss: 0.6950 - val_accuracy: 0.4950\n",
      "Epoch 2/1000\n",
      "10000/10000 [==============================] - 3s 287us/sample - loss: 0.7109 - accuracy: 0.5076 - val_loss: 0.6937 - val_accuracy: 0.4970\n",
      "Epoch 3/1000\n",
      "10000/10000 [==============================] - 3s 271us/sample - loss: 0.6970 - accuracy: 0.5023 - val_loss: 0.6933 - val_accuracy: 0.5030\n",
      "Epoch 4/1000\n",
      "10000/10000 [==============================] - 3s 269us/sample - loss: 0.6958 - accuracy: 0.5016 - val_loss: 0.6958 - val_accuracy: 0.4970\n",
      "Epoch 5/1000\n",
      "10000/10000 [==============================] - 3s 292us/sample - loss: 0.6948 - accuracy: 0.5001 - val_loss: 0.6935 - val_accuracy: 0.4970\n",
      "Epoch 6/1000\n",
      "10000/10000 [==============================] - 3s 320us/sample - loss: 0.6947 - accuracy: 0.4977 - val_loss: 0.6956 - val_accuracy: 0.4970\n",
      "Epoch 7/1000\n",
      "10000/10000 [==============================] - 3s 291us/sample - loss: 0.6944 - accuracy: 0.5026 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
      "Epoch 8/1000\n",
      "10000/10000 [==============================] - 3s 293us/sample - loss: 0.6946 - accuracy: 0.5014 - val_loss: 0.6935 - val_accuracy: 0.4970\n",
      "Epoch 9/1000\n",
      "10000/10000 [==============================] - 3s 298us/sample - loss: 0.6946 - accuracy: 0.4959 - val_loss: 0.6937 - val_accuracy: 0.4820\n",
      "Epoch 10/1000\n",
      "10000/10000 [==============================] - 3s 295us/sample - loss: 0.6945 - accuracy: 0.4951 - val_loss: 0.6949 - val_accuracy: 0.5030\n",
      "Epoch 11/1000\n",
      "10000/10000 [==============================] - 4s 447us/sample - loss: 0.6944 - accuracy: 0.5026 - val_loss: 0.6964 - val_accuracy: 0.4760\n",
      "Epoch 12/1000\n",
      "10000/10000 [==============================] - 3s 300us/sample - loss: 0.6933 - accuracy: 0.5126 - val_loss: 0.6935 - val_accuracy: 0.4980\n",
      "Epoch 13/1000\n",
      "10000/10000 [==============================] - 3s 299us/sample - loss: 0.6889 - accuracy: 0.5244 - val_loss: 0.6829 - val_accuracy: 0.5270\n",
      "Epoch 14/1000\n",
      "10000/10000 [==============================] - 3s 321us/sample - loss: 0.6561 - accuracy: 0.5820 - val_loss: 0.6216 - val_accuracy: 0.6340\n",
      "Epoch 15/1000\n",
      "10000/10000 [==============================] - 3s 324us/sample - loss: 0.5918 - accuracy: 0.6782 - val_loss: 0.5287 - val_accuracy: 0.7590\n",
      "Epoch 16/1000\n",
      "10000/10000 [==============================] - 3s 294us/sample - loss: 0.5129 - accuracy: 0.7612 - val_loss: 0.4562 - val_accuracy: 0.8120\n",
      "Epoch 17/1000\n",
      "10000/10000 [==============================] - 3s 300us/sample - loss: 0.4547 - accuracy: 0.8083 - val_loss: 0.4429 - val_accuracy: 0.7920\n",
      "Epoch 18/1000\n",
      "10000/10000 [==============================] - 3s 296us/sample - loss: 0.4210 - accuracy: 0.8251 - val_loss: 0.4104 - val_accuracy: 0.8160\n",
      "Epoch 19/1000\n",
      "10000/10000 [==============================] - 3s 296us/sample - loss: 0.4040 - accuracy: 0.8347 - val_loss: 0.4042 - val_accuracy: 0.8300\n",
      "Epoch 20/1000\n",
      "10000/10000 [==============================] - 3s 318us/sample - loss: 0.3878 - accuracy: 0.8475 - val_loss: 0.4004 - val_accuracy: 0.8390\n",
      "Epoch 21/1000\n",
      "10000/10000 [==============================] - 3s 295us/sample - loss: 0.3750 - accuracy: 0.8452 - val_loss: 0.3999 - val_accuracy: 0.8460\n",
      "Epoch 22/1000\n",
      "10000/10000 [==============================] - 3s 330us/sample - loss: 0.3646 - accuracy: 0.8512 - val_loss: 0.3944 - val_accuracy: 0.8370\n",
      "Epoch 23/1000\n",
      "10000/10000 [==============================] - 3s 269us/sample - loss: 0.3523 - accuracy: 0.8577 - val_loss: 0.3799 - val_accuracy: 0.8410\n",
      "Epoch 24/1000\n",
      "10000/10000 [==============================] - 2s 250us/sample - loss: 0.3480 - accuracy: 0.8599 - val_loss: 0.3819 - val_accuracy: 0.8400\n",
      "Epoch 25/1000\n",
      "10000/10000 [==============================] - 2s 250us/sample - loss: 0.3423 - accuracy: 0.8606 - val_loss: 0.4054 - val_accuracy: 0.8430\n",
      "Epoch 26/1000\n",
      "10000/10000 [==============================] - 3s 269us/sample - loss: 0.3369 - accuracy: 0.8620 - val_loss: 0.3656 - val_accuracy: 0.8400\n",
      "Epoch 27/1000\n",
      "10000/10000 [==============================] - 2s 231us/sample - loss: 0.3327 - accuracy: 0.8626 - val_loss: 0.3713 - val_accuracy: 0.8320\n",
      "Epoch 28/1000\n",
      "10000/10000 [==============================] - 2s 224us/sample - loss: 0.3253 - accuracy: 0.8628 - val_loss: 0.3735 - val_accuracy: 0.8330\n",
      "Epoch 29/1000\n",
      "10000/10000 [==============================] - 2s 226us/sample - loss: 0.3264 - accuracy: 0.8650 - val_loss: 0.3710 - val_accuracy: 0.8340\n",
      "Epoch 30/1000\n",
      "10000/10000 [==============================] - 2s 227us/sample - loss: 0.3237 - accuracy: 0.8611 - val_loss: 0.3615 - val_accuracy: 0.8350\n",
      "Epoch 31/1000\n",
      "10000/10000 [==============================] - 2s 226us/sample - loss: 0.3161 - accuracy: 0.8663 - val_loss: 0.3479 - val_accuracy: 0.8410\n",
      "Epoch 32/1000\n",
      "10000/10000 [==============================] - 3s 275us/sample - loss: 0.3126 - accuracy: 0.8682 - val_loss: 0.3778 - val_accuracy: 0.8320\n",
      "Epoch 33/1000\n",
      "10000/10000 [==============================] - 3s 328us/sample - loss: 0.3079 - accuracy: 0.8671 - val_loss: 0.3449 - val_accuracy: 0.8460\n",
      "Epoch 34/1000\n",
      "10000/10000 [==============================] - 3s 299us/sample - loss: 0.3098 - accuracy: 0.8695 - val_loss: 0.3647 - val_accuracy: 0.8350\n",
      "Epoch 35/1000\n",
      "10000/10000 [==============================] - 3s 296us/sample - loss: 0.3075 - accuracy: 0.8678 - val_loss: 0.3526 - val_accuracy: 0.8420\n",
      "Epoch 36/1000\n",
      "10000/10000 [==============================] - 3s 296us/sample - loss: 0.3048 - accuracy: 0.8710 - val_loss: 0.3527 - val_accuracy: 0.8400\n",
      "Epoch 37/1000\n",
      "10000/10000 [==============================] - 3s 325us/sample - loss: 0.3042 - accuracy: 0.8687 - val_loss: 0.3388 - val_accuracy: 0.8470\n",
      "Epoch 38/1000\n",
      "10000/10000 [==============================] - 3s 295us/sample - loss: 0.2985 - accuracy: 0.8681 - val_loss: 0.3505 - val_accuracy: 0.8520\n",
      "Epoch 39/1000\n",
      "10000/10000 [==============================] - 3s 297us/sample - loss: 0.2970 - accuracy: 0.8723 - val_loss: 0.3503 - val_accuracy: 0.8420\n",
      "Epoch 40/1000\n",
      "10000/10000 [==============================] - 3s 306us/sample - loss: 0.2986 - accuracy: 0.8703 - val_loss: 0.3428 - val_accuracy: 0.8430\n",
      "Epoch 41/1000\n",
      "10000/10000 [==============================] - 3s 309us/sample - loss: 0.2987 - accuracy: 0.8718 - val_loss: 0.3408 - val_accuracy: 0.8410\n",
      "Epoch 42/1000\n",
      "10000/10000 [==============================] - 3s 326us/sample - loss: 0.3000 - accuracy: 0.8714 - val_loss: 0.3540 - val_accuracy: 0.8410\n",
      "Epoch 43/1000\n",
      "10000/10000 [==============================] - 3s 303us/sample - loss: 0.2933 - accuracy: 0.8715 - val_loss: 0.3495 - val_accuracy: 0.8400\n",
      "Epoch 44/1000\n",
      "10000/10000 [==============================] - 3s 299us/sample - loss: 0.2928 - accuracy: 0.8737 - val_loss: 0.3553 - val_accuracy: 0.8360\n",
      "Epoch 45/1000\n",
      "10000/10000 [==============================] - 3s 297us/sample - loss: 0.2882 - accuracy: 0.8768 - val_loss: 0.3398 - val_accuracy: 0.8380\n",
      "Epoch 46/1000\n",
      "10000/10000 [==============================] - 3s 299us/sample - loss: 0.2944 - accuracy: 0.8710 - val_loss: 0.3511 - val_accuracy: 0.8360\n",
      "Epoch 47/1000\n",
      "10000/10000 [==============================] - 3s 336us/sample - loss: 0.2923 - accuracy: 0.8739 - val_loss: 0.3547 - val_accuracy: 0.8380\n",
      "Epoch 48/1000\n",
      "10000/10000 [==============================] - 3s 304us/sample - loss: 0.2922 - accuracy: 0.8749 - val_loss: 0.3569 - val_accuracy: 0.8340\n",
      "Epoch 49/1000\n",
      "10000/10000 [==============================] - 3s 305us/sample - loss: 0.2881 - accuracy: 0.8742 - val_loss: 0.3533 - val_accuracy: 0.8420\n",
      "Epoch 50/1000\n",
      "10000/10000 [==============================] - 3s 328us/sample - loss: 0.2889 - accuracy: 0.8756 - val_loss: 0.3436 - val_accuracy: 0.8370\n",
      "Epoch 51/1000\n",
      "10000/10000 [==============================] - 3s 323us/sample - loss: 0.2847 - accuracy: 0.8786 - val_loss: 0.3842 - val_accuracy: 0.8330\n",
      "Epoch 52/1000\n",
      "10000/10000 [==============================] - 3s 308us/sample - loss: 0.2886 - accuracy: 0.8735 - val_loss: 0.3537 - val_accuracy: 0.8380\n",
      "Epoch 53/1000\n",
      "10000/10000 [==============================] - 3s 303us/sample - loss: 0.2869 - accuracy: 0.8754 - val_loss: 0.3466 - val_accuracy: 0.8390\n",
      "Epoch 54/1000\n",
      "10000/10000 [==============================] - 3s 259us/sample - loss: 0.2837 - accuracy: 0.8780 - val_loss: 0.3435 - val_accuracy: 0.8390\n",
      "Epoch 55/1000\n",
      "10000/10000 [==============================] - 3s 268us/sample - loss: 0.2878 - accuracy: 0.8756 - val_loss: 0.3636 - val_accuracy: 0.8320\n",
      "Epoch 56/1000\n",
      "10000/10000 [==============================] - 3s 310us/sample - loss: 0.2853 - accuracy: 0.8767 - val_loss: 0.3665 - val_accuracy: 0.8330\n",
      "Epoch 57/1000\n",
      "10000/10000 [==============================] - 3s 322us/sample - loss: 0.2842 - accuracy: 0.8764 - val_loss: 0.3575 - val_accuracy: 0.8270\n",
      "Epoch 58/1000\n",
      "10000/10000 [==============================] - 3s 306us/sample - loss: 0.2831 - accuracy: 0.8786 - val_loss: 0.3532 - val_accuracy: 0.8340\n",
      "Epoch 59/1000\n",
      "10000/10000 [==============================] - 3s 299us/sample - loss: 0.2825 - accuracy: 0.8779 - val_loss: 0.3536 - val_accuracy: 0.8410\n",
      "Epoch 60/1000\n",
      "10000/10000 [==============================] - 3s 301us/sample - loss: 0.2831 - accuracy: 0.8800 - val_loss: 0.3572 - val_accuracy: 0.8320\n",
      "Epoch 61/1000\n",
      "10000/10000 [==============================] - 3s 337us/sample - loss: 0.2779 - accuracy: 0.8783 - val_loss: 0.3707 - val_accuracy: 0.8370\n",
      "Epoch 62/1000\n",
      "10000/10000 [==============================] - 3s 302us/sample - loss: 0.2747 - accuracy: 0.8815 - val_loss: 0.3538 - val_accuracy: 0.8350\n",
      "Epoch 63/1000\n",
      "10000/10000 [==============================] - 3s 302us/sample - loss: 0.2774 - accuracy: 0.8797 - val_loss: 0.3671 - val_accuracy: 0.8300\n",
      "Epoch 64/1000\n",
      "10000/10000 [==============================] - 3s 307us/sample - loss: 0.2747 - accuracy: 0.8801 - val_loss: 0.4498 - val_accuracy: 0.8230\n",
      "Epoch 65/1000\n",
      "10000/10000 [==============================] - 3s 307us/sample - loss: 0.2780 - accuracy: 0.8820 - val_loss: 0.3639 - val_accuracy: 0.8380\n",
      "Epoch 66/1000\n",
      "10000/10000 [==============================] - 3s 332us/sample - loss: 0.2733 - accuracy: 0.8830 - val_loss: 0.3643 - val_accuracy: 0.8320\n",
      "Epoch 67/1000\n",
      "10000/10000 [==============================] - 3s 303us/sample - loss: 0.2727 - accuracy: 0.8807 - val_loss: 0.3596 - val_accuracy: 0.8290\n",
      "Epoch 68/1000\n",
      "10000/10000 [==============================] - 3s 305us/sample - loss: 0.2722 - accuracy: 0.8850 - val_loss: 0.3858 - val_accuracy: 0.8350\n",
      "Epoch 69/1000\n",
      "10000/10000 [==============================] - 3s 300us/sample - loss: 0.2735 - accuracy: 0.8811 - val_loss: 0.3994 - val_accuracy: 0.8260\n",
      "Epoch 70/1000\n",
      "10000/10000 [==============================] - 3s 300us/sample - loss: 0.2697 - accuracy: 0.8853 - val_loss: 0.3855 - val_accuracy: 0.8290\n",
      "Epoch 71/1000\n",
      "10000/10000 [==============================] - 3s 338us/sample - loss: 0.2722 - accuracy: 0.8847 - val_loss: 0.3911 - val_accuracy: 0.8330\n",
      "Epoch 72/1000\n",
      "10000/10000 [==============================] - 3s 299us/sample - loss: 0.2656 - accuracy: 0.8853 - val_loss: 0.3784 - val_accuracy: 0.8380\n",
      "Epoch 73/1000\n",
      "10000/10000 [==============================] - 3s 302us/sample - loss: 0.2653 - accuracy: 0.8858 - val_loss: 0.3844 - val_accuracy: 0.8410\n",
      "Epoch 74/1000\n",
      "10000/10000 [==============================] - 3s 311us/sample - loss: 0.2613 - accuracy: 0.8896 - val_loss: 0.3543 - val_accuracy: 0.8360\n",
      "Epoch 75/1000\n",
      "10000/10000 [==============================] - 3s 306us/sample - loss: 0.2679 - accuracy: 0.8855 - val_loss: 0.3726 - val_accuracy: 0.8370\n",
      "Epoch 76/1000\n",
      "10000/10000 [==============================] - 3s 335us/sample - loss: 0.2633 - accuracy: 0.8885 - val_loss: 0.3785 - val_accuracy: 0.8310\n",
      "Epoch 77/1000\n",
      "10000/10000 [==============================] - 3s 304us/sample - loss: 0.2592 - accuracy: 0.8901 - val_loss: 0.3797 - val_accuracy: 0.8310\n",
      "Epoch 78/1000\n",
      "10000/10000 [==============================] - 3s 300us/sample - loss: 0.2587 - accuracy: 0.8869 - val_loss: 0.3835 - val_accuracy: 0.8350\n",
      "Epoch 79/1000\n",
      "10000/10000 [==============================] - 3s 302us/sample - loss: 0.2614 - accuracy: 0.8886 - val_loss: 0.3701 - val_accuracy: 0.8410\n",
      "Epoch 80/1000\n",
      "10000/10000 [==============================] - 3s 303us/sample - loss: 0.2660 - accuracy: 0.8885 - val_loss: 0.3877 - val_accuracy: 0.8300\n",
      "Epoch 81/1000\n",
      "10000/10000 [==============================] - 3s 334us/sample - loss: 0.2560 - accuracy: 0.8928 - val_loss: 0.3737 - val_accuracy: 0.8370\n",
      "Epoch 82/1000\n",
      "10000/10000 [==============================] - 3s 302us/sample - loss: 0.2598 - accuracy: 0.8910 - val_loss: 0.4097 - val_accuracy: 0.8350\n",
      "Epoch 83/1000\n",
      "10000/10000 [==============================] - 3s 305us/sample - loss: 0.2572 - accuracy: 0.8937 - val_loss: 0.3891 - val_accuracy: 0.8290\n",
      "Epoch 84/1000\n",
      "10000/10000 [==============================] - 3s 316us/sample - loss: 0.2554 - accuracy: 0.8912 - val_loss: 0.4113 - val_accuracy: 0.8300\n",
      "Epoch 85/1000\n",
      "10000/10000 [==============================] - 3s 309us/sample - loss: 0.2489 - accuracy: 0.8943 - val_loss: 0.4214 - val_accuracy: 0.8310\n",
      "Epoch 86/1000\n",
      "10000/10000 [==============================] - 3s 326us/sample - loss: 0.2529 - accuracy: 0.8928 - val_loss: 0.4078 - val_accuracy: 0.8290\n",
      "Epoch 87/1000\n",
      "10000/10000 [==============================] - 3s 306us/sample - loss: 0.2457 - accuracy: 0.8933 - val_loss: 0.4054 - val_accuracy: 0.8270\n",
      "Epoch 88/1000\n",
      "10000/10000 [==============================] - 3s 311us/sample - loss: 0.2464 - accuracy: 0.8958 - val_loss: 0.3975 - val_accuracy: 0.8330\n",
      "Epoch 89/1000\n",
      "10000/10000 [==============================] - 4s 395us/sample - loss: 0.2435 - accuracy: 0.8971 - val_loss: 0.4520 - val_accuracy: 0.8300\n",
      "Epoch 90/1000\n",
      "10000/10000 [==============================] - 3s 341us/sample - loss: 0.2434 - accuracy: 0.8952 - val_loss: 0.4196 - val_accuracy: 0.8320\n",
      "Epoch 91/1000\n",
      "10000/10000 [==============================] - 3s 306us/sample - loss: 0.2417 - accuracy: 0.8988 - val_loss: 0.4225 - val_accuracy: 0.8370\n",
      "Epoch 92/1000\n",
      "10000/10000 [==============================] - 3s 302us/sample - loss: 0.2431 - accuracy: 0.8978 - val_loss: 0.4261 - val_accuracy: 0.8280\n",
      "Epoch 93/1000\n",
      "10000/10000 [==============================] - 3s 308us/sample - loss: 0.2406 - accuracy: 0.8975 - val_loss: 0.4190 - val_accuracy: 0.8280\n",
      "Epoch 94/1000\n",
      "10000/10000 [==============================] - 3s 306us/sample - loss: 0.2405 - accuracy: 0.8989 - val_loss: 0.4192 - val_accuracy: 0.8270\n",
      "Epoch 95/1000\n",
      "10000/10000 [==============================] - 3s 339us/sample - loss: 0.2318 - accuracy: 0.9018 - val_loss: 0.4304 - val_accuracy: 0.8310\n",
      "Epoch 96/1000\n",
      "10000/10000 [==============================] - 3s 330us/sample - loss: 0.2301 - accuracy: 0.9031 - val_loss: 0.4399 - val_accuracy: 0.8290\n",
      "Epoch 97/1000\n",
      "10000/10000 [==============================] - 3s 324us/sample - loss: 0.2358 - accuracy: 0.9036 - val_loss: 0.4102 - val_accuracy: 0.8270\n",
      "Epoch 98/1000\n",
      "10000/10000 [==============================] - 3s 321us/sample - loss: 0.2266 - accuracy: 0.9017 - val_loss: 0.4425 - val_accuracy: 0.8310\n",
      "Epoch 99/1000\n",
      "10000/10000 [==============================] - 3s 308us/sample - loss: 0.2284 - accuracy: 0.9053 - val_loss: 0.4409 - val_accuracy: 0.8380\n",
      "Epoch 100/1000\n",
      "10000/10000 [==============================] - 3s 325us/sample - loss: 0.2338 - accuracy: 0.9047 - val_loss: 0.4579 - val_accuracy: 0.8370\n",
      "Epoch 101/1000\n",
      "10000/10000 [==============================] - 3s 306us/sample - loss: 0.2299 - accuracy: 0.9062 - val_loss: 0.4640 - val_accuracy: 0.8300\n",
      "Epoch 102/1000\n",
      "10000/10000 [==============================] - 3s 309us/sample - loss: 0.2282 - accuracy: 0.9069 - val_loss: 0.4282 - val_accuracy: 0.8390\n",
      "Epoch 103/1000\n",
      "10000/10000 [==============================] - 3s 312us/sample - loss: 0.2280 - accuracy: 0.9039 - val_loss: 0.4481 - val_accuracy: 0.8380\n",
      "Epoch 104/1000\n",
      "10000/10000 [==============================] - 3s 336us/sample - loss: 0.2214 - accuracy: 0.9092 - val_loss: 0.4576 - val_accuracy: 0.8380\n",
      "Epoch 105/1000\n",
      "10000/10000 [==============================] - 3s 309us/sample - loss: 0.2185 - accuracy: 0.9092 - val_loss: 0.4569 - val_accuracy: 0.8300\n",
      "Epoch 106/1000\n",
      "10000/10000 [==============================] - 3s 304us/sample - loss: 0.2213 - accuracy: 0.9080 - val_loss: 0.5473 - val_accuracy: 0.8320\n",
      "Epoch 107/1000\n",
      "10000/10000 [==============================] - 3s 303us/sample - loss: 0.2122 - accuracy: 0.9090 - val_loss: 0.4845 - val_accuracy: 0.8320\n",
      "Epoch 108/1000\n",
      "10000/10000 [==============================] - 3s 304us/sample - loss: 0.2154 - accuracy: 0.9108 - val_loss: 0.5170 - val_accuracy: 0.8300\n",
      "Epoch 109/1000\n",
      "10000/10000 [==============================] - 3s 337us/sample - loss: 0.2147 - accuracy: 0.9139 - val_loss: 0.4670 - val_accuracy: 0.8360\n",
      "Epoch 110/1000\n",
      "10000/10000 [==============================] - 3s 302us/sample - loss: 0.2100 - accuracy: 0.9130 - val_loss: 0.4816 - val_accuracy: 0.8360\n",
      "Epoch 111/1000\n",
      "10000/10000 [==============================] - 3s 313us/sample - loss: 0.2133 - accuracy: 0.9091 - val_loss: 0.5047 - val_accuracy: 0.8330\n",
      "Epoch 112/1000\n",
      "10000/10000 [==============================] - 3s 308us/sample - loss: 0.2102 - accuracy: 0.9141 - val_loss: 0.5146 - val_accuracy: 0.8340\n",
      "Epoch 113/1000\n",
      "10000/10000 [==============================] - 3s 309us/sample - loss: 0.2076 - accuracy: 0.9140 - val_loss: 0.6351 - val_accuracy: 0.8100\n",
      "Epoch 114/1000\n",
      "10000/10000 [==============================] - 3s 344us/sample - loss: 0.2133 - accuracy: 0.9132 - val_loss: 0.4674 - val_accuracy: 0.8290\n",
      "Epoch 115/1000\n",
      "10000/10000 [==============================] - 3s 304us/sample - loss: 0.2103 - accuracy: 0.9139 - val_loss: 0.4508 - val_accuracy: 0.8410\n",
      "Epoch 116/1000\n",
      "10000/10000 [==============================] - 3s 306us/sample - loss: 0.2032 - accuracy: 0.9156 - val_loss: 0.5025 - val_accuracy: 0.8300\n",
      "Epoch 117/1000\n",
      "10000/10000 [==============================] - 3s 328us/sample - loss: 0.2007 - accuracy: 0.9166 - val_loss: 0.5423 - val_accuracy: 0.8320\n",
      "Epoch 118/1000\n",
      "10000/10000 [==============================] - 3s 348us/sample - loss: 0.2048 - accuracy: 0.9183 - val_loss: 0.5325 - val_accuracy: 0.8320\n",
      "Epoch 119/1000\n",
      "10000/10000 [==============================] - 3s 327us/sample - loss: 0.1995 - accuracy: 0.9190 - val_loss: 0.5127 - val_accuracy: 0.8350\n",
      "Epoch 120/1000\n",
      "10000/10000 [==============================] - 3s 334us/sample - loss: 0.2057 - accuracy: 0.9154 - val_loss: 0.4989 - val_accuracy: 0.8340\n",
      "Epoch 121/1000\n",
      "10000/10000 [==============================] - 3s 325us/sample - loss: 0.1988 - accuracy: 0.9159 - val_loss: 0.6282 - val_accuracy: 0.8170\n",
      "Epoch 122/1000\n",
      "10000/10000 [==============================] - 3s 306us/sample - loss: 0.1981 - accuracy: 0.9181 - val_loss: 0.5575 - val_accuracy: 0.8320\n",
      "Epoch 123/1000\n",
      "10000/10000 [==============================] - 3s 342us/sample - loss: 0.1953 - accuracy: 0.9200 - val_loss: 0.5275 - val_accuracy: 0.8270\n",
      "Epoch 124/1000\n",
      "10000/10000 [==============================] - 3s 307us/sample - loss: 0.1926 - accuracy: 0.9206 - val_loss: 0.5358 - val_accuracy: 0.8260\n",
      "Epoch 125/1000\n",
      "10000/10000 [==============================] - 3s 305us/sample - loss: 0.1981 - accuracy: 0.9184 - val_loss: 0.4946 - val_accuracy: 0.8380\n",
      "Epoch 126/1000\n",
      "10000/10000 [==============================] - 3s 302us/sample - loss: 0.1942 - accuracy: 0.9194 - val_loss: 0.5764 - val_accuracy: 0.8270\n",
      "Epoch 127/1000\n",
      "10000/10000 [==============================] - 3s 305us/sample - loss: 0.1927 - accuracy: 0.9195 - val_loss: 0.4647 - val_accuracy: 0.8430\n",
      "Epoch 128/1000\n",
      "10000/10000 [==============================] - 3s 339us/sample - loss: 0.1864 - accuracy: 0.9237 - val_loss: 0.5786 - val_accuracy: 0.8350\n",
      "Epoch 129/1000\n",
      "10000/10000 [==============================] - 3s 314us/sample - loss: 0.1975 - accuracy: 0.9164 - val_loss: 0.5527 - val_accuracy: 0.8320\n",
      "Epoch 130/1000\n",
      "10000/10000 [==============================] - 3s 323us/sample - loss: 0.1956 - accuracy: 0.9209 - val_loss: 0.5951 - val_accuracy: 0.8310\n",
      "Epoch 131/1000\n",
      "10000/10000 [==============================] - 3s 318us/sample - loss: 0.1853 - accuracy: 0.9255 - val_loss: 0.5820 - val_accuracy: 0.8320\n",
      "Epoch 132/1000\n",
      "10000/10000 [==============================] - 4s 376us/sample - loss: 0.1840 - accuracy: 0.9257 - val_loss: 0.5464 - val_accuracy: 0.8350\n",
      "Epoch 133/1000\n",
      "10000/10000 [==============================] - 3s 320us/sample - loss: 0.1868 - accuracy: 0.9218 - val_loss: 0.5797 - val_accuracy: 0.8340\n",
      "Epoch 134/1000\n",
      "10000/10000 [==============================] - 3s 320us/sample - loss: 0.1783 - accuracy: 0.9265 - val_loss: 0.5768 - val_accuracy: 0.8260\n",
      "Epoch 135/1000\n",
      "10000/10000 [==============================] - 3s 325us/sample - loss: 0.1835 - accuracy: 0.9278 - val_loss: 0.5957 - val_accuracy: 0.8310\n",
      "Epoch 136/1000\n",
      "10000/10000 [==============================] - 3s 322us/sample - loss: 0.1828 - accuracy: 0.9278 - val_loss: 0.6637 - val_accuracy: 0.8240\n",
      "Epoch 137/1000\n",
      "10000/10000 [==============================] - 4s 357us/sample - loss: 0.1836 - accuracy: 0.9287 - val_loss: 0.5389 - val_accuracy: 0.8330\n",
      "Epoch 138/1000\n",
      "10000/10000 [==============================] - 3s 341us/sample - loss: 0.1777 - accuracy: 0.9289 - val_loss: 0.6724 - val_accuracy: 0.8190\n",
      "Epoch 139/1000\n",
      "10000/10000 [==============================] - 3s 333us/sample - loss: 0.1742 - accuracy: 0.9303 - val_loss: 0.6509 - val_accuracy: 0.8250\n",
      "Epoch 140/1000\n",
      "10000/10000 [==============================] - 3s 323us/sample - loss: 0.1840 - accuracy: 0.9281 - val_loss: 0.5653 - val_accuracy: 0.8240\n",
      "Epoch 141/1000\n",
      "10000/10000 [==============================] - 3s 299us/sample - loss: 0.1720 - accuracy: 0.9295 - val_loss: 0.6592 - val_accuracy: 0.8230\n",
      "Epoch 142/1000\n",
      "10000/10000 [==============================] - 4s 354us/sample - loss: 0.1707 - accuracy: 0.9324 - val_loss: 0.5704 - val_accuracy: 0.8350\n",
      "Epoch 143/1000\n",
      "10000/10000 [==============================] - 3s 329us/sample - loss: 0.1733 - accuracy: 0.9322 - val_loss: 0.6324 - val_accuracy: 0.8240\n",
      "Epoch 144/1000\n",
      "10000/10000 [==============================] - 3s 330us/sample - loss: 0.1689 - accuracy: 0.9336 - val_loss: 0.6003 - val_accuracy: 0.8290\n",
      "Epoch 145/1000\n",
      "10000/10000 [==============================] - 3s 333us/sample - loss: 0.1715 - accuracy: 0.9294 - val_loss: 0.6210 - val_accuracy: 0.8310\n",
      "Epoch 146/1000\n",
      "10000/10000 [==============================] - 3s 338us/sample - loss: 0.1778 - accuracy: 0.9291 - val_loss: 0.6521 - val_accuracy: 0.8210\n",
      "Epoch 147/1000\n",
      "10000/10000 [==============================] - 3s 311us/sample - loss: 0.1617 - accuracy: 0.9357 - val_loss: 0.6984 - val_accuracy: 0.8250\n",
      "Epoch 148/1000\n",
      "10000/10000 [==============================] - 3s 329us/sample - loss: 0.1692 - accuracy: 0.9336 - val_loss: 0.6866 - val_accuracy: 0.8210\n",
      "Epoch 149/1000\n",
      "10000/10000 [==============================] - 3s 332us/sample - loss: 0.1700 - accuracy: 0.9346 - val_loss: 0.6573 - val_accuracy: 0.8190\n",
      "Epoch 150/1000\n",
      "10000/10000 [==============================] - 3s 327us/sample - loss: 0.1591 - accuracy: 0.9382 - val_loss: 0.7210 - val_accuracy: 0.8260\n",
      "Epoch 151/1000\n",
      "10000/10000 [==============================] - 3s 350us/sample - loss: 0.1580 - accuracy: 0.9357 - val_loss: 0.7152 - val_accuracy: 0.8360\n",
      "Epoch 152/1000\n",
      "10000/10000 [==============================] - 3s 322us/sample - loss: 0.1676 - accuracy: 0.9324 - val_loss: 0.6614 - val_accuracy: 0.8290\n",
      "Epoch 153/1000\n",
      "10000/10000 [==============================] - 3s 326us/sample - loss: 0.1604 - accuracy: 0.9368 - val_loss: 0.6080 - val_accuracy: 0.8290\n",
      "Epoch 154/1000\n",
      "10000/10000 [==============================] - 3s 338us/sample - loss: 0.1627 - accuracy: 0.9360 - val_loss: 0.7008 - val_accuracy: 0.8210\n",
      "Epoch 155/1000\n",
      "10000/10000 [==============================] - 4s 353us/sample - loss: 0.1638 - accuracy: 0.9358 - val_loss: 0.7085 - val_accuracy: 0.8310\n",
      "Epoch 156/1000\n",
      "10000/10000 [==============================] - 3s 330us/sample - loss: 0.1576 - accuracy: 0.9398 - val_loss: 0.6876 - val_accuracy: 0.8190\n",
      "Epoch 157/1000\n",
      "10000/10000 [==============================] - 3s 320us/sample - loss: 0.1570 - accuracy: 0.9384 - val_loss: 0.6766 - val_accuracy: 0.8270\n",
      "Epoch 158/1000\n",
      "10000/10000 [==============================] - 3s 334us/sample - loss: 0.1579 - accuracy: 0.9377 - val_loss: 0.6925 - val_accuracy: 0.8170\n",
      "Epoch 159/1000\n",
      "10000/10000 [==============================] - 3s 298us/sample - loss: 0.1537 - accuracy: 0.9436 - val_loss: 0.6936 - val_accuracy: 0.8250\n",
      "Epoch 160/1000\n",
      "10000/10000 [==============================] - 3s 345us/sample - loss: 0.1516 - accuracy: 0.9426 - val_loss: 0.7703 - val_accuracy: 0.8260\n",
      "Epoch 161/1000\n",
      "10000/10000 [==============================] - 3s 314us/sample - loss: 0.1538 - accuracy: 0.9413 - val_loss: 0.6468 - val_accuracy: 0.8300\n",
      "Epoch 162/1000\n",
      "10000/10000 [==============================] - 3s 304us/sample - loss: 0.1510 - accuracy: 0.9422 - val_loss: 0.7208 - val_accuracy: 0.8170\n",
      "Epoch 163/1000\n",
      "10000/10000 [==============================] - 3s 307us/sample - loss: 0.1486 - accuracy: 0.9427 - val_loss: 0.6869 - val_accuracy: 0.8220\n",
      "Epoch 164/1000\n",
      "10000/10000 [==============================] - 3s 328us/sample - loss: 0.1476 - accuracy: 0.9450 - val_loss: 0.8119 - val_accuracy: 0.8210\n",
      "Epoch 165/1000\n",
      "10000/10000 [==============================] - 3s 305us/sample - loss: 0.1479 - accuracy: 0.9420 - val_loss: 0.7442 - val_accuracy: 0.8200\n",
      "Epoch 166/1000\n",
      "10000/10000 [==============================] - 3s 304us/sample - loss: 0.1478 - accuracy: 0.9425 - val_loss: 0.7508 - val_accuracy: 0.8250\n",
      "Epoch 167/1000\n",
      "10000/10000 [==============================] - 3s 305us/sample - loss: 0.1416 - accuracy: 0.9451 - val_loss: 0.7227 - val_accuracy: 0.8250\n",
      "Epoch 168/1000\n",
      "10000/10000 [==============================] - 3s 309us/sample - loss: 0.1427 - accuracy: 0.9445 - val_loss: 0.7048 - val_accuracy: 0.8220\n",
      "Epoch 169/1000\n",
      "10000/10000 [==============================] - 3s 345us/sample - loss: 0.1443 - accuracy: 0.9443 - val_loss: 0.7356 - val_accuracy: 0.8230\n",
      "Epoch 170/1000\n",
      "10000/10000 [==============================] - 3s 309us/sample - loss: 0.1451 - accuracy: 0.9435 - val_loss: 0.7335 - val_accuracy: 0.8200\n",
      "Epoch 171/1000\n",
      "10000/10000 [==============================] - 3s 307us/sample - loss: 0.1346 - accuracy: 0.9466 - val_loss: 0.7445 - val_accuracy: 0.8260\n",
      "Epoch 172/1000\n",
      "10000/10000 [==============================] - 3s 319us/sample - loss: 0.1392 - accuracy: 0.9438 - val_loss: 0.6805 - val_accuracy: 0.8290\n",
      "Epoch 173/1000\n",
      "10000/10000 [==============================] - 3s 318us/sample - loss: 0.1324 - accuracy: 0.9495 - val_loss: 0.7676 - val_accuracy: 0.8300\n",
      "Epoch 174/1000\n",
      "10000/10000 [==============================] - 4s 353us/sample - loss: 0.1450 - accuracy: 0.9459 - val_loss: 0.7893 - val_accuracy: 0.8220\n",
      "Epoch 175/1000\n",
      "10000/10000 [==============================] - 3s 311us/sample - loss: 0.1392 - accuracy: 0.9458 - val_loss: 0.6934 - val_accuracy: 0.8200\n",
      "Epoch 176/1000\n",
      "10000/10000 [==============================] - 3s 320us/sample - loss: 0.1286 - accuracy: 0.9495 - val_loss: 0.8077 - val_accuracy: 0.8200\n",
      "Epoch 177/1000\n",
      "10000/10000 [==============================] - 3s 325us/sample - loss: 0.1395 - accuracy: 0.9478 - val_loss: 0.8408 - val_accuracy: 0.8100\n",
      "Epoch 178/1000\n",
      "10000/10000 [==============================] - 4s 387us/sample - loss: 0.1264 - accuracy: 0.9518 - val_loss: 0.7854 - val_accuracy: 0.8180\n",
      "Epoch 179/1000\n",
      "10000/10000 [==============================] - 3s 326us/sample - loss: 0.1355 - accuracy: 0.9478 - val_loss: 0.7410 - val_accuracy: 0.8310\n",
      "Epoch 180/1000\n",
      "10000/10000 [==============================] - 3s 312us/sample - loss: 0.1310 - accuracy: 0.9502 - val_loss: 0.7493 - val_accuracy: 0.8240\n",
      "Epoch 181/1000\n",
      "10000/10000 [==============================] - 3s 315us/sample - loss: 0.1305 - accuracy: 0.9513 - val_loss: 0.7801 - val_accuracy: 0.8280\n",
      "Epoch 182/1000\n",
      "10000/10000 [==============================] - 3s 310us/sample - loss: 0.1320 - accuracy: 0.9490 - val_loss: 0.7563 - val_accuracy: 0.8280\n",
      "Epoch 183/1000\n",
      "10000/10000 [==============================] - 3s 336us/sample - loss: 0.1206 - accuracy: 0.9537 - val_loss: 0.8303 - val_accuracy: 0.8220\n",
      "Epoch 184/1000\n",
      "10000/10000 [==============================] - 3s 307us/sample - loss: 0.1278 - accuracy: 0.9521 - val_loss: 0.8762 - val_accuracy: 0.8230\n",
      "Epoch 185/1000\n",
      "10000/10000 [==============================] - 3s 304us/sample - loss: 0.1265 - accuracy: 0.9500 - val_loss: 0.8012 - val_accuracy: 0.8220\n",
      "Epoch 186/1000\n",
      "10000/10000 [==============================] - 3s 316us/sample - loss: 0.1261 - accuracy: 0.9504 - val_loss: 0.8414 - val_accuracy: 0.8230\n",
      "Epoch 187/1000\n",
      "10000/10000 [==============================] - 3s 308us/sample - loss: 0.1257 - accuracy: 0.9531 - val_loss: 0.8305 - val_accuracy: 0.8150\n",
      "Epoch 188/1000\n",
      "10000/10000 [==============================] - 3s 338us/sample - loss: 0.1223 - accuracy: 0.9530 - val_loss: 0.9215 - val_accuracy: 0.8250\n",
      "Epoch 189/1000\n",
      "10000/10000 [==============================] - 3s 310us/sample - loss: 0.1295 - accuracy: 0.9520 - val_loss: 0.7891 - val_accuracy: 0.8260\n",
      "Epoch 190/1000\n",
      "10000/10000 [==============================] - 3s 304us/sample - loss: 0.1140 - accuracy: 0.9547 - val_loss: 0.9549 - val_accuracy: 0.8210\n",
      "Epoch 191/1000\n",
      "10000/10000 [==============================] - 3s 304us/sample - loss: 0.1226 - accuracy: 0.9528 - val_loss: 0.9307 - val_accuracy: 0.8260\n",
      "Epoch 192/1000\n",
      "10000/10000 [==============================] - 3s 317us/sample - loss: 0.1208 - accuracy: 0.9546 - val_loss: 0.8231 - val_accuracy: 0.8270\n",
      "Epoch 193/1000\n",
      "10000/10000 [==============================] - 3s 348us/sample - loss: 0.1152 - accuracy: 0.9567 - val_loss: 0.8137 - val_accuracy: 0.8300\n",
      "Epoch 194/1000\n",
      "10000/10000 [==============================] - 3s 329us/sample - loss: 0.1198 - accuracy: 0.9548 - val_loss: 0.9484 - val_accuracy: 0.8280\n",
      "Epoch 195/1000\n",
      "10000/10000 [==============================] - 3s 315us/sample - loss: 0.1184 - accuracy: 0.9541 - val_loss: 0.8971 - val_accuracy: 0.8310\n",
      "Epoch 196/1000\n",
      "10000/10000 [==============================] - 3s 325us/sample - loss: 0.1182 - accuracy: 0.9577 - val_loss: 0.9142 - val_accuracy: 0.8160\n",
      "Epoch 197/1000\n",
      "10000/10000 [==============================] - 4s 362us/sample - loss: 0.1152 - accuracy: 0.9563 - val_loss: 0.8637 - val_accuracy: 0.8200\n",
      "Epoch 198/1000\n",
      "10000/10000 [==============================] - 3s 314us/sample - loss: 0.1147 - accuracy: 0.9610 - val_loss: 0.8644 - val_accuracy: 0.8260\n",
      "Epoch 199/1000\n",
      "10000/10000 [==============================] - 3s 307us/sample - loss: 0.1168 - accuracy: 0.9567 - val_loss: 0.9848 - val_accuracy: 0.8150\n",
      "Epoch 200/1000\n",
      "10000/10000 [==============================] - 3s 304us/sample - loss: 0.1126 - accuracy: 0.9573 - val_loss: 0.8993 - val_accuracy: 0.8240\n",
      "Epoch 201/1000\n",
      "10000/10000 [==============================] - 3s 307us/sample - loss: 0.1130 - accuracy: 0.9604 - val_loss: 0.9010 - val_accuracy: 0.8290\n",
      "Epoch 202/1000\n",
      "10000/10000 [==============================] - 4s 357us/sample - loss: 0.1080 - accuracy: 0.9621 - val_loss: 0.8878 - val_accuracy: 0.8350\n",
      "Epoch 203/1000\n",
      "10000/10000 [==============================] - 3s 312us/sample - loss: 0.1100 - accuracy: 0.9600 - val_loss: 0.9074 - val_accuracy: 0.8270\n",
      "Epoch 204/1000\n",
      "10000/10000 [==============================] - 3s 306us/sample - loss: 0.1101 - accuracy: 0.9592 - val_loss: 0.9444 - val_accuracy: 0.8220\n",
      "Epoch 205/1000\n",
      "10000/10000 [==============================] - 3s 314us/sample - loss: 0.1094 - accuracy: 0.9590 - val_loss: 0.9408 - val_accuracy: 0.8290\n",
      "Epoch 206/1000\n",
      "10000/10000 [==============================] - 3s 312us/sample - loss: 0.1088 - accuracy: 0.9588 - val_loss: 0.9174 - val_accuracy: 0.8240\n",
      "Epoch 207/1000\n",
      "10000/10000 [==============================] - 3s 336us/sample - loss: 0.1111 - accuracy: 0.9603 - val_loss: 0.8653 - val_accuracy: 0.8250\n",
      "Epoch 208/1000\n",
      "10000/10000 [==============================] - 3s 311us/sample - loss: 0.1104 - accuracy: 0.9589 - val_loss: 0.8240 - val_accuracy: 0.8280\n",
      "Epoch 209/1000\n",
      "10000/10000 [==============================] - 3s 306us/sample - loss: 0.1114 - accuracy: 0.9596 - val_loss: 0.8899 - val_accuracy: 0.8360\n",
      "Epoch 210/1000\n",
      "10000/10000 [==============================] - 3s 314us/sample - loss: 0.1053 - accuracy: 0.9618 - val_loss: 0.9514 - val_accuracy: 0.8300\n",
      "Epoch 211/1000\n",
      "10000/10000 [==============================] - 3s 337us/sample - loss: 0.1015 - accuracy: 0.9627 - val_loss: 0.9538 - val_accuracy: 0.8280\n",
      "Epoch 212/1000\n",
      "10000/10000 [==============================] - 3s 310us/sample - loss: 0.1039 - accuracy: 0.9614 - val_loss: 1.0321 - val_accuracy: 0.8270\n",
      "Epoch 213/1000\n",
      "10000/10000 [==============================] - 3s 305us/sample - loss: 0.1022 - accuracy: 0.9627 - val_loss: 0.9758 - val_accuracy: 0.8320\n",
      "Epoch 214/1000\n",
      "10000/10000 [==============================] - 3s 317us/sample - loss: 0.1064 - accuracy: 0.9599 - val_loss: 0.8508 - val_accuracy: 0.8320\n",
      "Epoch 215/1000\n",
      "10000/10000 [==============================] - 3s 318us/sample - loss: 0.1004 - accuracy: 0.9625 - val_loss: 0.9942 - val_accuracy: 0.8260\n",
      "Epoch 216/1000\n",
      "10000/10000 [==============================] - 3s 339us/sample - loss: 0.1049 - accuracy: 0.9593 - val_loss: 0.9508 - val_accuracy: 0.8340\n",
      "Epoch 217/1000\n",
      "10000/10000 [==============================] - 3s 319us/sample - loss: 0.1057 - accuracy: 0.9635 - val_loss: 0.9875 - val_accuracy: 0.8290\n",
      "Epoch 218/1000\n",
      "10000/10000 [==============================] - 3s 318us/sample - loss: 0.0996 - accuracy: 0.9633 - val_loss: 0.9953 - val_accuracy: 0.8300\n",
      "Epoch 219/1000\n",
      "10000/10000 [==============================] - 3s 335us/sample - loss: 0.0936 - accuracy: 0.9625 - val_loss: 0.9598 - val_accuracy: 0.8320\n",
      "Epoch 220/1000\n",
      "10000/10000 [==============================] - 3s 327us/sample - loss: 0.0911 - accuracy: 0.9666 - val_loss: 1.0400 - val_accuracy: 0.8190\n",
      "Epoch 221/1000\n",
      "10000/10000 [==============================] - 3s 344us/sample - loss: 0.0948 - accuracy: 0.9667 - val_loss: 1.1070 - val_accuracy: 0.8150\n",
      "Epoch 222/1000\n",
      "10000/10000 [==============================] - 3s 325us/sample - loss: 0.0982 - accuracy: 0.9695 - val_loss: 0.9815 - val_accuracy: 0.8280\n",
      "Epoch 223/1000\n",
      "10000/10000 [==============================] - 4s 366us/sample - loss: 0.1056 - accuracy: 0.9617 - val_loss: 0.9384 - val_accuracy: 0.8280\n",
      "Epoch 224/1000\n",
      "10000/10000 [==============================] - 3s 319us/sample - loss: 0.0974 - accuracy: 0.9647 - val_loss: 0.9376 - val_accuracy: 0.8290\n",
      "Epoch 225/1000\n",
      "10000/10000 [==============================] - 3s 346us/sample - loss: 0.1025 - accuracy: 0.9640 - val_loss: 0.9753 - val_accuracy: 0.8200\n",
      "Epoch 226/1000\n",
      "10000/10000 [==============================] - 3s 330us/sample - loss: 0.0945 - accuracy: 0.9659 - val_loss: 0.9710 - val_accuracy: 0.8390\n",
      "Epoch 227/1000\n",
      "10000/10000 [==============================] - 4s 355us/sample - loss: 0.0937 - accuracy: 0.9652 - val_loss: 0.9618 - val_accuracy: 0.8310\n",
      "Epoch 228/1000\n",
      "10000/10000 [==============================] - 3s 336us/sample - loss: 0.0945 - accuracy: 0.9651 - val_loss: 0.9803 - val_accuracy: 0.8270\n",
      "Epoch 229/1000\n",
      "10000/10000 [==============================] - 4s 373us/sample - loss: 0.0933 - accuracy: 0.9681 - val_loss: 0.9939 - val_accuracy: 0.8240\n",
      "Epoch 230/1000\n",
      "10000/10000 [==============================] - 3s 328us/sample - loss: 0.0942 - accuracy: 0.9681 - val_loss: 1.0629 - val_accuracy: 0.8380\n",
      "Epoch 231/1000\n",
      "10000/10000 [==============================] - 3s 309us/sample - loss: 0.0894 - accuracy: 0.9683 - val_loss: 0.9852 - val_accuracy: 0.8340\n",
      "Epoch 232/1000\n",
      "10000/10000 [==============================] - 3s 346us/sample - loss: 0.0907 - accuracy: 0.9680 - val_loss: 1.0731 - val_accuracy: 0.8320\n",
      "Epoch 233/1000\n",
      "10000/10000 [==============================] - 3s 273us/sample - loss: 0.0897 - accuracy: 0.9700 - val_loss: 1.0441 - val_accuracy: 0.8280\n",
      "Epoch 234/1000\n",
      "10000/10000 [==============================] - 3s 287us/sample - loss: 0.0863 - accuracy: 0.9696 - val_loss: 1.0466 - val_accuracy: 0.8290\n",
      "Epoch 235/1000\n",
      "10000/10000 [==============================] - 3s 260us/sample - loss: 0.0947 - accuracy: 0.9679 - val_loss: 1.0162 - val_accuracy: 0.8340\n",
      "Epoch 236/1000\n",
      "10000/10000 [==============================] - 2s 243us/sample - loss: 0.0953 - accuracy: 0.9668 - val_loss: 1.0630 - val_accuracy: 0.8330\n",
      "Epoch 237/1000\n",
      "10000/10000 [==============================] - 2s 239us/sample - loss: 0.0901 - accuracy: 0.9670 - val_loss: 0.9723 - val_accuracy: 0.8340\n",
      "Epoch 238/1000\n",
      "10000/10000 [==============================] - 2s 234us/sample - loss: 0.0844 - accuracy: 0.9707 - val_loss: 1.0633 - val_accuracy: 0.8280\n",
      "Epoch 239/1000\n",
      "10000/10000 [==============================] - 2s 235us/sample - loss: 0.0832 - accuracy: 0.9721 - val_loss: 1.1216 - val_accuracy: 0.8210\n",
      "Epoch 240/1000\n",
      "10000/10000 [==============================] - 3s 277us/sample - loss: 0.0880 - accuracy: 0.9691 - val_loss: 1.0544 - val_accuracy: 0.8200\n",
      "Epoch 241/1000\n",
      "10000/10000 [==============================] - 2s 239us/sample - loss: 0.0930 - accuracy: 0.9683 - val_loss: 1.0811 - val_accuracy: 0.8290\n",
      "Epoch 242/1000\n",
      "10000/10000 [==============================] - 2s 240us/sample - loss: 0.0963 - accuracy: 0.9683 - val_loss: 0.9647 - val_accuracy: 0.8230\n",
      "Epoch 243/1000\n",
      "10000/10000 [==============================] - 2s 243us/sample - loss: 0.0843 - accuracy: 0.9694 - val_loss: 0.9873 - val_accuracy: 0.8300\n",
      "Epoch 244/1000\n",
      "10000/10000 [==============================] - 3s 263us/sample - loss: 0.0850 - accuracy: 0.9710 - val_loss: 1.0562 - val_accuracy: 0.8310\n",
      "Epoch 245/1000\n",
      "10000/10000 [==============================] - 3s 255us/sample - loss: 0.0855 - accuracy: 0.9722 - val_loss: 1.0517 - val_accuracy: 0.8310\n",
      "Epoch 246/1000\n",
      "10000/10000 [==============================] - 3s 264us/sample - loss: 0.0817 - accuracy: 0.9720 - val_loss: 1.0985 - val_accuracy: 0.8280\n",
      "Epoch 247/1000\n",
      "10000/10000 [==============================] - 2s 232us/sample - loss: 0.0864 - accuracy: 0.9703 - val_loss: 0.9872 - val_accuracy: 0.8360\n",
      "Epoch 248/1000\n",
      "10000/10000 [==============================] - 2s 244us/sample - loss: 0.0857 - accuracy: 0.9699 - val_loss: 1.0092 - val_accuracy: 0.8380\n",
      "Epoch 249/1000\n",
      "10000/10000 [==============================] - 3s 255us/sample - loss: 0.0796 - accuracy: 0.9724 - val_loss: 1.0506 - val_accuracy: 0.8350\n",
      "Epoch 250/1000\n",
      "10000/10000 [==============================] - 2s 236us/sample - loss: 0.0861 - accuracy: 0.9718 - val_loss: 1.0176 - val_accuracy: 0.8280\n",
      "Epoch 251/1000\n",
      "10000/10000 [==============================] - 2s 224us/sample - loss: 0.0793 - accuracy: 0.9711 - val_loss: 1.0801 - val_accuracy: 0.8220\n",
      "Epoch 252/1000\n",
      "10000/10000 [==============================] - 3s 257us/sample - loss: 0.0884 - accuracy: 0.9691 - val_loss: 0.9448 - val_accuracy: 0.8260\n",
      "Epoch 253/1000\n",
      "10000/10000 [==============================] - 2s 244us/sample - loss: 0.0824 - accuracy: 0.9720 - val_loss: 1.0223 - val_accuracy: 0.8270\n",
      "Epoch 254/1000\n",
      "10000/10000 [==============================] - 2s 237us/sample - loss: 0.0764 - accuracy: 0.9711 - val_loss: 1.1244 - val_accuracy: 0.8250\n",
      "Epoch 255/1000\n",
      "10000/10000 [==============================] - 2s 231us/sample - loss: 0.0826 - accuracy: 0.9714 - val_loss: 1.1097 - val_accuracy: 0.8170\n",
      "Epoch 256/1000\n",
      "10000/10000 [==============================] - 2s 232us/sample - loss: 0.0770 - accuracy: 0.9722 - val_loss: 1.1259 - val_accuracy: 0.8220\n",
      "Epoch 257/1000\n",
      "10000/10000 [==============================] - 2s 239us/sample - loss: 0.0762 - accuracy: 0.9736 - val_loss: 1.1624 - val_accuracy: 0.8230\n",
      "Epoch 258/1000\n",
      "10000/10000 [==============================] - 2s 239us/sample - loss: 0.0787 - accuracy: 0.9743 - val_loss: 1.0391 - val_accuracy: 0.8310\n",
      "Epoch 259/1000\n",
      "10000/10000 [==============================] - 3s 323us/sample - loss: 0.0822 - accuracy: 0.9732 - val_loss: 1.0418 - val_accuracy: 0.8290\n",
      "Epoch 260/1000\n",
      "10000/10000 [==============================] - 3s 268us/sample - loss: 0.0834 - accuracy: 0.9731 - val_loss: 1.1456 - val_accuracy: 0.8180\n",
      "Epoch 261/1000\n",
      "10000/10000 [==============================] - 3s 284us/sample - loss: 0.0841 - accuracy: 0.9717 - val_loss: 1.0421 - val_accuracy: 0.8250\n",
      "Epoch 262/1000\n",
      "10000/10000 [==============================] - 4s 415us/sample - loss: 0.0806 - accuracy: 0.9732 - val_loss: 1.0930 - val_accuracy: 0.8260\n",
      "Epoch 263/1000\n",
      "10000/10000 [==============================] - 4s 357us/sample - loss: 0.0748 - accuracy: 0.9752 - val_loss: 1.0942 - val_accuracy: 0.8240\n",
      "Epoch 264/1000\n",
      "10000/10000 [==============================] - 3s 277us/sample - loss: 0.0801 - accuracy: 0.9723 - val_loss: 1.1575 - val_accuracy: 0.8310\n",
      "Epoch 265/1000\n",
      "10000/10000 [==============================] - 2s 246us/sample - loss: 0.0774 - accuracy: 0.9734 - val_loss: 1.1567 - val_accuracy: 0.8280\n",
      "Epoch 266/1000\n",
      "10000/10000 [==============================] - 3s 257us/sample - loss: 0.0826 - accuracy: 0.9735 - val_loss: 1.0584 - val_accuracy: 0.8330\n",
      "Epoch 267/1000\n",
      "10000/10000 [==============================] - 2s 238us/sample - loss: 0.0754 - accuracy: 0.9716 - val_loss: 1.2093 - val_accuracy: 0.8240\n",
      "Epoch 268/1000\n",
      "10000/10000 [==============================] - 3s 268us/sample - loss: 0.0791 - accuracy: 0.9741 - val_loss: 1.0835 - val_accuracy: 0.8190\n",
      "Epoch 269/1000\n",
      "10000/10000 [==============================] - 3s 283us/sample - loss: 0.0742 - accuracy: 0.9760 - val_loss: 1.1328 - val_accuracy: 0.8320\n",
      "Epoch 270/1000\n",
      "10000/10000 [==============================] - 3s 252us/sample - loss: 0.0767 - accuracy: 0.9758 - val_loss: 1.0472 - val_accuracy: 0.8210\n",
      "Epoch 271/1000\n",
      "10000/10000 [==============================] - 3s 302us/sample - loss: 0.0669 - accuracy: 0.9773 - val_loss: 1.1975 - val_accuracy: 0.8220\n",
      "Epoch 272/1000\n",
      "10000/10000 [==============================] - 3s 338us/sample - loss: 0.0784 - accuracy: 0.9746 - val_loss: 1.1489 - val_accuracy: 0.8150\n",
      "Epoch 273/1000\n",
      "10000/10000 [==============================] - 3s 276us/sample - loss: 0.0711 - accuracy: 0.9751 - val_loss: 1.1925 - val_accuracy: 0.8250\n",
      "Epoch 274/1000\n",
      "10000/10000 [==============================] - 3s 292us/sample - loss: 0.0872 - accuracy: 0.9719 - val_loss: 1.1344 - val_accuracy: 0.8380\n",
      "Epoch 275/1000\n",
      "10000/10000 [==============================] - 3s 270us/sample - loss: 0.0774 - accuracy: 0.9760 - val_loss: 1.0898 - val_accuracy: 0.8220\n",
      "Epoch 276/1000\n",
      "10000/10000 [==============================] - 2s 245us/sample - loss: 0.0736 - accuracy: 0.9776 - val_loss: 1.1636 - val_accuracy: 0.8230\n",
      "Epoch 277/1000\n",
      "10000/10000 [==============================] - 2s 249us/sample - loss: 0.0763 - accuracy: 0.9737 - val_loss: 1.0922 - val_accuracy: 0.8290\n",
      "Epoch 278/1000\n",
      "10000/10000 [==============================] - 2s 247us/sample - loss: 0.0733 - accuracy: 0.9768 - val_loss: 1.1476 - val_accuracy: 0.8280\n",
      "Epoch 279/1000\n",
      "10000/10000 [==============================] - 3s 292us/sample - loss: 0.0675 - accuracy: 0.9766 - val_loss: 1.2092 - val_accuracy: 0.8340\n",
      "Epoch 280/1000\n",
      "10000/10000 [==============================] - 3s 336us/sample - loss: 0.0694 - accuracy: 0.9782 - val_loss: 1.1295 - val_accuracy: 0.8270\n",
      "Epoch 281/1000\n",
      "10000/10000 [==============================] - 3s 277us/sample - loss: 0.0726 - accuracy: 0.9756 - val_loss: 1.1898 - val_accuracy: 0.8230\n",
      "Epoch 282/1000\n",
      "10000/10000 [==============================] - 3s 255us/sample - loss: 0.0732 - accuracy: 0.9754 - val_loss: 1.1369 - val_accuracy: 0.8210\n",
      "Epoch 283/1000\n",
      "10000/10000 [==============================] - 3s 251us/sample - loss: 0.0712 - accuracy: 0.9749 - val_loss: 1.1837 - val_accuracy: 0.8230\n",
      "Epoch 284/1000\n",
      "10000/10000 [==============================] - 3s 250us/sample - loss: 0.0723 - accuracy: 0.9772 - val_loss: 1.2083 - val_accuracy: 0.8260\n",
      "Epoch 285/1000\n",
      "10000/10000 [==============================] - 2s 250us/sample - loss: 0.0737 - accuracy: 0.9771 - val_loss: 1.1570 - val_accuracy: 0.8230\n",
      "Epoch 286/1000\n",
      "10000/10000 [==============================] - 2s 249us/sample - loss: 0.0767 - accuracy: 0.9760 - val_loss: 1.1247 - val_accuracy: 0.8260\n",
      "Epoch 287/1000\n",
      "10000/10000 [==============================] - 3s 257us/sample - loss: 0.0716 - accuracy: 0.9774 - val_loss: 1.2702 - val_accuracy: 0.8060\n",
      "Epoch 288/1000\n",
      "10000/10000 [==============================] - 3s 259us/sample - loss: 0.0620 - accuracy: 0.9784 - val_loss: 1.2698 - val_accuracy: 0.8160\n",
      "Epoch 289/1000\n",
      "10000/10000 [==============================] - 3s 262us/sample - loss: 0.0668 - accuracy: 0.9781 - val_loss: 1.1511 - val_accuracy: 0.8260\n",
      "Epoch 290/1000\n",
      "10000/10000 [==============================] - 3s 298us/sample - loss: 0.0739 - accuracy: 0.9777 - val_loss: 1.1427 - val_accuracy: 0.8220\n",
      "Epoch 291/1000\n",
      "10000/10000 [==============================] - 3s 307us/sample - loss: 0.0642 - accuracy: 0.9778 - val_loss: 1.2437 - val_accuracy: 0.8250\n",
      "Epoch 292/1000\n",
      "10000/10000 [==============================] - 3s 274us/sample - loss: 0.0707 - accuracy: 0.9786 - val_loss: 1.1942 - val_accuracy: 0.8210\n",
      "Epoch 293/1000\n",
      "10000/10000 [==============================] - 3s 269us/sample - loss: 0.0724 - accuracy: 0.9780 - val_loss: 1.1906 - val_accuracy: 0.8160\n",
      "Epoch 294/1000\n",
      "10000/10000 [==============================] - 2s 226us/sample - loss: 0.0676 - accuracy: 0.9778 - val_loss: 1.2523 - val_accuracy: 0.8210\n",
      "Epoch 295/1000\n",
      "10000/10000 [==============================] - 2s 237us/sample - loss: 0.0677 - accuracy: 0.9797 - val_loss: 1.2081 - val_accuracy: 0.8160\n",
      "Epoch 296/1000\n",
      "10000/10000 [==============================] - 2s 233us/sample - loss: 0.0684 - accuracy: 0.9788 - val_loss: 1.2371 - val_accuracy: 0.8230\n",
      "Epoch 297/1000\n",
      "10000/10000 [==============================] - 3s 272us/sample - loss: 0.0643 - accuracy: 0.9805 - val_loss: 1.3584 - val_accuracy: 0.8220\n",
      "Epoch 298/1000\n",
      "10000/10000 [==============================] - 3s 251us/sample - loss: 0.0681 - accuracy: 0.9791 - val_loss: 1.2010 - val_accuracy: 0.8200\n",
      "Epoch 299/1000\n",
      "10000/10000 [==============================] - 3s 257us/sample - loss: 0.0660 - accuracy: 0.9794 - val_loss: 1.1852 - val_accuracy: 0.8280\n",
      "Epoch 300/1000\n",
      "10000/10000 [==============================] - 3s 258us/sample - loss: 0.0619 - accuracy: 0.9800 - val_loss: 1.1843 - val_accuracy: 0.8220\n",
      "Epoch 301/1000\n",
      "10000/10000 [==============================] - 3s 260us/sample - loss: 0.0691 - accuracy: 0.9762 - val_loss: 1.1394 - val_accuracy: 0.8220\n",
      "Epoch 302/1000\n",
      "10000/10000 [==============================] - 3s 320us/sample - loss: 0.0607 - accuracy: 0.9816 - val_loss: 1.2435 - val_accuracy: 0.8140\n",
      "Epoch 303/1000\n",
      "10000/10000 [==============================] - 3s 266us/sample - loss: 0.0655 - accuracy: 0.9783 - val_loss: 1.2299 - val_accuracy: 0.8200\n",
      "Epoch 304/1000\n",
      "10000/10000 [==============================] - 3s 271us/sample - loss: 0.0678 - accuracy: 0.9798 - val_loss: 1.1414 - val_accuracy: 0.8230\n",
      "Epoch 305/1000\n",
      "10000/10000 [==============================] - 3s 260us/sample - loss: 0.0638 - accuracy: 0.9797 - val_loss: 1.2204 - val_accuracy: 0.8240\n",
      "Epoch 306/1000\n",
      "10000/10000 [==============================] - 2s 233us/sample - loss: 0.0623 - accuracy: 0.9814 - val_loss: 1.3321 - val_accuracy: 0.8160\n",
      "Epoch 307/1000\n",
      "10000/10000 [==============================] - 2s 237us/sample - loss: 0.0613 - accuracy: 0.9813 - val_loss: 1.2159 - val_accuracy: 0.8200\n",
      "Epoch 308/1000\n",
      "10000/10000 [==============================] - 3s 274us/sample - loss: 0.0750 - accuracy: 0.9774 - val_loss: 1.1853 - val_accuracy: 0.8180\n",
      "Epoch 309/1000\n",
      "10000/10000 [==============================] - 3s 260us/sample - loss: 0.0665 - accuracy: 0.9789 - val_loss: 1.2000 - val_accuracy: 0.8170\n",
      "Epoch 310/1000\n",
      "10000/10000 [==============================] - 2s 242us/sample - loss: 0.0569 - accuracy: 0.9794 - val_loss: 1.2549 - val_accuracy: 0.8220\n",
      "Epoch 311/1000\n",
      "10000/10000 [==============================] - 2s 245us/sample - loss: 0.0604 - accuracy: 0.9805 - val_loss: 1.2301 - val_accuracy: 0.8230\n",
      "Epoch 312/1000\n",
      "10000/10000 [==============================] - 3s 256us/sample - loss: 0.0662 - accuracy: 0.9785 - val_loss: 1.2552 - val_accuracy: 0.8210\n",
      "Epoch 313/1000\n",
      "10000/10000 [==============================] - 3s 260us/sample - loss: 0.0600 - accuracy: 0.9800 - val_loss: 1.3307 - val_accuracy: 0.8220\n",
      "Epoch 314/1000\n",
      "10000/10000 [==============================] - 3s 292us/sample - loss: 0.0655 - accuracy: 0.9806 - val_loss: 1.2098 - val_accuracy: 0.8260\n",
      "Epoch 315/1000\n",
      "10000/10000 [==============================] - 3s 265us/sample - loss: 0.0623 - accuracy: 0.9803 - val_loss: 1.2945 - val_accuracy: 0.8230\n",
      "Epoch 316/1000\n",
      "10000/10000 [==============================] - 3s 264us/sample - loss: 0.0543 - accuracy: 0.9816 - val_loss: 1.3070 - val_accuracy: 0.8200\n",
      "Epoch 317/1000\n",
      "10000/10000 [==============================] - 3s 268us/sample - loss: 0.0614 - accuracy: 0.9817 - val_loss: 1.3100 - val_accuracy: 0.8120\n",
      "Epoch 318/1000\n",
      "10000/10000 [==============================] - 3s 263us/sample - loss: 0.0622 - accuracy: 0.9803 - val_loss: 1.1674 - val_accuracy: 0.8180\n",
      "Epoch 319/1000\n",
      "10000/10000 [==============================] - 3s 274us/sample - loss: 0.0584 - accuracy: 0.9813 - val_loss: 1.3870 - val_accuracy: 0.8180\n",
      "Epoch 320/1000\n",
      "10000/10000 [==============================] - 3s 289us/sample - loss: 0.0588 - accuracy: 0.9826 - val_loss: 1.2969 - val_accuracy: 0.8140\n",
      "Epoch 321/1000\n",
      "10000/10000 [==============================] - 3s 267us/sample - loss: 0.0689 - accuracy: 0.9782 - val_loss: 1.1922 - val_accuracy: 0.8160\n",
      "Epoch 322/1000\n",
      "10000/10000 [==============================] - 3s 256us/sample - loss: 0.0557 - accuracy: 0.9820 - val_loss: 1.2687 - val_accuracy: 0.8220\n",
      "Epoch 323/1000\n",
      "10000/10000 [==============================] - 3s 269us/sample - loss: 0.0659 - accuracy: 0.9786 - val_loss: 1.2173 - val_accuracy: 0.8160\n",
      "Epoch 324/1000\n",
      "10000/10000 [==============================] - 3s 264us/sample - loss: 0.0564 - accuracy: 0.9814 - val_loss: 1.3450 - val_accuracy: 0.8140\n",
      "Epoch 325/1000\n",
      "10000/10000 [==============================] - 3s 275us/sample - loss: 0.0627 - accuracy: 0.9803 - val_loss: 1.2455 - val_accuracy: 0.8250\n",
      "Epoch 326/1000\n",
      "10000/10000 [==============================] - 3s 254us/sample - loss: 0.0654 - accuracy: 0.9809 - val_loss: 1.2284 - val_accuracy: 0.8160\n",
      "Epoch 327/1000\n",
      "10000/10000 [==============================] - 2s 240us/sample - loss: 0.0619 - accuracy: 0.9806 - val_loss: 1.3476 - val_accuracy: 0.8160\n",
      "Epoch 328/1000\n",
      "10000/10000 [==============================] - 3s 254us/sample - loss: 0.0621 - accuracy: 0.9820 - val_loss: 1.2625 - val_accuracy: 0.8160\n",
      "Epoch 329/1000\n",
      "10000/10000 [==============================] - 3s 269us/sample - loss: 0.0524 - accuracy: 0.9834 - val_loss: 1.3719 - val_accuracy: 0.8150\n",
      "Epoch 330/1000\n",
      "10000/10000 [==============================] - 3s 275us/sample - loss: 0.0642 - accuracy: 0.9822 - val_loss: 1.3832 - val_accuracy: 0.8250\n",
      "Epoch 331/1000\n",
      "10000/10000 [==============================] - 3s 300us/sample - loss: 0.0655 - accuracy: 0.9811 - val_loss: 1.3287 - val_accuracy: 0.8090\n",
      "Epoch 332/1000\n",
      "10000/10000 [==============================] - 3s 321us/sample - loss: 0.0552 - accuracy: 0.9834 - val_loss: 1.3610 - val_accuracy: 0.8220\n",
      "Epoch 333/1000\n",
      "10000/10000 [==============================] - 3s 284us/sample - loss: 0.0659 - accuracy: 0.9810 - val_loss: 1.2785 - val_accuracy: 0.8180\n",
      "Epoch 334/1000\n",
      "10000/10000 [==============================] - 3s 274us/sample - loss: 0.0598 - accuracy: 0.9824 - val_loss: 1.3169 - val_accuracy: 0.8150\n",
      "Epoch 335/1000\n",
      "10000/10000 [==============================] - 3s 262us/sample - loss: 0.0623 - accuracy: 0.9805 - val_loss: 1.2637 - val_accuracy: 0.8130\n",
      "Epoch 336/1000\n",
      "10000/10000 [==============================] - 3s 276us/sample - loss: 0.0652 - accuracy: 0.9796 - val_loss: 1.2537 - val_accuracy: 0.8160\n",
      "Epoch 337/1000\n",
      "10000/10000 [==============================] - 3s 258us/sample - loss: 0.0571 - accuracy: 0.9814 - val_loss: 1.3432 - val_accuracy: 0.8150\n",
      "Epoch 338/1000\n",
      "10000/10000 [==============================] - 2s 246us/sample - loss: 0.0642 - accuracy: 0.9796 - val_loss: 1.4446 - val_accuracy: 0.8160\n",
      "Epoch 339/1000\n",
      "10000/10000 [==============================] - 2s 239us/sample - loss: 0.0650 - accuracy: 0.9797 - val_loss: 1.2415 - val_accuracy: 0.8210\n",
      "Epoch 340/1000\n",
      "10000/10000 [==============================] - 2s 244us/sample - loss: 0.0599 - accuracy: 0.9816 - val_loss: 1.2371 - val_accuracy: 0.8180\n",
      "Epoch 341/1000\n",
      "10000/10000 [==============================] - 2s 242us/sample - loss: 0.0588 - accuracy: 0.9834 - val_loss: 1.2384 - val_accuracy: 0.8220\n",
      "Epoch 342/1000\n",
      "10000/10000 [==============================] - 3s 295us/sample - loss: 0.0544 - accuracy: 0.9845 - val_loss: 1.3161 - val_accuracy: 0.8190\n",
      "Epoch 343/1000\n",
      "10000/10000 [==============================] - 3s 250us/sample - loss: 0.0604 - accuracy: 0.9840 - val_loss: 1.3130 - val_accuracy: 0.8150\n",
      "Epoch 344/1000\n",
      "10000/10000 [==============================] - 3s 254us/sample - loss: 0.0608 - accuracy: 0.9812 - val_loss: 1.3751 - val_accuracy: 0.8230\n",
      "Epoch 345/1000\n",
      "10000/10000 [==============================] - 3s 262us/sample - loss: 0.0613 - accuracy: 0.9814 - val_loss: 1.2885 - val_accuracy: 0.8150\n",
      "Epoch 346/1000\n",
      "10000/10000 [==============================] - 3s 279us/sample - loss: 0.0554 - accuracy: 0.9824 - val_loss: 1.2194 - val_accuracy: 0.8130\n",
      "Epoch 347/1000\n",
      "10000/10000 [==============================] - 3s 296us/sample - loss: 0.0619 - accuracy: 0.9805 - val_loss: 1.2038 - val_accuracy: 0.8200\n",
      "Epoch 348/1000\n",
      "10000/10000 [==============================] - 3s 312us/sample - loss: 0.0640 - accuracy: 0.9833 - val_loss: 1.2431 - val_accuracy: 0.8190\n",
      "Epoch 349/1000\n",
      "10000/10000 [==============================] - 3s 274us/sample - loss: 0.0532 - accuracy: 0.9830 - val_loss: 1.2822 - val_accuracy: 0.8180\n",
      "Epoch 350/1000\n",
      "10000/10000 [==============================] - 3s 332us/sample - loss: 0.0606 - accuracy: 0.9815 - val_loss: 1.2912 - val_accuracy: 0.8190\n",
      "Epoch 351/1000\n",
      "10000/10000 [==============================] - 3s 336us/sample - loss: 0.0489 - accuracy: 0.9850 - val_loss: 1.4460 - val_accuracy: 0.8210\n",
      "Epoch 352/1000\n",
      "10000/10000 [==============================] - 3s 344us/sample - loss: 0.0557 - accuracy: 0.9813 - val_loss: 1.4046 - val_accuracy: 0.8230\n",
      "Epoch 353/1000\n",
      "10000/10000 [==============================] - 3s 344us/sample - loss: 0.0662 - accuracy: 0.9834 - val_loss: 1.1942 - val_accuracy: 0.8170\n",
      "Epoch 354/1000\n",
      "10000/10000 [==============================] - 3s 327us/sample - loss: 0.0520 - accuracy: 0.9828 - val_loss: 1.2820 - val_accuracy: 0.8200\n",
      "Epoch 355/1000\n",
      " 7776/10000 [======================>.......] - ETA: 0s - loss: 0.0607 - accuracy: 0.9816"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-d8db7d056ce4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mquestions_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0manswers_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mquestions_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0manswers_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit([inputs_train,questions_train],answers_train, batch_size = 32, epochs = 1000, validation_data = ([inputs_test,questions_test],answers_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Z_chatbot_100_epochs.h5'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtQAAALJCAYAAACUZbS1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3Xd4leX9x/H3nZO9J4EkkJCwCXuDICIbt9a6a63iqHX8HHWvqrVad121WmvdWidDEBVBhuy9RyCBJJC99/P745w85JAwBJIQ8nldV68+51nneyLoJ/f5PvdtLMtCRERERESOjUdzFyAiIiIi0pIpUIuIiIiIHAcFahERERGR46BALSIiIiJyHBSoRURERESOgwK1iIiIiMhxUKAWETkJGGPeMcY8fpTnphhjxjZ2TSIicnQUqEVEREREjoMCtYiInDDGGM/mrkFEpKkpUIuIHCVXq8Vdxpg1xphiY8xbxphoY8xMY0yhMWaOMSaszvnnGGPWG2PyjDFzjTHd6xzrZ4xZ4bruY8D3oPc6yxizynXtQmNM76OscYoxZqUxpsAYk2qMeeSg46e57pfnOn61a7+fMeZZY8wuY0y+MeZn177Rxpi0Bn4OY13bjxhjPjPGvGeMKQCuNsYMNsYscr1HujHmH8YY7zrX9zTGfGeMyTHGZBpj7jPGtDXGlBhjIuqcN8AYs98Y43U0n11EpLkoUIuI/DoXAuOALsDZwEzgPiAS579TbwEwxnQBPgRuA6KAGcA3xhhvV7j8EvgvEA586rovrmv7A28D1wMRwBvA18YYn6Oorxi4CggFpgA3GmPOc923g6vel1019QVWua77OzAAGO6q6W6g5ih/JucCn7ne832gGrjd9TMZBpwJ3OSqIQiYA3wLxACdgO8ty8oA5gIX17nvFcBHlmVVHmUdIiLNQoFaROTXedmyrEzLsvYA84FfLMtaaVlWOfAF0M913m+B6ZZlfecKhH8H/HAG1qGAF/CCZVmVlmV9Biyt8x7XAW9YlvWLZVnVlmX9Byh3XXdYlmXNtSxrrWVZNZZlrcEZ6k93Hb4cmGNZ1oeu9822LGuVMcYDuAa41bKsPa73XOj6TEdjkWVZX7res9SyrOWWZS22LKvKsqwUnL8Q1NZwFpBhWdazlmWVWZZVaFnWL65j/8EZojHGOIBLcf7SISJyUlOgFhH5dTLrbJc28DrQtR0D7Ko9YFlWDZAKxLqO7bEsy6pz7a462/HAHa6WiTxjTB7Q3nXdYRljhhhjfnS1SuQDN+AcKcZ1j+0NXBaJs+WkoWNHI/WgGroYY6YZYzJcbSBPHkUNAF8BPYwxiTi/Bci3LGvJMdYkItJkFKhFRBrHXpzBGABjjMEZJvcA6UCsa1+tDnW2U4EnLMsKrfM/f8uyPjyK9/0A+Bpob1lWCPA6UPs+qUBSA9dkAWWHOFYM+Nf5HA6c7SJ1WQe9fg3YBHS2LCsYZ0vMkWrAsqwy4BOcI+lXotFpEWkhFKhFRBrHJ8AUY8yZrofq7sDZtrEQWARUAbcYYzyNMRcAg+tc+yZwg2u02RhjAlwPGwYdxfsGATmWZZUZYwYDl9U59j4w1hhzset9I4wxfV2j528DzxljYowxDmPMMFfP9hbA1/X+XsADwJF6uYOAAqDIGNMNuLHOsWlAW2PMbcYYH2NMkDFmSJ3j7wJXA+cA7x3F5xURaXYK1CIijcCyrM04+4FfxjkCfDZwtmVZFZZlVQAX4AyOuTj7rT+vc+0ynH3U/3Ad3+Y692jcBDxmjCkEHsIZ7GvvuxuYjDPc5+B8ILGP6/CdwFqcvdw5wN8AD8uy8l33/BfO0fViwG3WjwbciTPIF+L85eDjOjUU4mznOBvIALYCZ9Q5vgDnw5ArXP3XIiInPePewiciItK8jDE/AB9YlvWv5q5FRORoKFCLiMhJwxgzCPgOZw94YXPXIyJyNNTyISIiJwVjzH9wzlF9m8K0iLQkGqEWERERETkOGqEWERERETkOns1dwK8VGRlpJSQkNHcZIiIiInKKW758eZZlWQfPvV9PiwvUCQkJLFu2rLnLEBEREZFTnDFm15HPUsuHiIiIiMhxUaAWERERETkOCtQiIiIiIsehxfVQN6SyspK0tDTKysqau5RG5evrS1xcHF5eXs1dioiIiIi4nBKBOi0tjaCgIBISEjDGNHc5jcKyLLKzs0lLS6Njx47NXY6IiIiIuJwSLR9lZWVEREScsmEawBhDRETEKT8KLyIiItLSnBKBGjilw3St1vAZRURERFqaUyZQi4iIiIg0BwXqEyAvL49XX331V183efJk8vLyGqEiEREREWkqCtQnwKECdXV19WGvmzFjBqGhoY1VloiIiIg0gVNilo/mds8997B9+3b69u2Ll5cXgYGBtGvXjlWrVrFhwwbOO+88UlNTKSsr49Zbb2Xq1KnAgWXUi4qKmDRpEqeddhoLFy4kNjaWr776Cj8/v2b+ZCIiIiJyJKdcoH70m/Vs2FtwQu/ZIyaYh8/uecjjTz31FOvWrWPVqlXMnTuXKVOmsG7dOnt6u7fffpvw8HBKS0sZNGgQF154IREREW732Lp1Kx9++CFvvvkmF198Mf/73/+44oorTujnEBEREZET75QL1CeDwYMHu80V/dJLL/HFF18AkJqaytatW+sF6o4dO9K3b18ABgwYQEpKSpPVKyIiIiLHrtECtTHmbeAsYJ9lWckNHDfAi8BkoAS42rKsFcf7vocbSW4qAQEB9vbcuXOZM2cOixYtwt/fn9GjRzc4l7SPj4+97XA4KC0tbZJaRUREROT4NOZDie8AEw9zfBLQ2fW/qcBrjVhLowoKCqKwsLDBY/n5+YSFheHv78+mTZtYvHhxE1cnIiIiIo2p0UaoLcuaZ4xJOMwp5wLvWpZlAYuNMaHGmHaWZaU3Vk2NJSIighEjRpCcnIyfnx/R0dH2sYkTJ/L666/Tu3dvunbtytChQ5uxUhERERE50ZqzhzoWSK3zOs21r16gNsZMxTmKTYcOHZqkuF/rgw8+aHC/j48PM2fObPBYbZ90ZGQk69ats/ffeeedJ7w+EREREWkczTkPdUPraFsNnWhZ1j8tyxpoWdbAqKioRi5LREREROToNWegTgPa13kdB+xtplpERERERI5Jcwbqr4GrjNNQIL8l9k+LiIiISOvWmNPmfQiMBiKNMWnAw4AXgGVZrwMzcE6Ztw3ntHm/b6xaREREREQaS2PO8nHpEY5bwB8b6/1FRERERJpCc7Z8iIiIiIi0eArUJ0BeXh6vvvrqMV37wgsvUFJScoIrEhEREZGmokB9AihQi4iIiLRezbmwyynjnnvuYfv27fTt25dx48bRpk0bPvnkE8rLyzn//PN59NFHKS4u5uKLLyYtLY3q6moefPBBMjMz2bt3L2eccQaRkZH8+OOPzf1RRERERORXOvUC9cx7IGPtib1n214w6alDHn7qqadYt24dq1atYvbs2Xz22WcsWbIEy7I455xzmDdvHvv37ycmJobp06cDkJ+fT0hICM899xw//vgjkZGRJ7ZmEREREWkSavk4wWbPns3s2bPp168f/fv3Z9OmTWzdupVevXoxZ84c/vznPzN//nxCQkKau1QRERFpQFllNc99t4Xi8qrmLkVaiFNvhPowI8lNwbIs7r33Xq6//vp6x5YvX86MGTO49957GT9+PA899FAzVCgiIiKH88Evu3np+614Oww3j+l8Qu/95rwd7Mgq5q8X9Dqh9wWoqq6hpLKaYF+vE3K/8qpqtmYWkRx7+EFAy7Iwxvzq+xeWVfLuol2c0yeG9uH+bM4opH24H/7eLS+eaoT6BAgKCqKwsBCACRMm8Pbbb1NUVATAnj172LdvH3v37sXf358rrriCO++8kxUrVtS7VkRERJpfZmEZAOVVNSf83k/M2MiHS3ZTXWOd8Hs/9PV6ej8ym8rqGv45bzsZ+c7PYVkWucUV7C8s574v1rJydy4AT3+7iYXbs5i2Zi+FZZUA5JdWUuOq7bnvtnDWyz/T+f4ZbN/vzDVV1TUUuM4FmLk2nR4PzWJ3dgk7s4qZv3W/fX1NjUVJxYFR/ue+28JPW/YDkJ5fyuSX5vPMrM38e0EKxeVVTHhhHtf+Z5ldc2ZBmX2vk13L+xXgJBQREcGIESNITk5m0qRJXHbZZQwbNgyAwMBA3nvvPbZt28Zdd92Fh4cHXl5evPbaawBMnTqVSZMm0a5dOz2UKCIiLVpNjcW36zMY2z0ab8/mHbPbnFFIYlQAXo4Ddcxcm87G9AL+b3xXt3NraiyKK6oIco3s7sktBSC7uOJXv29+aSV5JRXERwQc9rwfNu0jwMfBsMSIYxrdrbUnr5Rd2cUkx4bw6bJUAD5aspsnZ2ziyRmbuGJoB3bnlDJvy35O7xLFT1v2U11tERXkw6tzt/P5ij1kFJQxpVc77p/SneFP/UBsqB+9YkP4dn0GAJXVFh8t2U1xRTX+Xg7+9fNOZt8+CoeH4cb3nQOEa/fkc/+Xa8krqeSVy/rj8IAF27L57+JdXDUsnpvHdOKl77fadQf5elJeVUNiVAAfL93N2wt2ArBwezZ5JRUs2ZnD1P8uZ3TXKP599aDj+hk1BeNcsLDlGDhwoLVs2TK3fRs3bqR79+7NVFHTak2fVUSkqWzNLCQh0j18tUQfLdnNQ1+vZ/2jE+p9lsKySjsw/lrF5VX4ezuOGGreXZTCQ1+t5/HzkrliaDzF5VU8/PV6RnSK4Px+cfZ5abklfLchk6uHJ7C/sJwvVu7hD6d1xPMIP//yqmrWpuXTKy6EymqLxduzWb47l7fm7+SBs7pz1bAE9hWWcfvHq1iwLZsrhnagV2wI6/cW8IfTOnL6M3MB2PHkZDw8nJ+lrLKa+75Yy+cr9rDl8Ul4e3ow5u9z2ZFVTIdwf64Y2oHu7YJZsSuPq4cn8If/LKVnTDCPnNPT7eexaHs23doGceXbv7BuTwHrH51AgI/7uGVVdQ2d7p/ptu/sPjHcPaErDg9DWm4pgzuGU1ZZzafL0xjSMZxOUYE8Nm0DX6/ey/vXDqGiqoZgPy8Kyyp57JsNLNuVe6R/fPUMS4zg7D4x3PeF+yQOXg5DZbV7LhzfI5rZGzKPeM/LhnTgg192A+Dt6UHFQaP7XaOD2Jzp/o38Bf1jiQ314+Uftrnt79M+lE5RgfxvRRoAz13chwv6x9EcjDHLLcsaeKTzNEItIiKtWn5pJeOen8eoLlE8dFZ3kqICT/rRsOLyKjyMwdvTA4fHgVqfnrWZiqoaNqUX0ivuQN/rv+bv4PHpG1ly/5m0CfKtd791e/L5cMluHB6G2FA/hidFEuDjIDEqkGUpOVz0+iLevGogndoE0jHSOfJaWlHNje8v5/cjOtK9bRAPfrWOWeudwSu7qIJd2cV2gF25O5eB8eF8uy6D6WvTWZWaB0BKVjF5pZV8tWovXg4Prjmto1td2/YVsiWziOyicn4zsD0PfLmOz5anMaZbG37YtM/t3I+WpDIxuS1/nbGJBduyAXhv8W77eHiAt7194/vLuXRwB96cv4N1ewrIL3W2MDw/Zwv/nLfDbsfYnVPCkzM22deVVlazbFcuy3blMjQxAj9vB5szChmaGMGlby52q+cP/1nKO78fjK+Xg3s/X8uPm/aRUVBW72f/zeq9eHkYVqXmsSOrmEfO7sHfZ2+hqLyKMd3aMLZ7NO8sTAHg2dmbmbPR+bnP6t3uqMP0GV2j+HGzs9UixM+LJSk5bi0nIztHsmN/MXvySt2u++qPI0iODWHscz+xM6u4wXu3CfKhqLzKDtOAHaZP6xTJ/VO688qP25i2Jr3etUlRgZzfL9YO1O3D/bhzfFdu/WgVq1PzOKNrFMXlzl94Tusc2eCf3ZOFRqhbmNb0WUVEmsK6Pfmc9fLP9uvXr+jPxOR2bufM2ZDJt+sz+Ptv+gDOkVKHMUccUa0rv7QSD8OvGiXOL62koqqGqCAfe9+i7dl2eLtqWDyPnZtsH5v4wjw2ZRTyyNk9uHpER8oqq1m4PYtr3jnw3833/jCEb1bvpai8ipvHdOLcfyygorrhXuHoYB8yC8oB8PNyUFpZzQNTujO+R1ve+2UX/5y3o8HrLuwfx5hubfjjByuO+rP2iQvhq5tPA+CTZanc/dmao7ru9rFd+PfCnUQH+bqNgP73D4O58q0lR/3+B3v18v5s21fE5yvSSMk+sABb93bBFJZVkpZbeshrJ/Zsy7frM/jLeclk5pfxjx/dR2AHdwxn+a5cO9T6eHq49Wv37xDKnrxSaiznz2XrviIuHdyBp2ZucrtPj3bBTO7Vlr/P3mLvO7tPDN+s3gvAfZO78eSMTTx9UW+W7MzB29ODNkE+vDBnq9t9Hjm7B5cPjXfW9sQccksqeenSfpzTJwaA3729xO59BrhxdBKju0Tx238uZlhiBIt2OH+Buf70RFKyipm1PpOhieF8NNXZ/rozq5gLXl3AZUM6MHNtBjtc4fz53/bh/H5x9i+Ivl7Ov083vLecORv38f61Q+gTF8raPfkM7hh+yJ93Y2p1I9TH+oRpS9LSfvkREWlIZkEZ2UUV9IgJ/tXX7skr5T8LU7h7QtdfFWYPJy3XfbXaHQeNxFVV13Dtu85A+sT5yaTnlXH5v36hU5tA/nPNYLdzb/1oJX5eDp66sLfb/vySSgY8/h2eDsPKB8eTWVDGM7M388PGfXx6wzB7FoXakBXq70XHyAAmvzifPXmlpDw1hf2F5ewvLHfrQ3130S5uGt2JGstixtp0NmU4A+Xzc7Yypls0V/97Sb3Pc8Vbv9jbDg9jh+lQfy8uGdSB13/abh+vDdPgHJ0FeHz6Rh6fvvGQP09jYOH2LPvr+oYsf2AsAx6f47ZvY0YhpRXVpOeX8pdpG4D6QfO0TpGc2b0Nj37jPN41OojfDY8no6CMD5fsdrvfgPiweu975/gubuET4DPXz7/bg9/a+544P5nJvZy/VBWXV/FGnV8crh+VyNzN+0jLLWVyr7ZUVVvM3pBJr9gQKqtr6NQmkJcv7cd5ryzg6W83UVjmfChveFIEC7dnM6JTBK9eNoAAH4fd/lH7GUd2jsTb4cHTF/Vm5roMHvhyHXM27uM3A+K4flQi+wrK+WJlGmO6RbO/qJyHzupORZXl9pl8PT345ubTKK6oYkjHcJJjQhiWFMHFA9s7f87pBbw1fyeF5VU8fl4y87fu58IBcXaLUG3SiAvzs+/ZMybYLVAnRQUyID6Mm0YncdmQDlz42kIyC8q5Y1xX5m3Zz6z1mW7fCHSMDGDZA+NweBjumtCNbg/OpKyyhpgQ53sc3Brzj8v6k1tSYY9IN1eY/jVOiUDt6+tLdnY2ERHH19h/MrMsi+zsbHx9T96vO0Sk9fj7rM0kRgUcU1/jyL/9SEV1DSlPTal3bHVqHr/95yJ+vHM07UL86h2/7/O1/LRlP/sKynjygl7HPL3Wv+bvoLyqhj+e0emQI42V1TV4OTy4+I1F9r6lO3PtQLonr5RnZ2/GsuD/xnXBGPhqlXNk8K8X9KKy2uL5OVvo1jaIWz9aBUBVjcWG9AKenb2Zhdudo3pnvfwzf72gFxf2j+PC1xY2WEthWSXnvbKg3lfyAEP/+j0eBmq/we/RLpit+woZ9cyRH3T/2jWSCbDgz2MI8PHk9C5RlFVW8/t3ltrHArwdFFdU079DKCt259n7rxnR0X6YDOD3IxIoKqvi0+XuYfq0TpH8vC3Lfh0R6ON2fFJyW2auy6D7QwdC7V/O7clvBrbH08PwwZLdtA/354yubdjr+qXq2Yv72qE5KtAZ3gbEh7Hc1Qbh7+3JhJ7RLE3J5b7J3RmWFIGXw7iFz0sGtWdggjOsTegZTWZBOb8d1J5LB3ewz4l1Bcsx3dowMbktZ/eJITLQhy9X7eXG0zvx4+Z9zN6QyYD4MB6Y0h1jDMYYJvdqx19dI8rPXdyH8/vFUlVjHbZP/+2rB9nHp/Rqx/PfbSG7uIIzu7fBGMNDZ/fg/ind3dp8attVao3p1sat3Wd4J/eF47q3C2btoxOoqKrB29ODK1wj07VC/LzIK6kkNvTA37+bx3Rid06J3bYxoWc0ng4P7p7YDYAvbhpBUXkV3p4ejO0RzbO/6cPQpAi3+9atuXZ8MCa0/t9xAC+Hx0nd3tGQUyJQx8XFkZaWxv79+498cgvm6+tLXFzzNOWLiNRV+xX2sQTq2hHRhr5ZfOvnnZRV1vDz1iwuGhDHgm3OEb3a82p7M79ctZfwAB9uH9eZC15dyP1TutOpTSAAMSF+VNVYeHt6sDmjkL35pZRX1jAxuS3gDKfPfbcFH08PhiVFkJZbSqCPJ0WuRTzmbtpPt7ZBXP/f5fUe0Ko7OgzYvZ9fr97L3+qMSl/976XsyCoiNad+AL77s9WE+nu77bv387UscgXshgx4fI7bQ15ju7chPMCbFbvz2LavyO3cXrEhDE2M4O0FOzmzWxu+d/Uaf3bDMC56fZHbeWv35APw1AW97FHCYa4gtOXxSXR5YCY3jk7itbnOUeupo5L4dFkq2cUVXDk0nnP6xnDNaQl8siyNVal5PHx2T75evdcO1JcP6cDwpEiqLcsO1C/8ti8A714zmKvedrZknNs3lpnrnDNK+Hs7mH7LSLtXG+CqYQn2dkyoH3PvOsPtMydGOf/Z/2lMJ+ZtyaJfh1AA3rjS/Zv62inYhidF0K1tMNeNOtCzffC5tWpn6xgQH2aP8p7WOZLNj0/Ex9NBm2Aflu3K5cbRSW7fmkxMbstz323h3L4x9t8TL4f7n/cXftuXTRmFnN8vFl8vD7ewHRbgzSc3DCO3uMIO/eAeTMEZgBMi/Pnd8ASuGBp/1A/WHmoWlrd+N5BvVqfTpk6bkb+3J/+4rD+3jS3CNNC2dHAwvnDA4f+9MHVUIi//sI3o4JYVmg/nlOihFhGRppGeX0pJRTVnPvsTQIOjzIeyLCWHnjEh9ijkygfHkV1c7vYQ4I3vLWfmugyePL8XhWWV/HXmJkL8vBjTrQ3n9InhP4tSmOt6uGp8j2iuHp7AZf/6pd57eTkMN56exFs/76S4wtmq8O41gxnVJYr3Fu/igS/X2efGhfkR6OPJlcPiuf+LdfXudTCHh2F8j2iGJkbw8Nfrj/rzx4X5HbbvtlbtaG1d0cE+XNg/ju82ZLJ1XxGzbhtF17ZBfLchk+veXcaEntG8eEk//rcijQk92xIR4M3cLfsZEB9G70dmA7Dk/jMZ/MT3gLNPvLoGu8f5UP8cK6pq8PQwJN43A4AF94xxG7lsSFF5FckPz2JKr3a8cnl/+z5Pf7uJK4bGk1AnKCfcMx2A1Q+Px8fTg2lr0ukTF0Ln6KAj/pzqqqmx2JVT4hbCD2VvXinhAd74ejmO6t6WZTFvaxYjkiJ+dZtR7SiwuLMs64ij9SeLVtdDLSIijW/YX39we719fxFJUYHkFFcwZ2Mmb/+8k4+mDq03Aru/sJyLXl9Ezzp90+e/uoCU7BIePacnvxueAECJK/z+d/EuNqYXAM6vtL9YuYcvVu5hWOKBr5Fnb8i0Z4s4WGW1xUsHTcV11dtLuHp4gj1jQq203FLGdm/D5UMOBOrEyAD+cVl/4iP8yS6qoKCs0n5wceqoRP48sZu9OEatjpEBRAZ6szTFuf/eSd3IKangjZ+c/bc/3DGabfuKuO3jlWzJLKJXbIizp3p3Hm9fPZBr3llGYlQAlw+JdwvUN45O4rqRiYQHePP7ER2ZsTadLtHOEdlRXSK5alg815+ehK+Xg8uHHPj6/oyubdzqiwr04dMbhrE0JYeJye3qjWw3pDYMjuwcyfytWbQ7ihHFQB9P5t99BpF12jq8PT144Kweh7wmxM854nnREUY2D8XDwxxVmIZDtxkcijGG07tEHUtZCtOHYIypN1rf0ilQi4i0UtPXpPPS91uZcetIt6+Rc4or2L6/CB9PD3rHhVJTY+HhYfhy5Z569zjz2Z9IeWoK572ygN05zof7Zm/ItL8aB+eo9vjn5wGwfm+Bvb925oQnpm+kc5tAsosr7AefasP0wVIPeoBwX2F5vXNuObMz149K5JlZm3F4GN76eSfJscGs21PAOwtT6NY2iMEdw3l30S77mrgwf7d7fHvbKDsMBfh4kltngY/u7YLt/w/y8aSwvIpgX09+vHM0AP/38So+X7mH60YmkpJdbAdqb08PesQE88pl/Zn44nzO7tOOP5yWSGV1DT6eHrzz+0EMTAin2NV6cuXQeMoqq7lpdJL9FXtUkI/9yweAj6fDbZaPhjz7mz6sSs3DGMOghHAGudoHEiL8D3tdXW9cOYCc4gp77uYjaR9+dPeecctI+8+NSEumlg8RkVaq030zqKqxWHr/WKKCfMjIL3PNKuCcSzg21I8bRifx9MxN/OW8ZG77eFWD99n6xCQ611msYmz3NvzzyoGkZBezcnced3y6+pA13DGuC89+d+AhMX9vByUV1RgD39x8mj0qfNeErjwzazMAQxPDuWpYAs/M2szOrGKGJoazeEeOfY+67QuWZfHtugzO7B5NlwecNa5/dAKbMwu54NUDDwDeP7k7141KZN2efHbnlNgzPNSqqbHstof5d5/hFhgz8svw8fQgzDWrQVV1DRXVNfh7e1JeVU3XB76tV9f2/UXEhvodsu3gaBdSOV7frN5LpzaB9i8JIuJOLR8iIqeoPXmlGNy/ui4oq+St+Tu56YwkfDzrh7TqGot1e/Lp0z7U3lflekArq6icqCAfbvlwJUtSDgTTPXmlPOjqNa4N07VTf9XV59HZbq/nbNzHHZ+u5osGRrQPds1pHamsrrHbM2bfPorlu3LZV1BuTyUH8JuBcXagvnxIPJN7tWNEUiT/XZzCpYM74Oft4LsNmeSVuM94YIxhkisc/2lMJ4wxBPh40qNdMIM7hpNfUsnmzEL76+fk2BC3963l4WHo0z6UHu2C6o2+tg1xb4PwdHjYvbY+ng4iA304r2+M2zlJrofoDuXgacQay9l9Yo58kogckQK1iMhJbktmIR3C/flm9V5+2LSPmesyCPX3YsGfx+Dt6ZwZ4K5PVzNrfSaZBWXcNaFrvWnJnpm1mdd/2s60P51Gzxhn+0OtBduySM0pOWSwnvNyAAAgAElEQVQ/8utX9OeZWZupqK7hqmHx9QJ1bd/ziE4RXDk0gbd/3lkvTD//2z74eDpIzSnB38fTDuoBPp783/iudqCOC/Ov134B0CbIly9uGs6mjEI7BIb4e3HzmM72Oef2jT3sz/GO8V3tbV8vB59cP4zlu3K58LWFnNb5yD2yX940/JhGjJc9MPZXXyMiLYsCtYjISWTbvkLu+d9a3rhyAC9+v5XwAG9enbudG09P4sU6U7bllVTS8+FZDE4IdxtV/mhpKh8tTaVnTDBv/W4QWUXl+Hh68OmyVMAZnhdsy7LnxwUaXKRjQHwYZ/Vux4JtWUzo2ZaJye2wLMueZu1gt4/twq1jneHWz9vBEtd0aAPiw7h3Uje3ab8sy2L2+gwuGXRgrt9/Xz2ImgZaEO+Z1I3NrsVK+nUIo1+H+ot1HI8B8WFHPVPJqbrOgYgcP/VQi4g0oYKySp6YtpE7J3Ql2M8TgyGzoIyXf9hKfEQAHy3dTWpOKX//TR/urNN73KNdMBsO8aDeoVw1LN7twbvDSYjwJyW7hMX3nomft8OedeFg6fml9kwfKx8cR7+/fEdkoI/bKGxNjeWcyi25rdvDiSIiLY16qEVEGtGWzELGPz+PmbeO5I2ftlNZbdlz7h7Oe4t38fGyVPx9HExbk87+BmapANzCNPCrwvSH1w3ls+VpfLrMfbW6+yd35/k5W+wWjbp+uGM0+4vKj7jQQttgX/5vXBfO6RNDWIA3903uxtju0W7neHgY3rp60FHXKyLS0mmCRBGRY/DREmcLxfcbM/ly1V6mr00nu6jhcFzXSteyzf9ekHLIMH0ktavAHUpUkDfn9I2htNI9OP92cHs+njqM28d2IcD7wIOLiVEBeHiYo1q1zBjDLWd2thfnmDoqyV6lTkSktdIItYgIzqnOHB7miH2yReVVZBeV894vzlaKuiunfbchk0sGH+gLLq2o5rWftvPtunTev3YoWzMLmbt5X717Hq6d45oRHUnLLXEuqhHiy0uX9qN9uL89s0aQr6e9yt/T3zpnwYgM9LGXSwa4ZFB7vBweBPt60SsuhF5xIVw0MI6yymrC/Y9+xTgREWmYArWItFpLduaQHBuMp4cHXR6YyS1jOtEzNoRF27N55JyeDV5z3+dr+Xr1Xvv1jLXp9vb7v+xm1voMLhwQxw8b9/F5nZkupv53mT06ffmQDrz/y277WEyoH0+cn8zNH6xkT96Bpanfv3YIIzpFAvDy91sJC/CuN6Xb0vvH4u3wwMPD2IE6xM8LYwyXDenAB7/s5v/Gd6FNkPvo85GWjxYRkaOnQC0irVJmQRkXv7GIs3q3Y1iScznrN+btoLyqBoAHpnQnPb+M9XvzmZh8YJGPWeudS0Jf0D+Wz1fsYU2ac9aL+Ah/ewaMHzfvd3uvMd3a8MOmAyPT5/SJoXdcCH/+31p6x4Vw/5TudIwM4Ic7TyenuMJ+6K82TAP86czObvf8+uYRLN6R3eDocu0o++PnJnPDqKR6YVpERE4sBWoRaZVSsooBmLYmnWlr0usdT893Bu70/DJGdo7kVdcDh+VVNdwxrgt/OrMzn684MAJ98cD29sIjPp4e1FgWlw+J5/QuUWQXV/DDpn20C/ElPb+M7jHBDEmM4Px+cfby1s7rHLQL8ePtqweSVVTB4fSOC6V3nHsv9d8u7MWu7APLOHt4GDr8iuWlRUTk2ChQi0irkHDPdC7oH0tZZTV/PKMTKdnFhz1/d04J6fllAMzf6py7uXaxlIOXaZ72p9MA7EC95pHxbqsVllVWk1NczhVD4/Ewxh5Vrhum6xrTLbrB/Ufy2zrzOouISNNRoBaRU1pqTom9YEjtiPL2fcWM7lZ/Zbzadg/AbaQXIKuogm37ioD6s2x0axtE7Yz+p3eJqrf0t6+Xg6mjko7rc4iIyMlLgVpETjm7s0vw9fKgTbAvI5/+sd7xzZmFbM4sPOw93l2U4vb6gS/XEezrSY92wfZI9bvXDGZTRoE908e8u84gItD7hHwGERFpORSoRaRF2baviOhgH4J8nSv5fbVqD/sLy7l2ZCIAmzIKmPjCfAAeOqtHveuvHBpPVU0N09ak88pl/Qn09cTb4UGAjye3f7yKVal5rvsUMjwpghcv6cegJ+YAUFBWxfn9Yu17jeoSxaguB0a61a8sItI6KVCLSIsy9rmfALh7YlduGJXErR+tAuCKofFUVtfYYRrgsWkb6l3ft30oFw6I48nze9Wbc3pEpwhWpeYxdVQiybEhTEpui5fDg6uGxTNtTTpPnJfMxOS2jfjpRESkJVKgFpGTzncbMjHA2B7uD+eV1Vn57+lvN2NZB459uy6DTm3cV+zrFRtiT2UHcGH/OM7pGwPQ4AIugT7OUe/qGotz+sTY+x87N5lHz+l5xEVfRESkddLS4yJyUlmxO5fr3l3Gte8uc9ufWVDGpBfnu+178futeDmcIff+L9baDw0C/O/GYXx98wiW3H8mnV1B+7Fze+LlOPS/9rq3CwKcc0ofTGFaREQORYFaRJrNtf9ZyuX/WkxqjnNGDcuymLflwKIoNTUWNTUWT0zfwAWvLmRn1oGp7h49pycVVTVUVlskRQVQXFHNgm1Z9vHEyECMMbQJ8mVoYgTBvp74ex9+ie3RXdvwvxuHc8WQ+BP8SUVE5FSmlg8ROWGmr0mnW7sgkqIOtF7M27Kfvh1CCXY9RDh/6378vT0ZEB/GnI3O1QNHPv0jM28dyYJtWbwwZ6t9bVpuKRvS83lz/k6393n/2iFEumbaAOjfIYzt+4uZt3U/of5ezL59FGEBB2bbuHN8Vy4f2uGoRpkHxIcd24cXEZFWS4FaRE4Iy7L44wcrAEh5agrgDNh//GAF143syP1TnDNuXPnWEgDGH9QfPenF+QT5uv8radQz9ae8Awjx86JjZID9ekB8GJ8uTyOzoJzJvdrWW2o7xN+LEH+v4/h0IiIih6aWDxE5IfJKKt1ef7hktx2w9xWWA1BedeChwtkbMuvdo7CsCoCnL+x92PcK8fPC29PDDuX964wqXz284zFULyIicuw0Qi0iJ0RmYZm9bVkWf/t2EwPjw8gurmBvXilQf/XBhlw8MM5tbudRXaK4cmg8ny5LtUN4qGu0+fUrBrArp4SOkQFMSm5LVJAPgzuGn8iPJSIickQK1CLyqxWUVVJYVkVsqJ+9L7Og3N7enFlIXkkl5/SNYcPeAuZsdAbhurNw1HX18ATeWZgCQHxEANHBPtw0Oonz+8XSOdo588a4HtEk3DMdgEAf57+6PDyM3frx2hUDTuyHFBEROUoK1CLyq5RXVdP7kdkArH54PDv2F9Em2Jffvb3EPueLFXsA6BodRGlFNVlFFVzxr1/IKa4g2NeTG0YnMb5HW95bvIuRnSMZ2TnKDtTd2wVhjOHuid3qvfdtYzvzydJUTWEnIiInFQVqETmiV37cxpbMQh48qwe5xRX2/m37CrnwtUX1zv/n/B0AdG0bRH6ps7f6Z9eUdreN7cxNozsB8Mg5PetdOyjh0C0bt43twm1juxz7BxEREWkEeihRRA5rx/4inpm1ma9W7WXg43PYnFloH5uxNsPt3K7RQfSJC8GyYHhSBKH+3iRGBbid0zsupMH36R0XgrfDgyBfzcYhIiIti0aoReSwxjz7k9vrxTuy7e1vVu/Fy2G4aEAc0cG+3Da2C+v35vPPeTv44xnOUej24e6rDtado7quz24YTk3dtcRFRERaCAVqEanHsiyMMZRWVNc7tmh7Nj6eHpRX1bCvsJw+cSH89YID09z1jAnhxUv62a99PN1XJ4wLq7+sN4C3p74wExGRlkn/BRMRN49P28CUl37GsizS80vt/VcOdS7HvX1/Mad1isTPyxmUex2ihaOu+XefwW1jO3NB/1gcHnqgUERETi0aoRYRABZuyyLYz4t//exc5ntvfhkZ+Qfmlm4ffmCKvDO7R7NsVy6lldX0ij1yoG4f7q+HCUVE5JSlQC0iFJdXcdm/fnHbtywlh+LyAy0fY7pF8+SMTQCM7xmNn7cHS3bmMr5H2yatVURE5GSjQC3Sim1ML+DLVXsY1z263rFbP1plb2/6y0R8XS0esaF+RAb6cH6/OM7vF9dktYqIiJysFKhFWpHFO7Ipr6ph1e48PlmWyh7XkuBvu9o8AHq0C8bb04NVqXkAjOwcaYfplQ+Os7dFRETESYFapJXYm1fKJf9c3OCxyuoD09WN6hKFwwNWpeZxx7guXDcq0T4WFuDd6HWKiIi0NArUIq3EAtdKhQf77IZhZBVV8PO2/WTkl3PTGUn4eTkYmhjByM5RTVyliIhIy6NALXIKWLE7l3cXpvDsxX3taelqaizmbMwkNbeU2FBfu70DwNPDUFXjHJXu1CaQgQneTEx2f7hQYVpEROToKFCLnAIuf/MXSiurCfbzYt6W/Vw5LIG/TNtwyPP7tA9l+a5cAEL91cYhIiJyPBSoRVo4y7IorXROb/fhkt1UVluHDdMAw5MieOisHmQVlTdFiSIiIqc0BWqRFmp1ah49YoLJLa6w99V9uPBQHj67B2f1jiEqyKcxyxMREWk1FKhFWpCft2Yxf9t+fjcsgXNfWcDwpAgWbs8+6utfvKQv5/aNbcQKRUREWh8FapGTRFZRORVVNcSE+h3ynBe/38LyXbmMdS3EUjdMJ0T4k5JdwpCO4QD8sjPHPvbsb/pwXr9Y+4FFEREROXE8mrsAEXEa+Pgchj/1wyGPp+eXsjQllxrLucLhwc7o1gaAiclt+fj6Yfb+r/44ggsHxClMi4iINBIFapEWYsbaDHv7s+Vp9Y73jgsBoE2QLwC/GxaPl8PQp31o0xQoIiLSSilQi5wESiqq7O2q6poGz5m2Zi++Xs6/smvS8t2O3TOpG8MSI0mODaZPe2ewfvTcZLY+MbmRKhYREZFa6qEWOQns2F9sb+eUVFBeWUNOcQX5pZW89P1WHB6GlbvzuHRwez5cklrv+htOTwJg2p9GNlnNIiIi4qRALXISSMk+EKizCiu46PWFlFRU1zvv6uEd7UAd6ONJUXkVA+LDmqxOERERqU+BWqQZ7MoupkO4P8Y4HxRMzyuzj13w2gLKKg+0fdx8Rif+8eM2ALq2DQKge7tgPpo6lOoaCz8vRxNWLiIiIgdToBZpYkt25nDxG4t45qLeTOrVjts/XkVpndHoumH60sEduH1cFxZuz+KSwR2c199/JsG+XvgqSIuIiJwUFKhFmtj3GzMB+GDJbnZll/DdBufruDA/LAv25JUCMPv2USREBODwMHx+0wj7+tpZPEREROTkoEAt0oR2Z5fwqWvKu5W781i5O88+lhARwHvXDmF1ah5h/t50iPBvrjJFRETkV1CgFmkCS3bmEOLnxdzN+8gprnA75u3woKK6hphQ58iz5o0WERFpWTQPtUgjqqqu4a5PV3PxG4uY8MI8UrKLCQ/w5rIhzn7obU9MYlBH5ywd5/WNbc5SRURE5BhphFqkEZRUVLE7p4SC0iq7xQOc8013jAzgL+cm88CU7ng6PHjs3GQWbs9meKfIZqxYREREjpUCtUgjuOuzNUxfk86U3u3c9m/YW8D4nm1xeBj8vZ1//ZKiAkmKCmyOMkVEROQEUMuHyAmyfm8+la5lw+dt3g/A9DXpbucUllcxNDG8yWsTERGRxqMRapHjlJJVzMrUXG7/eDV/vaAXlw7ugK+3g8LyKgA2/WUieSWVvP/LLkZ2jmJwRwVqERGRU4kCtchxqK6xGP33ufbrh75ah6+XB/sLywG4oH8svl4O2oY4uGN812aqUkRERBqTArXIcdjrWoSlVmW1xe0frwbg0xuGMTA+rDnKEhERkSakHmqRo7RtXxHPzNqEZVn2vp1ZxQ2eO7prFIMSwjHGNFV5IiIi0kw0Qi1ylK7+9xLScku5algC1TUWkYE+hwzUMaF+TVydiIiINBeNUIscpX0Fzr7o9Pwyhj/1A7d/vIplu3Lx9vTg/WuHEFsnREcH+TZXmSIiItLEFKhFjlKFa0q8815ZAMD0tel8s3ovvx+ewIhOkXx43VACfZxf+kQEejdbnSIiItK0FKhFjtPpXaIA6BDhz8TktgA4PNQ7LSIi0looUIscxrfr0jn/1QWk5pQc8pwQfy97e1yPaAD6tg9t9NpERETk5KCHEkUO4+2fU1i5O4/bP151yHNC/Q+0d0zo2ZaNj03Ez9vRFOWJiIjISUAj1CIuWzMLKXKtblir2jVF3rJduYe8LsTPy+21wrSIiEjrokAtAtTUWIx7fh6///cSe9+q1DyW1wnSCRH+LLxnTL1rAxSgRUREWjUFamnVvlm9l4R7prPHteLh0hRngL7+v8vs2TyCfZ2dUX3bhzY4v7QWbxEREWndFKilVXtnYQoAP23Zb+/LL61k1vpMIgO9+cu5PblnUncAzujWBoA3rxrIXRO6NnmtIiIicnLSQ4nSqsWE+rF8Vy4Lt2fZ+7ZkFgLwzEV9OKNbGyzLomvbQPp3CAOcM3mM6xHNM7M2N0vNIiIicnJRoJZWrbLKuVjL9xv32fve+GkHAF3bBgHOlo4B8eENXh8RoAVcREREWjsFamnVsoqcy4mXu4I1wJyNmfh4etAu5PDLh695ZDwO9U+LiIi0euqhllbHsiwqXAE6q6icNkE+9rHrRyUS7OvJ0xf1PuLDhsG+XgT46HdSERGR1k6BWlqdl3/YRpcHZlJWWU1WUQVndo+2j91yZmdWPDiOc/vGNmOFIiIi0pJoeE1aDcuyMMbw3HdbAHjp+60UlVfRIdzfPsff26Fp8ERERORX0Qi1tArPfbeFjvfOsFs9AF6dux2AAfFhdGoTCGhOaREREfn1NEItrcK/f94JwPcbM+sd69s+lK/+OILCsqp6x0RERESORIFaWoXYMD82ZRTy2fI0AKKCfGgb7MuNo5Pw9vTA29NDDxiKiIjIMVGCkFPO5oxCQvy8+P07S3nqgl70aR9Km2BfNmUU8v0m53zTi+4Zg6dDHU8iIiJy/BSo5ZSwOaOQ+Ajnw4UTXpiHw8NQXWNx12ermX376ZRVVgPQIdyfHu2CFaZFRETkhFGglhZvX2EZE16YB8C5fWMAqK6xANiSWcQdn6wmPb+UcT2iefOqgc1Wp4iIiJyaNEwnLd6KXXn29ler9tY7/r8VaaTmlBLkq98fRURE5MRToJYWb1lKzlGdF+zr1ciViIiISGukQC0t3s6s4qM6z9/b0ciViIiISGukQC0t2hPTN9gzd9RKjg22t2fcMpI7xnUBIKOgrElrExERkdZBgVpaLMuyeHP+znr7h3aMsLd7xAQzIbktAD1jQpqsNhEREWk99JSWtFg5xRUN7u8cHej2ukt0EAvvGUPbYN+mKEtERERaGQVqaXGqaywW78gmr6TS3nfl0HiMgd05JYzqEsUn1w/Dy2Hs4zGhfs1RqoiIiLQCCtTSYhSUVZKWU8qdn65mQ3qB27H4CH+uHZlov24XogAtIiIiTUOBWlqMfo99Zy/YcrDIQJ8mrkZERETESYFaWoTNGYUNhukXL+mLn5eDcT2im6EqEREREQVqaSGW7My2t709PaioqgHg3L6xzVWSiIiICKBALS1EWm6pvT2gQxiXDulAfmnlYa4QERERaRoK1NIipOaW0CbIh9gwP+6f0p3kWM0pLSIiIicHBWo56ezNK8XPy0FYgDfgXMAlNaeUbu2Cefeawc1cnYiIiIg7BWo56Qx/6gf8vR3cO7k7nyxNxcth2JhewMWD2jd3aSIiIiL1KFDLScWynDN5lFRU8+CX6+z9Dg/DeXoAUURERE5CCtTSrIrKqzjn5Z8ZkhjOk+f3IruB5cSnjkpkcq929G0f2gwVioiIiByeArU0i5ziClJzSqiormFHVjE7soq5bWwX/vTBSgCGJUZQXFHFmrR8LhnUnsSowGauWERERKRhCtTSLC57czGbMgp5/Lxke9/DX61nSUoOAPdP6U6nNoGsTs1TmBYREZGTmkdzFyCt06aMQgAW7ziwYMu36zPs7bgwP3y9HAxJjGjy2kRERER+DQVqaRbGOP9/2pp0+rQPxdfL+UdxfI9oPrhuCKH+3s1YnYiIiMjRU6CWJrM0JYeaGucsHgHeB7qN7p/cnSRXW0dybAjDkyKbpT4RERGRY6FALU3ilx3Z/Ob1Rbw+bzsA/t4O+9jgjuHEhvoBEBGokWkRERFpWfRQojSJwrIqAJ7+djOWBTWu+aa7RgcBcOPoJGZvyGSERqdFRESkhVGglkZXWV3DqtQ8+/Uzszbj5TBM6dWOv13UG4B+HcJIeWpKc5UoIiIicszU8iEnzOz1GZRUVNXbf8cnq/nHj9vc9lVWW/SOCyHQR7/TiYiISMumQC0nxLo9+Uz973L+Mm1DvWNfr95rbw9KCLO3Q/29mqQ2ERERkcakQC0nRO2S4ak5pQDklVQwb8v+eiPW7/x+sL3dt30YIiIiIi2dvm+XE6KsshoAL4dzgumnZ23mg1928/SFvd3OC/Dx5IEp3amxLLq2DWryOkVERERONAVqOSHySpwj1F4O55celmsWj0e+WV/v3GtHJjZdYSIiIiKNTC0fckLUtnx4e9YGauf+korq5ipJREREpElohFpOiFxXoJ62Jp1BCSnkl1bi5+WgtFKBWkRERE5tCtRyQtSOUAM8/PV6/L0ddG8XxMNn92RfYTnXvbuMIF/9cRMREZFTjxKOHLdF27P5fMUet30lFdUE+3nRp30oACseHIen64FFERERkVOJeqjluN3y0Uo6hPvX2x/se2Ce6fAAb7fXIiIiIqeKRg3UxpiJxpjNxphtxph7Gjgeb4z53hizxhgz1xgT15j1yIlXUVXD/sJyfjMgjvAAb7djIX4K0CIiInLqa7RAbYxxAK8Ak4AewKXGmB4HnfZ34F3LsnoDjwF/bax6pHFs21cEQGiANwWllQCc0TUKAD9vR7PVJSIiItJUGnOEejCwzbKsHZZlVQAfAecedE4P4HvX9o8NHJeT2MJtWUx+aT4AYf5e3D2xKwAXDWgPwJ680marTURERKSpNGagjgVS67xOc+2razVwoWv7fCDIGBPRiDXJMXjjp+18tyETgGlr9vLz1iwAXpm7zT4nzN+bqaOSSHlqCuN7RnP5kA7cembnZqlXREREpCk15iwfDU3pYB30+k7gH8aYq4F5wB6gqt6NjJkKTAXo0KHDia1SjuivMzcBsOkvE7n5g5UArHpoHMtScu1zQv0P9Et7OTx44vxeTVukiIiISDNpzBHqNKB9nddxwN66J1iWtdeyrAssy+oH3O/al3/wjSzL+qdlWQMtyxoYFRXViCXLwaqqa+zteVv229sPfLmO8qoDx8L83R9IFBEREWktGjNQLwU6G2M6GmO8gUuAr+ueYIyJNMbU1nAv8HYj1iPHIKfkwIItN3+4EoeH84uHaWvS6R0XYh9ToBYREZHWqtECtWVZVcDNwCxgI/CJZVnrjTGPGWPOcZ02GthsjNkCRANPNFY9cmyyCg8E6oqqGp67uI/9+ooh8fh5OWfy0IweIiIi0lo16kqJlmXNAGYctO+hOtufAZ81Zg1yfLKKygHoExfCv343iKggH279aBUACZEBzL59lD11noiIiEhrpKXH5bCyi52B+oVL+hEV5ON2LCHSnzZBvrRvYJVEERERkdZCS49LPak5JViWxbo9+UxfkwFARGD9HumoQJ96+0RERERaG41Qi5utmYWMe34e903uxpMznNPleXt6EORz4I/K7NtHsTu7BGMamhlRREREpHVRoBY3P7mmxvtq1YEZDqMCfdzCc5foILpEBzV5bSIiIiInI7V8iO27DZk8Pn0jALuzS+z9Qb76vUtERETkUBSoxfbPedsBuOH0JArL6y1YKSIiIiINUKBu5RbvyGb88z/x4pytLE3J5ZYxnfjzxK4Ea1RaRERE5KgoNbVy//hhG1syi9iSuQWATtFBGGNoF+JHQVkhAJbVnBWKiIiInNw0Qt2KVVbXsCQlh54xwfa+jhEBALQJPjAlXmJUQJPXJiIiItJSKFC3IqtS89iTV2q/Ts8ro6Kqht8NS7D3JUQ6F2k5r28sALec2Zm/XdS7SesUERERaUnU8tGKnPfKAgBSnppCWWU1D361DoC4MD+uHp7Ah0t2E+TrBcCFA+IY1SWq3uqIIiIiIuJOI9St1EdLdttzTseG+fHIOT3Z/Pgkt3MUpkVERESOTIG6lSivqnZ7vSYt395uF+LX1OWIiIiInDIUqFuJwrID80qvTctn2pp0+7W3p/4YiIiIiBwr9VC3Evmllfb26/O24+kwzL1rDF4OhWkRERGR46FA3UoU1AnU09ek079DKDGhavUQEREROV4anmwlCsrclxIf2TmqmSoRERERObUoULcSdUeohyVGcNMZSc1YjYiIiMipQy0fp7ji8iru/t8a5mzItPfdcmZnfDwdzViViIiIyKlDgfoUtjYtn2W7cpheZ0aPpfeP1fzSIiIiIieQAvUpZm1aPot3ZLNwexY/bt7vdizA20FkoHczVSYiIiJyalKgPsWc/Y+f6+377cD2xIb5cX6/WIwxzVCViIiIyKlLgfoUkFtcQVlVNYE+Df/jbB/ux81jOjdxVSIiIiKtgwJ1C1ZaUU1hWSWDn/yeuDA//v6bPg2eFxGonmkRERGRxqJA3ULll1bS59HZ9O8QCkBabim7sosbPDciQH3TIiIiIo1F81C3UKk5JQCs2J1n71tZZ7sujVCLiIiINB4F6hZqT15pvX1LUnIaHI2OUqAWERERaTQK1C3Untz6gXrH/mK6RAdx6eAOvPeHIfb+CE2VJyIiItJo1EPdgtz92Woqqmp44ZJ+pNUJ1GH+XuSWOJcWn9SrLVcNSwBgVJco/p+9+w5zo7raAP6OtNXb3HsH29jGBZtmIHRseg2mJ0AINeRLgZBGSwiQBAgQEkIJpiX0TsBU0/wvClQAACAASURBVMFgqgHbuBfc1nW9VbvSfH+cuZo7VzNqK3l32ff3PPtoJY2kURudOXPuuW99U40uRZwVkYiIiChfGFB3II/OWQUA+PP3x+OdRe6kLZvrm3Ho2L6oKCnAybsNjl9+5xmTsbk+wt7TRERERHnEgLqDsG07/v+o388EANxy8kT838Of4YRJA3Hj9MSWeSWFYfSrKt1u60hERETUGTGgbufqmlrwmyfn4ux9hiVcd/i4fpg2ti8KwyyFJyIiImorDKjbuWc+W41nP1+NhetrE64rDIdQyPJoIiIiojbF1GY7t7haAunqbY2ey2ecuVtbrA4RERERGRhQt2OzFqzHv99ZCgDYUBuJXz6idzkO2Kl3W60WEREREWkYULdjb8xf73t5UQHfNiIiIqL2gpFZO1IfafGc/2TFFkwZ3gO7De0GABg/sAoA0JMzHxIRERG1Gwyo24kPlmzEmCtewvuLNwIAmqMxzFtTgwmDuqJPZQkA4MYTJ+DnB4/EX08c35arSkREREQadvloI7ZtoyVmx1vezVm2CQBwyl0fYOKgrthtaDe0xGwM71WG8/YdjvP32wEj+lTg//pUtOVqExEREZGBGeo2csUzX2HE716Mny/R+t99tnIL7npbBiMO7t4F3cqKsPOAqu2+jkRERESUGgPqNvLAB8sBAI3NUQDAtka3fvqwnfvG/x/Uvcv2XTEiIiIiyggD6jb2rzcXoyESxca6pvhlx08aGP+/r1M/TURERETtE2uo29jNry7Eza8ujJ8/b7/hOGBUL5y+52AUhEIIh6w2XDsiIiIiSoUBdTsyYVBX/Oaw0QCAa44d18ZrQ0RERETpYMlHO3DK7oMBAKs21bfxmhARERFRppih3s6ufu4r7DuyF0IWELPlsuuOH4f+VSUY3a+ybVeOiIiIiDLGgHo72lIfwYx3l2HGu8sSrrv4oBHbf4WIiIiIqNVY8rEdzVuzra1XgYiIiIhyjAF1ntm2jXPum4NZ89dj3pqatl4dIiIiIsoxlnzk2bqaJrw6bx1enbcOx07sD8sCbNu9fo9h3dtu5YiIiIio1ZihzrMlG2rj/89eugmH79wvfv6SqSNx/492b4vVIiIiIqIcYUCdZ8s2uK3w1mxtxJ479IifH9KjDMUF4bZYLSIiIiLKEQbUeTBr/nrMeHcpAGDZxrr45QO6luLo8f1RXiyVNoeM6dMm60dEREREucMa6jy4+KFPUdvUggmDuuLzlVuwY+9y/GraKOw+rDuquhTi+Yv3Qcy2UVLI7DQRERFRR8cMdR4M7dkFAPDSV2vx6cot2H9kL0wd2xdduxQ515dheK/ytlxFIiIiIsoRBtR50BKVNh7Pf74GkZYY9hjeI8UtiIiIiKijYkCdBzUNzQCAb7c0wLKA3YeyNR4RERHRdxUD6jyoaWyJ/z+mXyWquhS24doQERERUT4xoM6xlmgMtU1uQH34uH5JliYiIiKijo5dPnLsuhfnAwBOnDwQhQUhnPO9YW28RkRERESUT8xQ51A0ZuPf70j/6T2H98C1x43jxC1ERETkWv4+MP+Ftl4Lr42LgU/ub+u16NCYoc6h5dokLmXFDKSJiIhI09wAzDhU/r9qa2a3CxUC4QzCtkgdUNgFsKzUy844HKhdC0w4BQhr477qNwF2DCjrmf7jdlLMUOfQN+u2tfUqEBERUXv1p77Z3+7B49Jfvm4jcG1/4J2b0lu+qUZOG7a4l0Wbgb8MA/66A9DE+CYVBtQ5tLhaMtR/OGYsDhmT5ZeGiIiIyLT0rfSXrV0rp3MfT2/5ojI5/fy/bulH/Sb3+sYMsumdFEs+cmhzXQSlhWH8YMrQtl4VIiIiak82Lcnudi2R3K6Hn6JyoK4aeOUKOT/pB0DDZvf65sb8r0MHxwx1DtU0NqOqlD2niYiISLNpKXDrLt7LbDu92zZuSb2MKdaSehldcXniZXpA3cKAOhUG1DlU09CCylIm/YmIqB17+kJg/v/aei06l5rViZdFm9O7rR7YpkvPKMdiwONnAytmBy9fZATUr/0R+OAf7vmWpszXIR2xGPDwacDy9/Jz/9sRA+ocqmlsRmUJM9RERNSOffYf4OFTc3d/ti31velmXDsl7bWpGiSnzfXp3TSbgLqlwf2/rhr48gngoZOClzcD6rdvAOY9539/uVS/EZj/PPDIGfm5/+2IAXUO1TQ2o5IlH0RE1Jl8+QRw31HApw+09Zq0X3bM/b+0q5w2pxmktjZDrQYUxqLByxeWJL+/fJd86K9PB8WAOodqGlpQWcKSDyIiaqfykUXevNQ5XZb+bb5+Brhxp+0z4C5TXz8D3DQ2t+umB7il3Z3LAjLUdRuB6wYDKz+U8yqgDhd5l/vmJeDmcf6BuZ5RVrdPVlcdSxHQ5q3kwyl78Quo/7UP8OFd+XncPGBAnSO2bWNrAwclEhFRO7JiNlC9wD2fLEuZrXiMnsYEIspz/wdsW5Nd9lW3+lNgzRetuw/TMxcDNauAhk2pl02XHjynylAvfQNo2gq8f5ucV69RYal3ucfPBrasALat9V7eEgE+vk/+t213UKPfe7/4dWDLSjewDfLxfcE7GNFm4LOHUgflvrdV96nt6H37sbyva+cCL1yS+X22EaZTc+S8Bz7G1gaWfBARUTtyz1Q5VbPyZdr9IRPpzMinNNXKaapALpU795fTTGYdTKXJua9cljl4AupuzmUBAXWjM8lKcaVz3lmfkBFfRJzXEMZRh3f+BiyZ5Z5PlqF+4Dh5nAGTEq/rv4s89qYlwMKX5H73+1Xi+/zxvRL4NtcDu/3I/zkFUQMz9SMndx3oXca2M/tstRFmqHNg7qqtePnrdQCA6m15OixCRETUWq0NYH1lUUai1iNfpQS5EElz0CAAPHI68JfhSe6rzv1fBdRBA/2ajIBaBd4q+Lx5PHBVlbt81AiUzay/Om8bGWoVxDbVJN4HAJzxNHDWi+752nVShvHEOd7l1Hu4fp572WcPyTqmOgKhMtTJaqiv7iqZ9HaOGeocWLKhNv7/tLGcIZGIiNqpfGSo49nFLLKI7bm/cbpdOABvR4xU9xWvoQ4KqJ1pvosr5FS9Rup0y3Lv8tEI8Ol/JGjvsYM766Hi6ScdAQqcWmz9sxD1Keco7eqdinzjImDdl/J3xE3AR3cBo4+RmnNAZmf8+hmgvC8w+3a5bPMydwfC9NXTbllNqkGJS94Adjgw+TJtjAF1DtRHZK/v/d8ciH5VpSmWJiIi2g78BiDmpYbaCYayOSzfnmfg07PK2WhpAmBJABvxK/mol5KKkirv7VRAHXJCtHiGusn/PY1GgGcudM8fdKX7vx3zBtSNW4HyXt77BRKPXJzyiJwWaN0/Vjp9rMPF0lbv3VuA1/7gXr9tLfDoD+T/fhOd+43K45j13wDw2A+19UxxlEPthLRjLPnIgbom2cvrUsT9EyIiaif8yinSnUwkI04wZGURUrS3DLUeRKfb1i7I9UOAm0Y79+UTUC9/H7h+MPDVU97bqaxw1Hn/9NdID46rBsupCsCVwi7u/y0N3u4repmJ/vnQSz7OeAoYdaj8X1CsLe+sR2GpG+zrVn3k/q8+C/+dDvwpjSP3qTLUrd252Q4YUOdAg5Oh7lIUbuM1ISKiNrNlBTDzN/nJApuWvwe89DvghV8FB8l6EDLrWmD1Z21T8lG3AfjfL90ATg/e2ltA3eSWcKI5iyDu5cvdbhctDUD9Bue+tIC6i5Nt/fZjOX1FyyhvWgJ88bBz+yYpi5j7mHu93tGjxKmxNuuU9eB0ywpg0atu8N3cAGxeDjz7U+Cp89zlohFg9NHAj171llb4HXVobgC69Ey8XKduV7/R/3rzM6vWOahTCAPqzqEuEkVROITCMF9OIuqANi5u6zVoP5q2JbYhS9czFwEf/BNYNSe36+RnxmHSVu3DO4IHbEW04PDNPwP3HpmnLh8qQx0QUL/0W+Cju4EFL8j5Rq0uN5uAetu6zNvtbVmRfADkpiUS6OtBdLqDEretc/9/71Zg48LE+172rnu+rJd7OSA10WqnZIE2CDAa8ZZFANJqUAk7XT/M9n7ma2rHgInOzJi16+Vz+sl9wOLX3GVizdLnetBu/s9RF20CNnyTYhmjJnvd187jxIANCxOz6uozFFS3rn+W2ylGgDnQEGlBKbPTRNQRffUU8PdJMkkEAf+cAtw4KrvbqqDIb4BXPgUFG2ZWL9ac37Z5QVQJg6rHbdRa3GUTUN80GvjzUO+RgGRHBVoiMgHK0xf4X79lJXDrLsCsa7xBdLqDEm8c6T1vvh937g9Uax0wSrrKVN96IFzv/L9pidRUl/Xyf230gHro97y3jd+XT1a47zg5ve9IYNnbiddHmxMnjknm4xnJr69d7z1/+xRg3VeyU3XbrsCce7zXqwx1UJkNM9SdQ10kirJ8BNTrvpIeke150AYRdWwrnbpHffKPzmzryuxvqwKS7R1QP3428MSP3fOvXAl8/khiEBIuapuSD7Ueqo+yJ6DOom2eav+25jP3smT1ziob+uUTwP3HSgCtU8Hfkje9QbRa78Ya4J7DgGd+4l63dRXwn+n+mXLzdW80emQXlgBdengve/LHwH1HSya/2zDZ+TCDUgCocQLqkx8Cdj5e/jfXoXad93xpNzcrHiTaDIRzOA7MXAdAarnVa/H6H73XxQPqgMCZAXXn0BCJ5idD/b9fyqG81Z/k/r6JqO1tWiL1jH6aaoFVH+d/HVQWTB/N76dhM/DtdtoWbVkhh4U7GhVQL5nl39cXkB2XbEtKkpn7qDuT3bs3A0+dm5gpDRdK0JiODQslaEyLKvkIuFqtR+1aKYdRfZaB1g380z+Pno4VMWCploWNaOUFS2YBb1zvLcFQHS6skDegVve5cSGw4j3g0wfc6977u0x28umDietlBtCA2/UCkO+aCnDLnQF7i18DljrvTcMm+SxVz3dvowb5qQx133Hu583MUM93SmvGnejc32YJ4pOJpZmhruifepkg0QiS9ixf8oZbw145ELjgfWCvi4GBu7Hko7Ooi7SgrDgPHT7UF2h7DHAhou3v1l2AW8b7X/fYmcDdB/rUGuaY6iRQkOLH9IkfA3cdkP/1AeTw/G275v9xck3VtL73dwlq/fxjd+DGnfLz+OahfjOrV78RmHlZevd1267ALRNTLwek7tCggtT/XQLcfZAMjlQyzVDrgbMe8OvdKz68U0obVGBpfmY/exC493Bgzefe6y3Lv+RDfx1VNl516vArr/DLWu9yOrCbcxQhVACUOYP6hu6duOzE06W7hqqx1h9v7VwAlmS4QwE11M11MinMcXe496d3/gASd6CjzYkzMfot23NH/2WUogoE7lk1bE5e4nP/MW4N+ZE3AX3GAFOvkRIZZqg7h/pIFKWFrcxQqxqutXPdy1RAnWpjlcyd+wPv3daqVSOiNqBaULXkuXxABTSpslNqoJUKQvLFL4GwYKYEocmymXcfDLwTEMRmI1VfXD/6a7hpabI7z/y+01FX7e2ekCoI+fAu4M4DEi9XGc90Z1VUr1WqDg0q6H1f+01Kt4Z6wyLgmj5uZwzAG1A3N8h63zhapsIG3Gxu0E5gXbXMcPj+P+S8maFW662/js//DHjqfLedXF114v0+e7Gsr66oHDj8r8DlGyVwV2VBg/bwBqy9x8j03ub3sZezE7bqQ6DXKKCoi7sDp96v0x7XbmABoTDw+/XA0X9P7ANtxhVN24JLPn672i1R6b+L/zJKQRFQNcj/uroNqXegZl0jp/oOQFEZA+rOoj4XGepVH8reqD5oIuQE6eZ0oemybWD1p8DLv2vduhFRG1BBSj76BmtUQJOqP3FPZ+DVtzkoQ9mwyHtIvnGrBMMrP/TvHvDy7yU4CgpSbVt2QF690v96fbkvHgsOzPUg2q/WePEsb09fkx4E6YfYl7yZIsDOkfoN3uDRr/RA98IlUlJoBsLplPYses3tDqN+o+Y/B8x7PnGnywyG9CD04xnp9cb+4hH5rM6+w73ME1DXy8DabavdAYDhQtlB+/BO//u0bcliL5kl562QVu9d4J+h/vhe4POHpK4a8C/5AKSThq6oTAJpFbRuWSGn/SdJsK106SHLqYC9op97+x5OdnjAZPf5AW6GevCebns8td0oKAZCocQMdcIOox28Ux0Ku5n4PS8CdjzEfzkAgAV0H+p/Vd2G9Et8ivSAupwBdWdRn5MaaucQiV+GOmivP5X21t+TiNKnfu/y/T1WGfBUmSP1Y5uL2ubbJssheeWblyQYfuJHwPz/JS6vflyDetqmW1+5/F3gyXOkf3Oq+/F7PR44FrhlQvD9h7VD5nrW8f6jgVvTLJ9ojboN3uewKc12iFHjuW50sqtBvYZr1wMPHg887LRiU/Xia+cCj5wG3LGv93fLN4hyfvO2rEjs+OBHvbZ1G9zLzAy13kkDkKD40wcSJ06JP4913oSVnqGuGuhmuP0+X0GfRWXlB97z5nTg37sEgAX03dn7WVHLqZ0Mle2NNgOjDpf/RzgBbUjPUFsSeO77S7nM3CFMlaHW78/P/r+Ruu+KPsC+lwYvZ1nuzreprtr9Xh16ffB9AECh9noVlbGGurOob2pll493bwUePyvxcsu5T7WnWbcBuKoKmPt44rJ+GmtSL0NE7VveSz4avadB1A+aX6B52+7AfUe551++HPhjiq4CgARd/7tEOhwAElx9cp97vQoqVAZPbxn24mWyPQS8QVYyKnv7+cNy22ojG67XvprPUw8Q7zpQuqNcVeVNgoS03wG/qZavqkq8LF03jQUePi35MnXV3gy1PqgtGfO9b0mRRVS/QSqL6ncUZcV7cmrb/tcXV2iPp73WC2bK62R24lAJJpXdLqkCaowMtdmpJlTo7RFtMo8aRJvdgHrI3s5EODH/7Oi6L4HKAcH3bdKz0AAw8RTgqi3yOdH7d6uAWg/sAQmQp/4RuGIzMPY4uSyeod4sr6dluZloM+ufMOjYp+woWZeP/X8NXOrsaBWXBy8HS7Lufuqq5bNWUALseQGw98+C76bQ2Mlghvq7z7ZtbGtsbl3Jx5t/9p5XXwS1cVYbO7WxePdm4K2/pj5MlupwHxG1f9EmycS9c3N2db2pqGAmIYCMAm/f5G5HVKBmBl8f3Q1sWAAsfcu97L1bpUY0VcvPxi3AR3d5L9uyQtqG6Y+pgoSa1e5ys//l/m8G1M2NwJt/TXx8laRQrbm+NJITDdqEI2bWVu8U8e3HwNdPy/+LZ2m30bfJlpRFzHsOOVGzCpj/vPxv7mRd8J5kY+s2eGf6S7fMZNZ1bpZ51RwpiwGCy41qvpVTPXtq2uos09Lknw3VdziKy+Xx37rBfV/1aawBd6rrOqeVnJkFnX1H4gRFdix5yeRm4/VZ9aG8n1YIGDxFupFsXOgfzH37sTuwMB1mhlqnB9QFzuuiBkdWOF1AVMY5pIVt8SMitvt6xks7jG2FOemO33uSbh9qfWdIOeIm93EGBATU9Rvl86CCe31ac92+vwK6DXXPj5gKHHJ19kfrtxMG1K1U09iCukgU/at8shGpNNXKj5ZlvA3qB0xdHv+hc74ga+cCr18jU5Imvf8cZaibG9KrceuIbNv7A0TUFny/X873vSUC/GNPKYnw6+3aWiq4NAPIb2YCr13tTousvid6QK2mlNbpP3r1PpljfacgKLM8fD/nMZ0gVv34fzsn8Ttr227W0gpLEP3erTK4SW9zBiRua9fP827f9OyuuYNhHvFTg8r0IER/H1sapCzikdP9n6MuUp9+N6dIXWK5QZ+x0n6t5ltv1nbLcsmM9top+WH6D+9wdy7uPghY/5X8b5ZqROol8FWvk7rer95c/f4EZRb1ADNSB8x7VnoTq3pm87HVe6d+H7vv4L1+4cverhiAfKb9Bg0qfjscy96WoLTvznL+20+Ck1OZBHjJAmq9K4YKfNX3UgXtfq+x/tlTQWpRl8Tl0pWs5EOnZ9t77Aic+YK2g+OUfAzcze1MAgDhYidD3eAfUPfVuh1NNmaHHDIFmHKRd2eiHWrfa9cBrN4iX/r+XTMMqFuagOsGyKAQc89RHXaMB9TOD5iZnQqa5lXRp3dtTWbrT32Be4/I/vbt2Vt/lffB7ONJtD0lO5zZVONmR1vTszfw/gMyzypoVYGR33JmgB+LAltXuOf9Ama9rCIo2BnitBKLGOsw7zkpj7tOO9QebXYDdzsK/KmPGyiFjCOHZrayer5s3x44LvG5mZOzmEFVPKAuTLwMAOpS1Njqru0HPPvT4Ov1wO3a/v513N2HASvel0lezMsvmg2MPCz5OvhNRhONeLPh1/aTqbAjxs6V323V749Z+6qOEux+nntZ07bEnQRzlkLzMfQM5q4/klPz/W1pcidC8aMy1L3Hei+P1LrlHE+f7+1KAgCjj5ZTvUZ90g/kNCjLa5Z86MwdPcDNUKvuHn7dNfQAOJ6hTha4pxBOM6DWM9QXfyyt/9TjW053kXNeBcZNl8umXiP9pOs3yjZMBdJ6Gcr52iDloNr9do4BdSu5AbVP0/RIHfD8z72HEZWvn5HT+S8kfplqvgWe+5m7AVeHLc0MUqqaRz2joo+MBmQQiOr3mI6Vs9NftiP5/GE5TTXA5Lvgvb8Dy99v67UgQLo+qFZdgH9ArXaCt2gTv/h95796KrjTgLL8PeDdW/yvi7c0M7YvKoCpXS/bo9q1icuZwUpdtXfnVA+o5/8P+OB2b9mGmcE+42ngnNfdFl0qiG/c6gZi5gCzlsbEwFyVBZgBgvn6qRIBNRWzHrSZr4d+xC9c5Gaj9UPn+u1VDXEqqtTisyTvoTl7nPlbAADdh7udI3TFTt1292HJ16N6gXRTMb38OykDUeY/n5ih9jvC0hiQoR53InDWTGCP84CfOv2o3/yzDEz13N7YgdF3JgvLZHCcEvTcWpqk64dy7hvudN2Au3N36iNI6J2cLKhTR1D0oL+4Uk79gmMg/ZIPRdWx958k6z31T4nLhELu4+UiQ51uQO23XDw41p5LaVc5bdomAxrtGDD3MTf4Dir5SDUJTTuVh9lIOhcVUA/wy1B/fK8ErsUVwCF/kA1LwxagaoC0swOAgbtKVkE3Z4Zbnwe4PwIRY4/924+B8ScnDiTYukp+kPQN0szLgFGHAd2GyPnnfy6nV/kcympukACzamB+ajbbE5XRCNoIfpeoH0u/95y2r/uP9p7f8I38+Pj96OozKfplqB87U053SVJaMMPJTu79f4nXqe2KGUCqYGPZ227Aaa6DHqwAEizrGcmNC4F+E4DyXm5HiEO0KYfNQHgHpyeymg5dZckba4AdD5LD+qaWJrde17zfplrZIQgXyuFns6baL6Pp9z/gtgvc6UgJKtXzjNTJzIcFJd7AMll7Pc9jauu0+HWpS+45QoL9bkMl25dOWVr34f6XlzgBdZfu3sv3vFA+d4telfNmFlb58E75u1xLOqjnptY9k5KP4nI5hA9IIFzYRQLTRa94lzOTHPrrVFzhDXj7aBnmqkHu9PEbF0mJZM9RwLjvS5bX/I4NngJ0HQSc/ZK0wxu4qwx+TVZeUDlQBtQN2Qv473R3nQAETmriN0hVSfb7U9oVqOwXfH24SF6bhBpqH1OvAcr7yA7S2OMkaJ/7OPDZf+T6ZFl0094/A4bt6573e34lTkDdsMVb866eb9gIqE9+yI2NOqBOEEXk1+qtjSgIWehZ7rOnpbIVKih95Azgb2Pk8J36sWquT/wymYe61IbdvHzOPYnthmwb+NtY4NEfJtZQ3zI+vVroh06R+wA6xMjaVlGHUjtDQE3t1wPHAg+e4H+dHpi1toWeuYNs2+52xQwgg8oxkmWoa9d5g7+ZvwZu2FG+Zyqwe+0P2gCzgCNDqotAvNykJniyiJbGxNrZemf72rQNuGEE8Pdd3WWT0TPMehZ442J3h7TSmXpZZeIjdcCNo4A/D5HbD9oD6OPU3044JfnjmY/5wHHAHftJUPH3ScAb17nPw6QOpyt9jLIF9XqVVPo/7u7nAnslKTMx6Z0/VK/wpBlqZ8fdLPkwA1rzd00xP3+ebHC5O3U3APQa7f7fdYj7/9zHJSt6+uMyWYrf45/8XzkdvAdw1M2yY+pXb16svY4llTJIbuQ07XonoA4qxUxaoulz3chD5TRZIA64ZR8qQ5wsoN7rYmD8dODwv8hOzQ4HAkfc6F6fySDLQ66WnVxFlbroz3PgbnLaf6L3vlVcYXYe2elw4MCOO28Go4hWqmloRlVpIUIh50P0wq/cMgJ1KFB161CDLf6+i9s/M1KHhC+TmYWJZ6h9glvzsKLaeC18ye1Nuds57vXpdP5Q6/nhXcBLv0m9fEemMlSc3p1ypaVJ2psF9WuedZ3/5eaRKjUoUQ+ozQy1Xl7x4Pfd8oHXr3Fni/Osm7Mt2bIC+M90pwba9l6nBA0YVMvN/A3wxrXe6x46xXt0TfnnHu62J9YMDNhVAhRVmmFSwcmGhcC9R0owVdE3sSYakIDUDKhVzbnKoNdvkNnr9Oeosmd+zw3w7jjo/Y5VQK2y9vp2ed2XEliobX+vUf7PD5DWguZjdhsq5R1v/kXOL3/P+3wOv8ENXMp7e+9vx4OBc98EfjFf/lQAU6K16rtMO9oRLvQGNBVJsqCAf/u5zUvls2Z2AynskljyUepkyNPNgs59DLh9H5nt994jvcmj4gpvgKa/FnoAGtkmWVB9Z8wMqM3MfRBVhgR4g+uEy4zf82P+AVyyKGFx7221mmT1nky/P/XtALf8Qj3vTEs+9M+AvpOSKZWU0l/fQbsBP/tSdiyLtOeo4pSgko8OigF1K21rbEF5ibaR//AO4ClnsIWZ/VSDCzYvc2uSI3XePTq1jK6lEVgxG/jyicTr9FnLNixye6KGCuSw5IDJkjFRGjan0XDf8cIlwCf3B1+/cbH3cPTy9+SQqt4+q71TgbTfIUtl3dfJe5l2BO28RAATrgAAIABJREFU3dB3ypYV8t1bPEtmA1TfC0A+b28mmdBg6dtuIKeyyXprr4WvyH0teyfxukWvSGeOlR/JYNvnfMo7FjqH1V/7g+x0f/GIe5056Euvbx4xVbKZOxwk26OP7gY++KfPE7C996mY2cZuQ+RQdlBZRHlf+XvjWjdwHTDJP5BpqnEP8SvqCKA+G+Mn97uvG+CfjdODaP312LbW/b+iv/c2eju9umoJcFTAkCxAee9W5zG1gHrArlLKoGYaLCiWbexH/5bzvUe7h8nNgNqyJBNY2U/+VCCtv2al2k5EqMAb0Kjfgp20CXd0awOmnDdbuA7bDxi0u5ahdgJqNahOH5Sayrq5kq3XS44ACcr19y8UBqZdC/zo1cSAsrSb9zd2/MlS7rD3z4AT703++Gdqkwyp2QkB/50PdVTFzEQXlUvJUzLT75NyrCk/cTO0BcWpbwe4AXU8Q53hoER9fVsTUFf2B/b/rVOPruk6SB6j3wT5fAOJ3XvU7I4dHAPqVqptakFFSUApum0E1PqXUG2sI7XeoPZQn+xVSyNwz1SZ5cu0ZQVQ6/xY3TbZrZWMtUj92K5neR+3YbP30FmNUQOZib9PkjISQNpPzThMRtjfd5T/bGftkZ1GQH37FPd5dlT5nr6aXCpAeu0PMhvgjMNkBkDAf1pt3X1Hyo6sTg9AZt8OXDdQuu6s/DCx7denDwL/Pjj4/h89A1j1sbvN0bc9CRlqLQjuO14mleixo2S1zVZ5flTLrBFTEyd6KCqX64P6JIcLgImnuuetEDD8QG+2Vdm4WLa1fj/KG42jBPOedf83D403NwYPStRrxfVWYEBiJj9c5Ja9pOpW0Nzg7aJR1EWylarPc0Ep8Mrl3hpXFUCV90FSqqY6aMCeGVBHaoGy3sDoo/yXX/dV8GPp28+pf5Tsf7yG2nktvud8ZvTA1NR3XPB1uuJK9wiD6hYy5SLJiJrvq/l+Dd1bAulDrnYnSAkydB/gBGdnZsqF7uWerLYTkMZLPoywKp3ezl0HyziraX9KXN9UQkaGOtnkLKmUppmt92NZwP6XBdfyhwuAY2+X/9X3TH02D/9L9o/bjjCgbqXaxhaUq0ldEuoTVUCtJhNo8B72ACRDo9c6m9kPIPXkCKs/Cb5u6D7eQ1UNm72HKLclaSlkSpblNH9UHj61YwTV8Qx1ioCzPUzjXrcRuKYPsOKD1Mua/NpatdbWVcAfe3tniusIPn0QuHl8+gNub99HZjNVXrnSv955zgyZQU8FYnrmcv7zwAf/kp62qSyYmXiZPqBHfVbXfpFY6mBmav188E93ghA9oG1pkh306wbLTHX64CBVC6wHYMf8E/jtav8fUCvsBr/hosSJIIrKJHBINnCv5wj3/8uWyyAxv3pglaWvCAgww8XAb9ckBqDmof/GLYmDEt+9BbjnUKkVLyoHLt/gvV3fcYmvebjQ3caW9UoeIG1b4922FHYxDv8Xe7etxRVugBYvofCZZAOQ8pBfzPfumOjMgDrWIudVYObJwlrJA2p9+xIulkz4hm9ke/W/X8jl/SYAv1sngwODmDteQ/aRrLMpXCgB3OUbEqewNpNEmQaopp1PkPXuowX7elZXlSGpbipmyUe6nTOyZWaoW3Vfee5TYR4VUp+JUSlaOnYQDKhbqaaxGeXFzgfaDLrMDhKRWqCH0YxeKesFnPe2/2hev7rnfS+VGisr5C370HXpIQM0eo8G9rxILmvY7B0kog92adwKvPM3//sCvK2bgnYedC9fLjWQy3wy68ms+CBxCtl8UeutAusVH8iMdKr+rz3VVq/8QD5j79zsf/2KDxKnUlbyMTHP/P/JwC2/Wt1ciTZLAJzL6befuUha0cXbxUXkMYJeo3VzJUuovHuz2xlB9/zP5Luot7nTzbwssSuGn7r1wGcPeb9TvcckLrd2rgTUFf2Bw/4qQbe5g2zbiTvk+uyAeh/dliYpK2vStjcjpgLH3Qn03FHO6/WpvXZygkufAVXF5d7JGxICaidDnWwWOz2gU4G0X8nHpmVyWtY78TpAtqlFXRJrps3BXg2bEwclvnKF1LZvWy2HtMOFbkBdVC7BrKqvVhnycJE7oLGsB/DjWcDxdwHnvJa4bl897U2ImAE1bO8RCj2gLqmS7On5ASV2oXDy7hChgsQgLFzkZnhtW36TTrxXnvs3Pjt6iv7dKSgCdnOmkjd3FvzaoZ2v/T70Hp14/cBd3ey2ojqAhAsTu3GY0623NqC2LFnvoMBYjZEKmo57ewXU+ud5+gPAhe2w1a3fuIUO2iLPDwPqVqptakGlKvkw29qZJR+ROmlFp+iDM477F9BvvP8Phl+P5OEHAGOOkUOw677yH7DYe4xsDCwL2Nc5jGxmqPXyjwUzgVev8n2eALzBt/l4fj+MoTBw267AvYcH36efe6YB/9g9s9tkKx5QO4csnzpfZqRTA0P1nQ+/fuLbk8qEBAUh90wD/rGb/3X5yFDHp8LNY1bj9WskAJ6fo+mbAff7qAKVV66Qx/ALGDLZoVIZw+Xv+V/fe0z6n6Gnz/d2VTA7OADA+vnA+q9lJ32PcyVTbG4rmrZ5J3gybXQGPRVVyLbAXL8hewMTTnLP6xnNZMFacaUb+IWLgclnea9XGepkKn2O1vmVfKgMtZn9ipfaOfdjPp5ZGrBpiff7rmerV8x2jxKogLq4Uv5XnyO106GXP5T1ksPa46dLYGgGsK9d7bYwBdySD6Wp1r3/UIEEJCqAKi6XbG/QIfZUQgWJbcsKSrTAzJbfpLHHuV1LdHo/Z/05h4tllsHTjTE/QW3o+u4MnOT04N7hQDmt1H4nLUtqc3XJZj/c71cALPltBFofUOvrUdIV2O8y7+WH/EFO432ozQx1mtN5Z8vs8gEAY44GevuMxwoy8jB3MqV8CoXkNdz7Z/l/rDbAgLqVapu0QYlm+594QA3g9r0lG6SXX6gfjN1+LCO0Af/WOn7T96oflsr+cvj2Wp8fH30ASkmVrMi2NcAd2obw43vl8G79ptRTlevtsPR1uqpKRvybUtWLtgcqYFIZFr0VFuB9zun2lc0XVTqUrN47SD4D6q+els9AUFeI1lDZ71z2Q1c7ACpQUd0D/I6yJGsbaWZ+uzqdBPxKcoornYB1swQLP56V2Tr7ZahXfiCD11RA5bcz/rexbj2ubsBkCV7Ua1DeS4Lzd42jH2aQ6ukI4GSE/bZZReVu8B0uBAZOlv7nqqVZUVlitqqrUQPtN/DLL8O1aak8nplxVp0dKvrKqRlYmZnDh0+VyY8UvZa9bj2wyxnyv3peAyZ5yz9UwN1Y4667WVaivsNBCsu8AXXECaj3+ilwxUbJ/qo641Tt1FIJFyZ2WSgocu9X/84df6d3uX1/5W2Zpm9f1H3ueDDw49fl/7HHJ1+X0UfJ56PHCPmM9XA+06rsxyxFCGqhCEhXq6u2uM+j1Oczk61fLwcOMIL7Pc6TdVffDcvyJhnSnc47W2rHsTWZ3lMfBs56ITfrk8qvl0v9+ncQA+pWsGMxnBJ5Ej0L6qWzhTmDV7w+NyrtlABvVlpNnWrWBZ77hrcP5mafQ8jqNn4114peWxcKy4banC1NdeTYuCh1z+l3/ubOxGUGT+ZhNlM6AdGK2cC851Mvl0vmoER1Xh2qTJaV397UocWGLcDbN6WXPa3fJO+b2WM4F9RrpmbQCyp1aI34jo1PH94NC4FPHsjs/pa84f74q8ytOjwfqZe2c2/9FXj/n1I+k+w9NzO/6jX2m62ucoB8Zxo2S2CXyQQKQPL2a+pwuF/2tqkG+Oy/iZeXdvMOmDv4Kvcwvc4c9R8PGkLJ6y2LK9zspydoc7YDquRDOe2JxFpZv3ppv64H21ZLAGvuaKoBZ6pDhxlQZzoWQXWp6DoYOOVh4Lg7vO+LCv4at0ogeZbPTLShVAF1qfezUbtetkX6uh9zG3DKI9lnphUr5FPyUSwDIQHvDqb52Sos9e5Q6u0b9fe7/yTg+zOkdVw6QiHgtMelzOik/3gH6Z/zmsysePoTiQF+MrnKUKcS37G03BkggfzXJasdhoJW7mBRq3GmxFaILHwDlxU8hIXLNwEfGdOmxmJAg7OR0Tc2esZCZWvMzFL/Xbx9T9UgpJ4j3axvPEOd7LCrUbfYbagMZPITbU4dMH7+X+DbOcCPXsk8G6nP5BTknqmZ3Wcu6Ds9+mn9Jgmu9EPAftP95kvTtsT3T22wV38ifz1HBI/IV164VGpmkzX7z1bUCGDMw8e5EArL59+cHAIA7jxABv5NPM09nBxtlsAq6LN2/zHu/5uXA8MggYUdk8f4ZqaUmQAyHXKyrM3WVRKcq8yqyvb6HempGgBUz5MBU0EzIiajZ28r+kuXgXVfyqAeNftp0AQei2dJ5k/veFHazZu56zteDuF/dJf3tmZGWAVgqXoWl/d2j9jph7zVfnVRmbft24iAziRjj3cnhwCCEwiD9pBuDx/d7V42+Uypad/HObysAqteo+XI3sRT5b1//zZ5nDeucz9nOxwErPrI+17qr68aRKV3rFCTizTVyP37lawcezvwyGnyvz6jn1JkZKhVjbseFBZXAKMO9X8dMmFZicGeJ0Md8y6rK+zi3aFs0H7j9O2AZQE7p8hOm4Y5R1ArjfZ9A52Wa6mmUFfUjpTf+5APJVUyruCgK+RoVf9dZGCv35GvXFLfxe9YT+eOiBnqVmholBrHLjGf7Nkb18pAJwDYoA2w039cVI2TX32a3w/uETe6dWsq+2z+4J3xtDsi3xwkcVTAYDZAfgSCAmp9FqoN38iMYLP/FXxfvvfv8xq1B0EZ6jevBx4zZpvM5cC4ZJa+Ja3RlrzpvdwMYPWWZ0HZavVDl4/X38wI5mWHw/kh91t/1UVDrzW+Zxrwp77p3fWzP5GuG+qQbKTOWwbQuAW4fa/g2999EHDzOKmZtu3k9dHqR33jIidDHRBQ6yVhOv3H8pfzgN2cNnx68GJmEUcdIaebFrvlKEppN2+QVlTmP8GFuT4qw+pXgqLrPcY7KDFOZajL0suwnjjD264sKIFw5E1Ar5HeiUsq+gJnPu+W06nnGy4AznhS6o93Pl6yyXv9xNuT+Iwngd+slCyp4tdFQQXUOx7svsfJJs8afSRwxE3ObQ4Cdj3be31hF/+a2+2VZQ0Xa4MSkwSChSVA94AB9vkehJcuVWdtdg7Jl1AYuGg2sJPzvVOlGLksV/OjvhNtPcaHGFC3Rr0TTxT6zSiqH4rWO1ZEtgE//1pmD5p8thzG8svO+B0SLiwDTnkIuPADNyNnBjUlle4XOGFkfUB7JQB47CzvJBHKnhf6N79fkmENqF9AVLseeP4XwKo5wOt/Srz+g9sze4xsxAclNktXEr0WcP7zwNMXuefNgPHTB4Gvn4WvNV9Ie7VUG9Nos8yuqZcJqEPRy96WyShU+0GztZ9+38km6AH8M7yAfDZf+l123UzM9cl1WYlta6U3xvrP1TpVfPZfYLZzCDio4w3g3/ZxzedukBipy+45LHtXXv9kOxRqkFWkNnlA3W9ieo+pyjX04MU80uXJahuBqBlQqyBKP1R98n/dgXaKqsf2DJJ0NoBH3eoGLz1HuOvmyVBrJR/ZlCwEZahV0F7aVUotzn458SiFysgH7Rj71aDr75NfrXhZT6mHP+lBt97c/Kya1HiNcFHidr6w1D+x0dp66XQVFGufqSTbrnARMOkHcnTIlHSK7Tagt1/cnuJjXvLcKUp9J5IN1KTtgiUfrdDQLBucQivFF0ZvZdVYI4d/FXUYy+QbUJdKkKy3Fpp8JrDmM+CblyVTV1ThBtnmfegBdq/Rcshaz/It8Dm8bfaxztaGhRJAD9rD3Rl4+fcyq9qcf/vfZuavgT0vSLy8ZrX8+OkZ+PXzJDj264aQjqVvAR/61OXpbc7Wz5es36YlspF+xgm2r/LJSD11ngzyGjxFjkRU9JfDqUqkTjIK6+fJ7Jo13wInO9kwS9tZevZi9zHMtm56BilVQF0bsLF9/ucyYdDOx0u2rbZaAkyVrdy4WEqF/Go/zcfMda/u5gbEf9TNMgo1UQrgDh4bo5VzxGKJXQX8uuXUVbuva6QueMdD8dtB+vbj1LO/6T2SS7t5A+Fp18p92DYw4WRgsdZebej3ZHImk8qW6vdjlnyoUhDAHZinWKHEDDXgPZw+fP/Ex514uuwsqjIKXXlv4IS7pXRitDa5kyegjrmPl812Rc9QH/ZX4MVLE5cZEnBUYej3gMF7BZcg+NWgp1PrPsDZibBtqUNP1mcZcHdEw0WJQbwVcrfJ40+SbWZRmXe229Y67Qlg6Rvu+X0vlXEDgATUpd3kd2XSD4LvwwpJ4DxkL3fSmfbm+LulpCZV3Xq+HHu7fBcG5DlDvsvpMvPy3j4zo9J2xQx1K9Q3y49DcSSDqVSDAmiTXwbLnFIVkMBn+v3SNguQjaHaYJsbaz0A/f49/o9hDmwoKgvur5mJh04CZhzq3ZCnyuQA/gHMTaNlsgWluQH4555yeD7bw15+wbTpjWuBP/aQ1nRL3ki+rAoWHjoJuGWC9CDW3X8s8LcxblZBD4xCAZkNs1OHXupgdpgx1QZMna6CqrVfShB6w47A3c4Rk+pvZDbMt2/yv60ZfOY6Q60H7KkCXcC7Q+hXx+zXA3rjIvf7EqlNXRrj9xy//dh9H4Om0NVnIDO7DoyYKt/HE2ckDgKcdq1MLKGoySNUsDximnudeVs9Q63eZ3WUqutgb0Dtl1X0q7uv6CPTJPuVIIQLpYXfCXd7M6q+JR9d3MfMZLpj1Vlk/MnA7j6DKJPpvRNw9ovBt/OrQc+k1t2ygCNuAAbvmXw59T0OFfiMkwgBA52WoXucD/zgadnRzmWnihEHA1Ovcc8f+Hv3sxIuludx1C2JMxoO39+7nmr59mr8icD3ftF2j99zR+D7/85/CUxxuWw79EQdtQlmqFuhwQmoixqNAXrm1KOA9MT8wTMy2j8dQSUfQQ66UjbA5b3cQMxso6PfvqjM/zBi/4kyqEJNYV5Y5t/8P9s2bDVatj6dmtumbf4/dOu02fn07ODWVbn98QmSrE7yw7ukXEO37B3v+VUfyqkafKrXwgcdKjTLe/QdkqAMtcq+6gH1/cfKRnj6A+5h6tWfuD+qaiCUKgFaEdBX2Tw0ncuAOhaVnRGlaRsw6zrZgVz1kf9t9CC6YbP7OYjUA4+dKUdblP67yOv8xSPuZZE6N6DuM877GYvPdmrsuAzeS14f9f72nwhs9enyoWdjVRDVeyyw3ph9zgxi9WDzsuXuzlavUcDPv/JuTwZP8d5WD6iLK4FLFsl3qa5ajph8O0euC5phLd1D92q5oH67+uUqQFV165cty6yPebgAuGShfF9yXVqQquQjV9Tvg1+yIlQgmeEdD/LOWZBv8Y4sSXomn/II8N/pwNI33efAgXBEccxQt0KdE1AXNG7yXmHH3FZiSkU/2UCm+yOQboZaCYXdQTEqiDL7X+qHwIvK/TNQRWVuOz9AMlHmOpuZi0w0bAY2LJK66ZUBgZG5vM4vY60Ht3p5zZI3EgfyZcPsjwsYE0BEvAGz3r9WCRpUVD1PTs0Z2oDEGmVzJ0bPpgZlqNVIfL27y5JZwLzn5P7UfdSsdqcWVs9XXRcUcGUSUNs2sPj15NPXA1IStWK21JTrgXP1Ahko+uKvgLmP+d9W36lYoLUsW/sFsPAl72yHReWyA6pb+qa8DqHCxGxPuFDeY7NsZKSTIVbrFHR4Vx/wpwK30x6Tw7T64C7zO64H4qVdvRlNc3sSLpSgJ7689pglVbKzXVAstwuF3BIH87N51kzgyCQzpgYxtzd+gfapjwIH/M7bG9rM0qZS3tsN/A693u113Fq+29wcHJ0z7X4uMOUnwJSLvM99n5/LTpFlbd9gGvBOwhOksCSxTEcPqE95BDj6ttyvG1EHwYC6FRqajGBNb+9kyrR1j9pQ6T/66faZVJnMZIeagjLURWXejWqZT51ja0ZN128AbpssHRKakmR5FTOg9qvTbdQykzXOYf3186RF2rM/yX5dlYOudP+fdq3zOFrg/vYNwL1HJPa1VRMwAMEB9XonoNafpwpUzdaEZg21J6gPqF9OVgITbXZfu8at7mQ9KjBSr2VQ5jEhoE5SQz33ceCB44DPHgxeBpCynXumuo8NSNbObC/mR9+peOk3Un8K+K//zick1tLWVUs9f3FFYoeDlkZ5j1//o/fy4fvL6ZrPgPI+3p1RnR7cqiCtaoDMsqbv6JpHoZJlDP2MOlQCVsCY2Mmvp7NTPjHF+I4MmZLYfSIdCa+zE1DrQVePHWQmu1xll/e8oHU7+DrfCWrykKEuKgOm/UlO9YD94KuCZxPMN/U5S5VxHnO0nPabIKfqPQ8VyM7lpDPys35EHQAD6mwtfRuHf2LU4p3wb2APn0F0QOq+rSbLAi7fKBkYJd2NrcqGJfsxKCh2A+rJZwLD9nNuU+79EfebmSzbgX9A4uQ3QfZxat/MgNqvtMEvQ60Cyc8f8r//B08A3vxLeuuiv44qQ6PPPqf+X2ccvte7qqjXcfl7wC1aJwdV8tGwWZ7bDaOAL59IfIx/TpFSEp1e4mBmqGvXA9cPTh6IRiPua9dY49YBq8BYvZaxFsk+37Y7cPs+Uo6x6FUZzGjen+6eQ936a1XaYL5Gukidu776rJTlfXwXT2DW5L94mayDuSNy6WL5zAcNViouD24Z9vUz3vMV/dwguNswb0BdrA1yM/sIB0l2FCpd+14KXL7B2WlW02T7DLgr7Qb8vloypa2iMtEBO/DtpY1aNlSAmY9MNeA/ELItxKevThFQjz1OPluqc4ZavkuP9tfdg2g7Yw11tt6+MfGy4gpv8HX0390uDekGBTrVdP8nc4C1c5Mvqzv8BhkVbtZU6izLDahLqtxDsEVGzbS5kTzqFmDQ7skfv7RbcNeDdKfvNifLUPxKG5qMDPWCmTJVsPLWDdI9YfVn0gfWtiUgXGTMzFZQ6h3op+ilMSqg1ktLVJ2rOfBP3zFRr+Nrf/S2J1TrXrsOeON6b6nQVi2gXv914nolq6FeOdsNlkceKhOWmGIt7uM31bgZcZV5Vlni+k0ySYLqp770TQlWTR/fJyPOC0vlNV7xvvx97xfAOmf99RaSJr2cQv+cVPTz7lz0myjPd4NxX/p7DgBfPSmnZua8pCr5j39xZerJGI68WepIK/rId6a5TkoqumldMo79B/DI6fK//llINshX/+6d/kTydQhiWW4QW9YD2FIXHKhnmgFPpiMHzsppT3inW7csGTCabjvDTPWbAOx3mYyxaUtq5zKdQYb6+6yW14/AEHVSzFBnyy+7VVzhHgIbMU0Gl5Q7gaq+kc5UzxGZzTZV2lVGsqfKGGxaIqdVg9zDpn3GJh8kNPnM1JMMDN4rdUssK0UrI1UiU2sEScky1BX9pWvDQye5OzKAHKa/+2CZoax6gTuDlumA3/hf7un1WyGvj16SoDKg29Z4a7ztmNt6Sq13UEZq0xLgXWPinZpV/ssqqsbZtmXgnU4/sjD5TP/bezLUW92AWu20qOx5/UbvUYAHjpPXue947/2tmwt89bRzG21cgW27/aE3Lgp+PvpUxvpOh1nPXN5HygZM5mdF0Xd+AP/Ar0qb+KSoPHX/8B0PAib/0Fne2YkuqvCWWQTNYuk3+E3Rv7NqQpLWOPhqOU13MHQ+5Htii1wacbAMLNXtfIKUquRDuBA44LfA+On5uf90qfco0x0sPUNN1MkxoM6W2cmjoEQ2jurHWm2YVCDSmoA6X1TgvPMJwB7nAVdsluArVSDuVwaiKyj2zq5o6j4cuHKT9Fb2myUScEtkZl7mDeb0DLXqgqGu7z8xsQxBUSUgnz7o7kiYxh7n31Narw0tKJHD6HpArQK5LSuBq7XXJhaVoxT9JrhZ0nqjLro1atdL3fY1fYCnzvU+rt5BJWgCDb2GOlLrZtijERnMqYLaDQuAO76XeHu/+1U7AXqLuqu7us87Wb9sPZO8SQuoK40BWn3G+A+oXTlbTk/4t/f7uXl54rKmQ68DJjv9nksqk0868qul3oGqqhwg3cF16ZQPpNrhTNfOx8tnOmha8lwI2l6wBKDjUEcw/L5XycQDamaoiRhQZ8v8wVM/pvHR0s6pKiHIpNdqPl38iczsBQCnPCwj+tXGMFmN9k8/dUfThwuAHzwrjfMB6Q07/X6Z1ACQQ/4nPeD2U1VUD1l9tjOVres5ytsbtaTKzaxWf+Nermcx9XKFUKF3whtF1aCr92Hj4uCAOmjQp56xLyyVPz0wVqUGZlmOCvgLSiWQXPmhf8s3M2BM17q5MtOk2X4wGvF23Og6BL5aGqVUQe0g6fXW29ZIZjrZIeAjfPpTq8GaNWsSrxuyT2L5RbRFatlr13vXWd9hUZOiFJUDJ94H7P/b5EdRwoXeEqstaQTU4WJ3kOfQfWTQ2M7GBB3jpgOnP5kYPKhgRJVyXPgBcEFAq0EgdeD9o1eA//s89Tq3ewyoO4xp1wKH/jn1pDQm9TvHgJqIAXXWzAy1yjr5TbcLuFMFt7UeO7itvboPkxH9fkYeKjORKd2He0fTD9/PPRRf3kdmqVMZzq6DZQO7w4He+1SPqweAKnO/w4FAz5Hu5YWlwJ7OYCk9ANYz1Hq5QkmVt/2YMvkseH7Yt61ObGmoBA3IMTPUZj2qqvc1s8+21g+8YbM7QM88/O7Xli+Zin5SJ19QmtjHGJBsvMoE99opsR+5svpTZ5lR7mUquFeDB4MmIhox1b8DjCqv8JtEpd8Ed72iLVIDvvIDYNafgMfO8tav166V71jfcUAPZwCUHQPGHitHf/Sdv54jvUdEBu7u3YlIp26/oEh2CAdPASb9UD5/ZnDRfZiUepjUznW8v/To5AN3U00jPWh3oOug5Mu0J4deL9sHvX6cOpbeo4E9z09dzmdiyQdRHAPqbJnZXPVjGh/cYQbUHWyDc+p84bBMAAAgAElEQVQj7uyLQVQGVj13VR+8izMQyzzkq1oA6p0Q1KH1guLEwLXbEACWEVBrQZcaxLZlpfwQmHWOhV0kmFTtwQDJnAaVHagBYaollKLX3BaWJrY2CwrYVPvCglLphfzNixKImjXNmQZPv5wvNfLjp3t37CacKqc37eRme099JPH2ytNOR5rhB7iXqamd1SBIs6+yOiQc1EFGZZa3+czMWNpNdjKizcC9hwPXDZCBogCw/B1vhtqOydTL57/jvn/6QEF1lGPvnwE/+citXZ52rTwH/TO2xWeiFVO4GBi8B3D2TPe+zMA3MLOsZv9LsxPEd60UYocD5AiWueOm2ka2Zf025VdRmRwtyrQtLNF3EAPqbJkZavVjq4JMM6DO5Wj69kINilP1mdOulUPd8UkJjMChaqBcf8SN3ssAoGGTt8NBcYUzCcUgd+Y+wJuhXvOFDJxb/Jp07xhgZFPVe6K3LKxbHzy9tAqcf/gcsNdP3cv18gK/DHUQFQDqgUb34cmniFbMcgM/U69xy3cA74+aGlDoV8ZilivpXVtUqYQKjFV2WFFZyKCAWmWom40e1QUlboC6ba1b76wGKwKJ04urnVCVNdNnjuwzRp77gc5kLaqURC3bXcuWmpOx+PHrVW1OVBIUUKv3Odlgw85or58C57wefBSMOr7iCvkeTjy9rdeEqM2xbV62ggJqlWVTP9AnPwSs+S7UQ/rY4QAZ0Kg6CZRUAiXaoe49zpWShN3PAz77jwSTZncU1a5v2zr/NnNdB7vBIeDNLq/4QMo97Bgw+mip7f7+DOBxZ3CZyhhW9peJNwBZNmiQmnrMkirvSH892CosdbO0VYMTp5kOF8kEB1YY2N/pGqLXIReVSWZ56ZtuT269W8aYY2WZCScDXz7uv55KSaV3PfWAWg3OVIdkf/icTHRjx+T5NThdOMYc4w3w1c6HKt/pZtRfl/cC1sN9bU99TKZRf8spD6pdLxloc9bEghJ3x0KftVGvb14x23sbFRyrU9uYil3PnjcbAfUe58ukOV8/HTyLJCDvkx313+FVfbV7jAD6jQ/eyVEdEvza4R37LzegP/G+4Pr976JQCBiYo0lXqP3qNz71MkSdAAPqbAXVUKsfYfUDvdPh8vddVFgqPVqDlHaTwYoAMHRv/2XUYeHBe/oPgKvsJ4P5FJWJ7D8J+OJh93KV6d75eFl+9u2JGeouPaXOefMyqbFtaUzsHR1/bloG1tN3tdANqCv7A4dc7QbwgOw0nGTMBqjXBvffRQLmE++VgLr/Lt5D4tPvk1N9IGa69JZ8KvOrsv7D9pVBRy9e6g2oD7rSO7JflXyoziVVRjmKGsCoMtQjp8qfCqhhy2tqDj4MF7nZcr1tod7BZfbt3tuoDLV6XuNOTHjKcWaGurSrvJa3TvIe4TCFwkA06v/ZU5+pyWcCeyWZcTOeofbJYE88xf1/7LHB90FERB0aA+psJXT5UAG105M4aLpm8uo2FPjFPCk18MveVfSTAKx6AfDKFUDvMXL5rmcDz37iLqcP+lQBmAr6VJBY0U8C6voNkpW98H3JeP/VZzCjXj9r9i1WJR8lVYntEAt8BgCqiVIOvsrbm/iX30gA6FeDnU2bRf0zp8on9IGWKsOrB97hIm99fzxDvVZ2Es31iPdcTjILZ80abzcWQHZAVYb6f79wL6+rliC90WeKdLVeoTBwycLk7RpVRtwcVJWqPEd9j/0y1D1HAD//Oo36UNXDN8VgQyIi+s5iDXW2zAy1+rFXHSy+C7OGbS+V/SVo8tsJqewvr+mHd8psf+84nTLGT5c2bIo+SFQFk2r2MTWATQ1uq98oAXNRWXDgqmdtzVpaVfNcUJxYD+3XwUHNaNh/F+/lFX0kkPMrFSjtBhzwe+DA3/uvn+70J6W0QA2CVApKvAPgVGCvB9QFJd5gUtVIb14mAbVeF3z8Xe7n2hyYOf1+t8Rl22rJGFf0d99Ty/IPOBu3ajX3Br0VV3nv5OMQVIbaDLpTDRQMGkSsVA1IPYhQZajNbQIREXUa/AXIllkLrDJjqmPCsP236+p8J6jsrh54qYypPs12kTNg8WSjtEIZuJuc7nmhnKoMtd7tI9UEBnpm09w5Uu0Dt6xIDKjVzIg6FcgGtaTyKxWwLGC/S4G+ExKvM+14kJQWNBqT0phtAFX9uT6bn7mM3rqwuMINJsccIzsx8cDTmP1uzDHArj+S/2vWSMa4rKe091OC2vcFdYHIpDPObs5jl5oBtRP4q52i8Sd7r1cZ6nSmXA4y8TQ5zbT9IRERfWew5CNbZtYqHlDvB1y+UQbIUWZUN42eWmcJdbhdtXED3L7JQQHq2GOBkevcAE4FbJ6AOsXhef16M0OtAupwkbsOXXoAv1zgf2RCBXlBJQtmtlcX1Bvbj7mTZ2aE1eA8Pets3n9pN9lJqKt2M+eXb3SzryqgVmMFdF16yGulMtR6Zw8EZKiBxKnF9ftL1wG/A/b7deL3TgXU4SLgd2sTX6OqgcD6ra1rZbfbOdLvnN95IqJOi78AWbKtsLcpnB7c8Yc1O2U9gKNvA0Yc4l6mJujQO0Poh+dPfsi/ZEDPhvYcKZnSIXsB797iXJ8qoHYy1FZYyknOfQOodwbyVfQFjr1dZtQLhWWq6/67BJf5nPBvYOFLiR0zlGQzVGYSUE84RTL5nz8kr5d523imXAvszVKHUEiOCtRVa7N/ap9n9Rz9AupQSHZa6jY4AXWxuw6WlXmGOpNJJizL/3unSj4KivyvP/0JYMms1s30FvTYRETUabDkI0sxs8dypjNMkb9JZ7it9AAJ0FQGt6BUstj7XuJev9Phqds2WZZMhKIPLktV8qECbhVw9t/FO0vexFPdQ/zjvp84qYyuoo9/KYiuvA8wxaeTRCafq3AhMOVCN2A2B0hOcDpOjDzUvUxlZvc4330+6nUq8ilF2fkEOR0V0LmmSw8Jxlsa5TXU1yEwQ+2zQ1RclZtxCHqG2k9lP3kviYiIWoFplSxFEYLn4DED6vywLGlFt24u0HNHmTkvW3oQnW6GensNLr0koE2eGliZiXhW1shQD5kCXLXV27ZOOezP8ge4GWO/jHLfcXIfQcp6ORnqJm+GGsky1EYXjVBh6zLGulQBNRERUQ4woM5SzGaGervpPkwC6uKq1MsmEy6SWmA75s2WnvdWYh1zuFACu1Abf0X0mt8L3kts1+hHBZFBOw2pgsuR04A5//bOYpiusl7AhoWy3gUl7usc1OUDSKyVLijJfUBtHlEiIiLKIQbUWYqa1TIMqPNHdZ5obbbYsiTzHKn1Bpv9AjppFHZpH5nNw/4CrJoD9BmbelnADSKD6q9T7STseAiww0FSfpOpsp5AzSoZgOnJUMOboR76PWDZ2/J/cSUwYiqw8GV3vTMZkJiMOeESERFRHrCGOksJGepUJQSUvXibuoApwzOhgslUNdSAtM5rD/3E9zgPOOGu9JdXQWTQc0y1kxAKAWc8CYw9Lv3HVMp6yhGAhk2SkY7XUFvu+ux4sMzQqJRUAqc95p7v0j2NyVTSpAZWJpt+nIiIqJWYoc6SJ0N90Ueta7tFyQ2YJKfbAqYJz0Y6O0AddSdJlYmo9oKmfO4kqElOAKPLh/O4F7wns2NuXIT4FWrw4y8XyEyj0UjyWREz0Xu0nDbV5Ob+iIiIfDCgzlJUn9ei18jA5SgHKvoCe1wAjDqs9ffVtE1O0ykpKOziTiXfkagp3NU07SazF3Mu7fx94LU/yP/hIm1H0zlVZStqIpXiSrdtoN7dJVf67Jz7+yQiIjKw5CNL0Vgs9UKUO4ddL5PmtJYdldNkbe6UwtL2UfKRKVUiM2iP7f/Y3YYA066V/yO17jTnOx3pXU5lrktaOdA0FfU4Zb2TL0dERNQKzFBnKRaLtvUqUGt0H556mY6aod7rp8D4k3JXh5ypUqdDR/0mGaz7y298OnmogLoSeXfZ8vxm5YmIqNNjQJ2lWJQZ6g4tnZKPKRd1zMFsoXDbBdOA2/KuQc0s2SdxmfB2ylAD3pkhiYiI8oABdZaizFB3TIP2lP7K6QwiHTkt/+vzXdR3nJyOOTZ4mQKn00jxdshQExER5RkD6izZrKHumM560duJgnKvsj9w+cbkZRbh7VjyQURElGcMqLPEGuoOKhQCx+ICOPVRd4rxfAin2LSECwFY26fkg4iIKM/yGllYlnWoZVkLLMtaZFnWr32uH2xZ1izLsj61LOsLy7IOz+f65FKMGWrqyEZOA/q2YUs5ywIG7+l2JCEiIurA8pahtiwrDOAfAA4BsArAR5ZlPWvb9tfaYr8H8Kht27dbljUGwAsAhuZrnXKJJR9ErXT2zLZeAyIiopzIZ4Z6dwCLbNteYtt2BMDDAI4xlrEBqCLKKgCr87g+OWWz5IOIiIiIkGZAbVnWE5ZlHWFZViYB+AAAK7Xzq5zLdFcBON2yrFWQ7PTFAY9/rmVZcyzLmlNdXZ3BKuSPzYFtRERERIT0M9S3AzgVwELLsq63LGunNG7j15fMNs6fAuBe27YHAjgcwAN+Qbtt23fatr2rbdu79urVK81Vzi+WfBARERERkGZAbdv2q7ZtnwZgEoBlAF6xLOs9y7LOsiwraG7mVQAGaecHIrGk40cAHnUe430AJQB6pr/6bYcBNREREREBGdRQW5bVA8CZAM4B8CmAWyAB9isBN/kIwAjLsoZZllUE4GQAzxrLrABwkHP/oyEBdfuo6UiBNdREREREBKTZ5cOyrCcB7ATgAQBH2ba9xrnqEcuy5vjdxrbtFsuyfgLgJQBhAPfYtv2VZVl/ADDHtu1nAfwSwF2WZf0cUg5ypm3bZllI+8QaaiIiIiJC+m3zbrNt+3W/K2zb3jXoRrZtvwAZbKhfdoX2/9cA9k5zHdoV245ind0VfX77ZVuvChERERG1oXRLPkZbltVVnbEsq5tlWRfmaZ06BtvGNpQBxRVtvSZERERE1IbSDah/bNv2FnXGtu3NAH6cn1XqGOxYFDansCYiIiLq9NKNCEOWZcXb4DmzIBblZ5U6CDsG2/LrDEhEREREnUm6NdQvAXjUsqx/QQYPng+gU88bLBO7MENNRERE1NmlG1BfBuA8ABdAJmx5GcDd+VqpDoEZaiIiIiJCmgG1LenY250/AoBYDHZGM7ETERER0XdRun2oRwC4DsAYyOQrAADbtofnab3aP9sGSz6IiIiIKN2IcAYkO90C4AAA90Mmeem0bJsZaiIiIiJKP6AutW37NQCWbdvLbdu+CsCB+VutDsCOAayhJiIiIur00h2U2GhZVgjAQmc68W8B9M7fanUAdox9qImIiIgo7YjwZwC6APgpgMkATgfww3ytVEdg2VGAJR9EREREnV7KDLUzict027YvBVAL4Ky8r1UHYLGGmoiIiIiQRobatu0ogMn6TIkE6fLBgJqIiIio00u3hvpTAM9YlvUYgDp1oW3bT+ZlrTqEGANqIiIiIko7oO4OYCO8nT1sAJ02oGbJBxEREREB6c+UyLpp3Vs3YHR0Ab6ydm/rNSEiIiKiNpbuTIkzIBlpD9u2z875GnUEr/9RTpmhJiIiIur00i35eF77vwTAcQBW5351OhaLATURERFRp5duyccT+nnLsh4C8Gpe1qgjCTGgJiIiIursso0IRwAYnMsV6YhCiVUwRERERNTJpFtDvQ3eGuq1AC7Lyxp1IAVoaetVICIiIqI2lm7JR0W+V6QjCiPa1qtARERERG0srZIPy7KOsyyrSjvf1bKsY/O3Wh1D2GZATURERNTZpVtDfaVt21vVGdu2twC4Mj+r1HEwQ01ERERE6QbUfsul23LvOytss4aaiIiIqLNLN6CeY1nWTZZl7WBZ1nDLsv4G4ON8rlhHEGLJBxEREVGnl25AfTGACIBHADwKoAHARflaqY6CGWoiIiIiSrfLRx2AX+d5XToMGxYs2AgxoCYiIiLq9NLt8vGKZVldtfPdLMt6KX+r1c6FwnLCkg8iIiKiTi/dko+eTmcPAIBt25sB9M7PKnUAIUnshzixCxEREVGnl25AHbMsKz7VuGVZQ4FOPO+25WSoY8xQExEREXV26ba++x2AdyzLetM5vy+Ac/OzSu2fHSqABQ5KJCIiIqL0ByXOtCxrV0gQ/RmAZyCdPjonlaFmQE1ERETU6aUVUFuWdQ6A/wMwEBJQ7wngfQAH5m/V2i/bGZRoMaAmIiIi6vTSraH+PwC7AVhu2/YBAHYBUJ23tWrv1KBEBtREREREnV66AXWjbduNAGBZVrFt2/MBjMrfarVvdnxQIgNqIiIios4u3UGJq5w+1E8DeMWyrM0AVudvtdo328lQW5240QkRERERiXQHJR7n/HuVZVmzAFQBmJm3tWrnVIaaiIiIiCjdDHWcbdtvpl6qc7ARgtXWK0FEREREbSrdGmrSOVOOv3XQk228IkRERETU1jLOUBOAWAxPRvdBaded2npNiIiIiKiNMUOdDTuKGEIIhVjwQURERNTZMaDORiyKqB1C2GJATURERNTZMaDOgmVHEYWFMDPURERERJ0eA+ps2DHEEAIT1ERERETEgDoLkqEOMUNNRERERAyosxKTQYmsoSYiIiIiBtRZsOwYouzyQURERERgQJ0dp4aaJR9ERERExIA6C5bqQ82SDyIiIqJOjwF1NuwY2+YREREREQAG1FlRXT4YTxMRERERA+pM2TYs2Cz5ICIiIiIADKgzF4sCgEw9zhQ1ERERUafHgDpTthNQs8sHEREREYEBdeacDDVLPoiIiIgIYECdOWaoiYiIiEjDgDpTWoaaU48TEREREQPqTNkxAJKhZjxNRERERAyoMxVjyQcRERERuRhQZ8rJUNucKZGIiIiIwIA6c9qgRHb5ICIiIiIG1JliyQcRERERaRhQZ8pmlw8iIiIicjGgzpQ29XiIrx4RERFRp8eQMFNa2zzWUBMRERERA+pM6RO7sIaaiIiIqNNjQJ0pdvkgIiIiIg0D6kwxQ01EREREGgbUmfJkqNt4XYiIiIiozTGgzlS0GQDQggJYLPkgIiIi6vQYUGcqGpGTUEEbrwgRERERtQcMqDMVz1AXtvGKEBEREVF7wIA6U05AHbOYoSYiIiIiBtSZi5d8MENNRERERAyoMxeTDHWUGWoiIiIiAgPqzMVLPpihJiIiIiIG1JlzSj5iLPkgIiIiIjCgzpyTobYZUBMRERERGFBnTgXUYQbURERERMSAOnNOyYfFgJqIiIiIwIA6c06XD9ZQExERERHAgDpzTskHGFATERERERhQZy4aQQwWQgXsQ01EREREDKgzF21GCwpQEOJLR0REREQMqDMXbUaLVYiCkNXWa0JERERE7QAD6kxFI4gijIIwA2oiIiIiYkCduWgELRZLPoiIiIhIMCrMVKwFzShghpqIiIiIADCgzlw0wkGJRERERBTHqDBT0YhkqDkokYiIiIjAgDpzUZZ8EBEREZGLAXWmohE0I8wMNREREREBYECduWgEzXYBCsJ86YiIiIiIAXXmYi2IMENNRERERA4G1JmKZ6gZUBMRERERA+rMRSNOhpovHRERERExoM5cLIaoHWLJBxEREREBYECdOTuKFtvioEQiIiIiAsCAOnMxJ6BmhpqIiIiIwIA6Y7YdRRQhDkokIiIiIgAMqDMXcwJqZqiJiIiICAyoM2argJo11EREREQEBtSZs6OIscsHERERETkYUGeKJR9EREREpGFAnSE7FkWMJR9ERERE5GBUmCmbGWoiIiIicjGgzlQsxkGJRERERBTHqDBDlu2UfDBDTURERERgQJ25GCd2ISIiIiIXA+pMsYaaiIiIiDQMqDNlx5ySD750RERERMSAOmOWk6EuLOBLR0REREQMqDNj27CcDHUha6iJiIiICAyoM2PHAABRO4RCts0jIiIiIjCgzkwsCgBS8sGAmoiIiIjAgDoztgTULPkgIiIiIoUBdSbiGWqLGWoiIiIiAsCAOjM2Sz6IiIiIyItRYSZiLPkgIiIiIi8G1JlQXT4QQhEz1EREREQEBtSZ0TLUBQyoiYiIiAgMqDPjqaFmyQcRERERMaDODPtQExEREZGBUWEmPH2o+dIREREREQPqzGg11OEQSz6IiIiIiAF1ZpwuH1Yo3MYrQkRERETtBQPqTDgZaitU0MYrQkRERETtBQPqTNgqoObLRkRERESCkWEmmKEmIiIiIgMD6kzEM9SsoSYiIiIiwYA6EzEOSiQiIiIiLwbUmVAZ6jADaiIiIiISDKgzwRpqIiIiIjIwoM6Ek6EOseSDiIiIiBx5DagtyzrUsqwFlmUtsizr1z7X/82yrM+cv28sy9qSz/VpNSdDHWLJBxERERE58la7YFlWGMA/ABwCYBWAjyzLeta27a/VMrZt/1xb/mIAu+RrfXIinqFmyQcRERERiXxmqHcHsMi27SW2bUcAPAzgmCTLnwLgoTyuT+upLh/MUBMRERGRI58B9QAAK7Xzq5zLEliWNQTAMACv53F9Wk9lqMPMUBMRERGRyGdAbflcZgcsezKAx23biVjNO7Kscy3LmmNZ1pzq6uqcrWDGnBpqcFAiERERETnyGVCvAjBIOz8QwOqAZU9GknIP27bvtG17V9u2d+3Vq1cOVzFDqg+1xYCaiIiIiEQ+A+qPAIywLGuYZVlFkKD5WXMhy7JGAegG4P08rktuxDixCxEREf1/e/cbZFt21gX49/bpm4QkwCRmojgJTCKDEi1J4lSMjFqRIEalEj4ETQRMRZQvpAT/J6KgqeKDVSpikUKoAAaNhDiGkKJSxhhTUajK/yAyM6SYGoRciJmRTAaDJdPn7NcPZ5++p0/3zd1nTvp2973PUzXVvXfve+7qXrX6/madd60FR51aoO7ueZLXJHlXkvuSvLW776mq11fVS9cefWWSt3T31cpBzg8z1AAAbDjV1XXd/c4k79y4990b1//oNNvweTXu8qGGGgCAFSclbqMtSgQA4CiBehurGuo9PzYAAJYkw22saqidlAgAwEig3sbhDLWSDwAAlgTqbaxOShSoAQAYCdTbGGeoe3bpjBsCAMB5IVBvY3GQJNlTQw0AwEig3sYwX36cCdQAACwJ1NtYBeo9JR8AACwJ1NsYA3WZoQYAYCQZbqEXB+kuu3wAAHBIoN7CsJhnnln29+qsmwIAwDmh5GMLPcyzyCx7AjUAACOBegu9OMg8e5kJ1AAAjATqLfRY8jErgRoAgCWBegu9WJZ8mKEGAGBFoN7CsuRDoAYA4AqBegs9zDNvixIBALhCoN7GMF8uSlRDDQDASKDeQi8Oxhrqs24JAADnhWi4jcU8B5lltufHBgDAkmS4hdXBLmaoAQBYEQ23MdZQ76mhBgBgJFBvY5hnnn3b5gEAcEig3sYwzyJ72ReoAQAYCdTbWBws96FW8gEAwEig3sawcFIiAABHCNTbGOaZx0mJAABcIVBvoYaDLJyUCADAGoF6G8MiB5lZlAgAwCGBegs1Huyi5AMAgBWBehs9tygRAIAjBOot1DDPop2UCADAFQL1FkoNNQAAGwTqLSx3+VDyAQDAFQL1FqqXB7so+QAAYEWg3kJZlAgAwAaBegurbfNmfmoAAIxEwy0sSz72MtvzYwMAYEkynKo7e2MNtaPHAQBYEain+rnvT5Ic9H5MUAMAsCIaTvWpe5Ikb1/cZVEiAACHBOqphnkeedLt+fXcquQDAIBDAvVUwzxDZkmSfdt8AAAwkgynGhYZahmolXwAALAiUE81zLMYA/WlmUANAMCSQD3VesmHbT4AABhJhlOtzVDvK/kAAGAkUE81LDJklr1K9gRqAABGAvVUwzzz7NnhAwCAI6TDqcYa6ktmpwEAWCNQTzXMs8jMlnkAABwhUE81LDLPLJeUfAAAsEY6nGqYZ5G97NuDGgCANQL1VMM888zsQQ0AwBHS4VRmqAEAOIFAPdWwyLxnDnUBAOAIgXqqcR9qixIBAFgnHU41zDNv2+YBAHCUQD3VMM+BkxIBANggHU41LJYlH2aoAQBYI1BPpeQDAIATCNRTDfMctEWJAAAcJR1ONQZq+1ADALBOoJ6iO+lF5r3npEQAAI6QDqcYFkmynKFWQw0AwBqBeophniRKPgAAOEagnuIwUM8sSgQA4AjpcIoxUD86lG3zAAA4QqCeYqyhfrT3cknJBwAAawTqKdZrqO3yAQDAGulwilXJR+8p+QAA4AiBeorDGmolHwAAHCVQT7G2KHHfLh8AAKyRDqdYX5So5AMAgDUC9RTjDPW8Z5lZlAgAwBrpcIoxUC/ipEQAAI4SqKdYzVBnZlEiAABHCNRTjDXUiyj5AADgKOlwisMZatvmAQBwlEA9xRd9ST5752tyuW91UiIAAEdIh1M85fZ85q7vyq/277EoEQCAIwTqieaLTpLs24caAIA1AvVE82FIEiclAgBwhHQ40XxYzlA7KREAgHUC9USrko+ZQA0AwBqBeqKDxbLk45KSDwAA1kiHE61KPuzyAQDAOoF6IiUfAACcRKCeaLXLh5IPAADWSYcT2YcaAICTCNQTHW6bZ4YaAIA10uFE83GXDzXUAACsE6gnOjicoRaoAQC4QqCeaDVDvb/nRwYAwBXS4USrGmolHwAArBOoJ1rt8mFRIgAA66TDiVb7UDspEQCAdQL1RIcz1GqoAQBYIx1OtJqhnpmhBgBgjUA90YGTEgEAOIFAPdHCSYkAAJxAOpxotQ+1CWoAANYJ1BMdDJ1Ls0qVRA0AwBUC9UTzxeCURAAAjpEQJ5oPbUEiAADHCNQTzRftUBcAAI4RqCeaD0P27fABAMAGCXGi+aJzSckHAAAbBOqJ5kNnT6AGAGCDQD3R0BYlAgBwnEA90WLo7NmDGgCADQL1REMr+QAA4DiBeqLF0JmZoQYAYINAPdHQMUMNAMAxAvVEw9CRpwEA2CRQT7TozkyiBgBgg0A9kV0+AAA4iUA9UXeUfAAAcOyzWOoAAArzSURBVIxAPdFiUPIBAMBxAvVEi1byAQDAcQL1RG1RIgAAJxCoJ7IoEQCAkwjUEy0c7AIAwAkE6omGoTOTpwEA2CBQTzSooQYA4AQC9USLoVNqqAEA2CBQTzR0ZyZQAwCwQaCeyMEuAACcRKCeqO3yAQDACQTqiZYnJZ51KwAAOG8E6okWgxpqAACOE6gnGoZW8gEAwDEC9URDxww1AADHCNQTLbqz56cFAMAGEXGiYejsmaEGAGDDqQbqqnpJVX28qu6vqtde5Zm/UFX3VtU9VfXvTrM9u1g4ehwAgBPsn9YLV9UsyRuS/Okkl5N8qKre0d33rj1zR5LXJbmrux+uqqefVnt2ZYYaAICTnOYM9QuS3N/dD3T3o0nekuRlG8/8tSRv6O6Hk6S7HzzF9uxk6AjUAAAcc5qB+rYkn1i7vjzeW/cVSb6iqn6uqt5fVS856YWq6tuq6sNV9eGHHnrolJr7uS2PHj+TvxoAgHPsNCPiSdO5vXG9n+SOJC9K8sokb6yqW479oe4f7u47u/vOW2+99fPe0CmWu3yYoQYA4KjTDNSXkzxz7foZSX7jhGd+ursPuvtXknw8y4B97nQ7KREAgONOM1B/KMkdVfWsqnpcklckecfGM29P8qeSpKqelmUJyAOn2KbHbGFRIgAAJzi1QN3d8ySvSfKuJPcleWt331NVr6+ql46PvSvJb1bVvUnem+TvdPdvnlabHqvuXi5KVPIBAMCGU9s2L0m6+51J3rlx77vXPu8kf3P879waxspvJR8AAGyyb8UEQy8TtQlqAAA2CdQTLMYpaiUfAABsEqgnWM1QO3ocAIBNAvUEaqgBALgagXqCVcmHPA0AwCaBeoJhUPIBAMDJBOoJFmqoAQC4CoF6givb5gnUAAAcJVBPMAzLjwI1AACbBOoJrpR8nHFDAAA4d0TECVaLEs1QAwCwSaCewMEuAABcjUA9wcIMNQAAVyFQT3C4y4cZagAANgjUEyzGXT4cPQ4AwCaBeoLBLh8AAFyFiDjBqoa6zFADALBBoJ7gcIZaoAYAYINAPcFqhtq2eQAAbBKoJxjztF0+AAA4RqCe4HDbPHkaAIANAvUEs73K07/w8XnCpdlZNwUAgHNm/6wbcBE8/0ufkg9+19eedTMAADiHzFADAMAOBGoAANiBQA0AADsQqAEAYAcCNQAA7ECgBgCAHQjUAACwA4EaAAB2IFADAMAOBGoAANiBQA0AADsQqAEAYAcCNQAA7ECgBgCAHQjUAACwA4EaAAB2IFADAMAOBGoAANiBQA0AADsQqAEAYAcCNQAA7ECgBgCAHQjUAACwA4EaAAB2IFADAMAOBGoAANiBQA0AADsQqAEAYAfV3Wfdhq1U1UNJfvWM/vqnJfnfZ/R3c33o45uDfr456Oebg36+OZxVP39Zd996rYcuXKA+S1X14e6+86zbwenRxzcH/Xxz0M83B/18czjv/azkAwAAdiBQAwDADgTq7fzwWTeAU6ePbw76+eagn28O+vnmcK77WQ01AADswAw1AADsQKAGAIAdCNQTVNVLqurjVXV/Vb32rNvDY1dVz6yq91bVfVV1T1V9x3j/qVX17qr65fHjU8b7VVX/cuz7X6iq55/td8BUVTWrqo9V1c+M18+qqg+MffyTVfW48f7jx+v7x6/ffpbtZrqquqWq7q6qXxrH9B8zlm88VfU3xt/Xv1hVP1FVTzCeL76q+tGqerCqfnHt3tbjt6peNT7/y1X1qrP4XhKB+pqqapbkDUn+bJLnJHllVT3nbFvFDuZJ/lZ3f2WSFyb59rE/X5vkPd19R5L3jNfJst/vGP/7tiQ/eP2bzGP0HUnuW7v+J0m+b+zjh5N863j/W5M83N1fnuT7xue4GL4/yX/s7j+Q5Kuy7G9j+QZSVbcl+etJ7uzuP5RkluQVMZ5vBP86yUs27m01fqvqqUm+J8kfTfKCJN+zCuHXm0B9bS9Icn93P9DdjyZ5S5KXnXGbeIy6+5Pd/dHx8/+T5T/At2XZp28aH3tTkm8YP39Zkh/vpfcnuaWqvuQ6N5stVdUzkvz5JG8cryvJ1yS5e3xks49XfX93khePz3OOVdUXJfmTSX4kSbr70e7+TIzlG9F+ki+oqv0kT0zyyRjPF153/9ckn964ve34/TNJ3t3dn+7uh5O8O8dD+nUhUF/bbUk+sXZ9ebzHBTe+Ffi8JB9I8ru7+5PJMnQnefr4mP6/mP5Fkr+bZBivf1eSz3T3fLxe78fDPh6//sj4POfbs5M8lOTHxtKeN1bVk2Is31C6+9eT/NMkv5ZlkH4kyUdiPN+oth2/52ZcC9TXdtL/2dpr8IKrqicn+Q9JvrO7f+tzPXrCPf1/jlXV1yd5sLs/sn77hEd7wtc4v/aTPD/JD3b385L8dq68PXwS/XwBjW/fvyzJs5L83iRPyvLt/03G843tav16bvpboL62y0meuXb9jCS/cUZt4fOgqi5lGabf3N1vG29/avX27/jxwfG+/r947kry0qr6n1mWaH1NljPWt4xvGSdH+/Gwj8evf3GOvw3J+XM5yeXu/sB4fXeWAdtYvrF8bZJf6e6HuvsgyduSfHWM5xvVtuP33IxrgfraPpTkjnFF8eOyXAzxjjNuE4/RWEv3I0nu6+5/vvaldyRZrQ5+VZKfXrv/l8cVxi9M8sjq7SjOp+5+XXc/o7tvz3K8/pfu/qYk703y8vGxzT5e9f3Lx+fNaJ1z3f2/knyiqn7/eOvFSe6NsXyj+bUkL6yqJ46/v1f9bDzfmLYdv+9K8nVV9ZTx3YyvG+9dd05KnKCq/lyWM1yzJD/a3d97xk3iMaqqP57kvyX5H7lSX/v3s6yjfmuSL83yF/g3dvenx1/gP5DlIof/m+TV3f3h695wHpOqelGSv93dX19Vz85yxvqpST6W5Ju7+3eq6glJ/k2W9fSfTvKK7n7grNrMdFX13CwXnj4uyQNJXp3lRJGxfAOpqn+c5C9muUvTx5L81SzrZI3nC6yqfiLJi5I8Lcmnstyt4+3ZcvxW1V/J8t/xJPne7v6x6/l9rAjUAACwAyUfAACwA4EaAAB2IFADAMAOBGoAANiBQA0AADsQqAFIVb2oqn7mrNsBcBEJ1AAAsAOBGuACqapvrqoPVtXPV9UPVdWsqj5bVf+sqj5aVe+pqlvHZ59bVe+vql+oqp8aTxJLVX15Vf3nqvrv45/5fePLP7mq7q6qX6qqN4+HKQBwDQI1wAVRVV+Z5Ylxd3X3c5MsknxTkicl+Wh3Pz/J+7I8cSxJfjzJ3+vuP5zl6aCr+29O8obu/qokX51kdQT385J8Z5LnJHl2krtO/ZsCuAHsn3UDAJjsxUn+SJIPjZPHX5DkwSRDkp8cn/m3Sd5WVV+c5Jbuft94/01J/n1VfWGS27r7p5Kku/9fkoyv98Huvjxe/3yS25P87Ol/WwAXm0ANcHFUkjd19+uO3Kz6hxvP9TVe42p+Z+3zRfwbATCJkg+Ai+M9SV5eVU9Pkqp6alV9WZa/y18+PvOXkvxsdz+S5OGq+hPj/W9J8r7u/q0kl6vqG8bXeHxVPfG6fhcANxizDwAXRHffW1X/IMl/qqq9JAdJvj3Jbyf5g1X1kSSPZFlnnSSvSvKvxsD8QJJXj/e/JckPVdXrx9f4xuv4bQDccKr7c70zCMB5V1Wf7e4nn3U7AG5WSj4AAGAHZqgBAGAHZqgBAGAHAjUAAOxAoAYAgB0I1AAAsAOBGgAAdvD/ASCTHJaC3CKVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Lets plot the increase of accuracy as we increase the number of training epochs\n",
    "#We can see that without any training the acc is about 50%, random guessing\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To load a model that we have already trained and saved:\n",
    "model.load_weights('Z_chatbot_100_epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets check out the predictions on the test set:\n",
    "#These are just probabilities for every single word on the vocab\n",
    "pred_results = model.predict(([inputs_test,questions_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'got',\n",
       "  'the',\n",
       "  'milk',\n",
       "  'there',\n",
       "  '.',\n",
       "  'John',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Is', 'John', 'in', 'the', 'kitchen', '?'],\n",
       " 'no')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First test data point\n",
    "test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.4758190e-21, 2.1397022e-21, 2.2722944e-21, 1.9776182e-21,\n",
       "       1.7983421e-21, 1.9400778e-21, 1.6792089e-21, 2.0177312e-21,\n",
       "       2.2013671e-21, 2.1278508e-21, 1.8952951e-21, 1.9446645e-21,\n",
       "       2.1805394e-21, 2.1526293e-21, 2.1304580e-21, 2.4526099e-21,\n",
       "       1.9765925e-21, 1.8287746e-21, 2.2381072e-21, 1.0000000e+00,\n",
       "       2.3029066e-21, 2.1592005e-21, 2.5348889e-21, 1.8851353e-21,\n",
       "       1.8703010e-21, 2.3107912e-21, 2.3018439e-21, 2.2044449e-19,\n",
       "       2.0388772e-21, 2.3365857e-21, 2.1607000e-21, 1.9910922e-21,\n",
       "       2.3918412e-21, 2.1491505e-21, 1.7650330e-21, 2.4313060e-21,\n",
       "       2.0611253e-21, 2.2488391e-21], dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#These are the probabilities for the vocab words using the 1st sentence\n",
    "pred_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_max = np.argmax(pred_results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n"
     ]
    }
   ],
   "source": [
    "for key,val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#See probability:\n",
    "pred_results[0][val_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now, we can make our own questions using the vocabulary we have\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story = 'Sandra picked up the milk . Mary travelled left . '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sandra', 'picked', 'up', 'the', 'milk', '.', 'Mary', 'travelled', 'left']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_story.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_question = 'Sandra got the milk ?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sandra', 'got', 'the', 'milk', '?']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_question.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put the data in the same format as before\n",
    "my_data = [(my_story.split(), my_question.split(),'yes')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorize this data\n",
    "my_story, my_ques, my_ans = vectorize_stories(my_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make the prediction\n",
    "pred_results = model.predict(([my_story,my_ques]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_max = np.argmax(pred_results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "#Correct prediction!\n",
    "for key,val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9867547"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confidence\n",
    "pred_results[0][val_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
