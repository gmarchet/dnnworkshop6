{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From: https://machinetalk.org/2019/03/29/neural-machine-translation-with-attention-mechanism/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import re\n",
    "import os\n",
    "print(tf.__version__)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = (\n",
    "    ('What a ridiculous concept!', 'Quel concept ridicule !'),\n",
    "    ('Your idea is not entirely crazy.', \"Votre idée n'est pas complètement folle.\"),\n",
    "    (\"A man's worth lies in what he is.\", \"La valeur d'un homme réside dans ce qu'il est.\"),\n",
    "    ('What he did is very wrong.', \"Ce qu'il a fait est très mal.\"),\n",
    "    (\"All three of you need to do that.\", \"Vous avez besoin de faire cela, tous les trois.\"),\n",
    "    (\"Are you giving me another chance?\", \"Me donnez-vous une autre chance ?\"),\n",
    "    (\"Both Tom and Mary work as models.\", \"Tom et Mary travaillent tous les deux comme mannequins.\"),\n",
    "    (\"Can I have a few minutes, please?\", \"Puis-je avoir quelques minutes, je vous prie ?\"),\n",
    "    (\"Could you close the door, please?\", \"Pourriez-vous fermer la porte, s'il vous plaît ?\"),\n",
    "    (\"Did you plant pumpkins this year?\", \"Cette année, avez-vous planté des citrouilles ?\"),\n",
    "    (\"Do you ever study in the library?\", \"Est-ce que vous étudiez à la bibliothèque des fois ?\"),\n",
    "    (\"Don't be deceived by appearances.\", \"Ne vous laissez pas abuser par les apparences.\"),\n",
    "    (\"Excuse me. Can you speak English?\", \"Je vous prie de m'excuser ! Savez-vous parler anglais ?\"),\n",
    "    (\"Few people know the true meaning.\", \"Peu de gens savent ce que cela veut réellement dire.\"),\n",
    "    (\"Germany produced many scientists.\", \"L'Allemagne a produit beaucoup de scientifiques.\"),\n",
    "    (\"Guess whose birthday it is today.\", \"Devine de qui c'est l'anniversaire, aujourd'hui !\"),\n",
    "    (\"He acted like he owned the place.\", \"Il s'est comporté comme s'il possédait l'endroit.\"),\n",
    "    (\"Honesty will pay in the long run.\", \"L'honnêteté paye à la longue.\"),\n",
    "    (\"How do we know this isn't a trap?\", \"Comment savez-vous qu'il ne s'agit pas d'un piège ?\"),\n",
    "    (\"I can't believe you're giving up.\", \"Je n'arrive pas à croire que vous abandonniez.\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "\n",
    "def normalize_string(s):\n",
    "    s = unicode_to_ascii(s)\n",
    "    s = re.sub(r'([!.?])', r' \\1', s)\n",
    "    s = re.sub(r'[^a-zA-Z.!?]+', r' ', s)\n",
    "    s = re.sub(r'\\s+', r' ', s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_en, raw_data_fr = list(zip(*raw_data))\n",
    "raw_data_en, raw_data_fr = list(raw_data_en), list(raw_data_fr)\n",
    "\n",
    "raw_data_en = [normalize_string(data) for data in raw_data_en]\n",
    "raw_data_fr_in = ['<start> ' + normalize_string(data) for data in raw_data_fr]\n",
    "raw_data_fr_out = [normalize_string(data) + ' <end>' for data in raw_data_fr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What a ridiculous concept !',\n",
       " 'Your idea is not entirely crazy .',\n",
       " 'A man s worth lies in what he is .',\n",
       " 'What he did is very wrong .',\n",
       " 'All three of you need to do that .',\n",
       " 'Are you giving me another chance ?',\n",
       " 'Both Tom and Mary work as models .',\n",
       " 'Can I have a few minutes please ?',\n",
       " 'Could you close the door please ?',\n",
       " 'Did you plant pumpkins this year ?',\n",
       " 'Do you ever study in the library ?',\n",
       " 'Don t be deceived by appearances .',\n",
       " 'Excuse me . Can you speak English ?',\n",
       " 'Few people know the true meaning .',\n",
       " 'Germany produced many scientists .',\n",
       " 'Guess whose birthday it is today .',\n",
       " 'He acted like he owned the place .',\n",
       " 'Honesty will pay in the long run .',\n",
       " 'How do we know this isn t a trap ?',\n",
       " 'I can t believe you re giving up .']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> Quel concept ridicule !',\n",
       " '<start> Votre idee n est pas completement folle .',\n",
       " '<start> La valeur d un homme reside dans ce qu il est .',\n",
       " '<start> Ce qu il a fait est tres mal .',\n",
       " '<start> Vous avez besoin de faire cela tous les trois .',\n",
       " '<start> Me donnez vous une autre chance ?',\n",
       " '<start> Tom et Mary travaillent tous les deux comme mannequins .',\n",
       " '<start> Puis je avoir quelques minutes je vous prie ?',\n",
       " '<start> Pourriez vous fermer la porte s il vous plait ?',\n",
       " '<start> Cette annee avez vous plante des citrouilles ?',\n",
       " '<start> Est ce que vous etudiez a la bibliotheque des fois ?',\n",
       " '<start> Ne vous laissez pas abuser par les apparences .',\n",
       " '<start> Je vous prie de m excuser ! Savez vous parler anglais ?',\n",
       " '<start> Peu de gens savent ce que cela veut reellement dire .',\n",
       " '<start> L Allemagne a produit beaucoup de scientifiques .',\n",
       " '<start> Devine de qui c est l anniversaire aujourd hui !',\n",
       " '<start> Il s est comporte comme s il possedait l endroit .',\n",
       " '<start> L honnetete paye a la longue .',\n",
       " '<start> Comment savez vous qu il ne s agit pas d un piege ?',\n",
       " '<start> Je n arrive pas a croire que vous abandonniez .']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data_fr_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Quel concept ridicule ! <end>',\n",
       " 'Votre idee n est pas completement folle . <end>',\n",
       " 'La valeur d un homme reside dans ce qu il est . <end>',\n",
       " 'Ce qu il a fait est tres mal . <end>',\n",
       " 'Vous avez besoin de faire cela tous les trois . <end>',\n",
       " 'Me donnez vous une autre chance ? <end>',\n",
       " 'Tom et Mary travaillent tous les deux comme mannequins . <end>',\n",
       " 'Puis je avoir quelques minutes je vous prie ? <end>',\n",
       " 'Pourriez vous fermer la porte s il vous plait ? <end>',\n",
       " 'Cette annee avez vous plante des citrouilles ? <end>',\n",
       " 'Est ce que vous etudiez a la bibliotheque des fois ? <end>',\n",
       " 'Ne vous laissez pas abuser par les apparences . <end>',\n",
       " 'Je vous prie de m excuser ! Savez vous parler anglais ? <end>',\n",
       " 'Peu de gens savent ce que cela veut reellement dire . <end>',\n",
       " 'L Allemagne a produit beaucoup de scientifiques . <end>',\n",
       " 'Devine de qui c est l anniversaire aujourd hui ! <end>',\n",
       " 'Il s est comporte comme s il possedait l endroit . <end>',\n",
       " 'L honnetete paye a la longue . <end>',\n",
       " 'Comment savez vous qu il ne s agit pas d un piege ? <end>',\n",
       " 'Je n arrive pas a croire que vous abandonniez . <end>']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data_fr_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tokenizer.fit_on_texts(raw_data_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'.': 1, 'you': 2, '?': 3, 'the': 4, 'a': 5, 'is': 6, 'he': 7, 'what': 8, 'in': 9, 'do': 10, 'can': 11, 't': 12, 'did': 13, 'giving': 14, 'me': 15, 'i': 16, 'few': 17, 'please': 18, 'this': 19, 'know': 20, 'ridiculous': 21, 'concept': 22, '!': 23, 'your': 24, 'idea': 25, 'not': 26, 'entirely': 27, 'crazy': 28, 'man': 29, 's': 30, 'worth': 31, 'lies': 32, 'very': 33, 'wrong': 34, 'all': 35, 'three': 36, 'of': 37, 'need': 38, 'to': 39, 'that': 40, 'are': 41, 'another': 42, 'chance': 43, 'both': 44, 'tom': 45, 'and': 46, 'mary': 47, 'work': 48, 'as': 49, 'models': 50, 'have': 51, 'minutes': 52, 'could': 53, 'close': 54, 'door': 55, 'plant': 56, 'pumpkins': 57, 'year': 58, 'ever': 59, 'study': 60, 'library': 61, 'don': 62, 'be': 63, 'deceived': 64, 'by': 65, 'appearances': 66, 'excuse': 67, 'speak': 68, 'english': 69, 'people': 70, 'true': 71, 'meaning': 72, 'germany': 73, 'produced': 74, 'many': 75, 'scientists': 76, 'guess': 77, 'whose': 78, 'birthday': 79, 'it': 80, 'today': 81, 'acted': 82, 'like': 83, 'owned': 84, 'place': 85, 'honesty': 86, 'will': 87, 'pay': 88, 'long': 89, 'run': 90, 'how': 91, 'we': 92, 'isn': 93, 'trap': 94, 'believe': 95, 're': 96, 'up': 97}\n"
     ]
    }
   ],
   "source": [
    "print(en_tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_en = en_tokenizer.texts_to_sequences(raw_data_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_en = tf.keras.preprocessing.sequence.pad_sequences(data_en,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8  5 21 22 23  0  0  0  0  0]\n",
      " [24 25  6 26 27 28  1  0  0  0]\n",
      " [ 5 29 30 31 32  9  8  7  6  1]]\n"
     ]
    }
   ],
   "source": [
    "print(data_en[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "\n",
    "# ATTENTION: always finish with fit_on_texts before moving on\n",
    "fr_tokenizer.fit_on_texts(raw_data_fr_in)\n",
    "fr_tokenizer.fit_on_texts(raw_data_fr_out)\n",
    "\n",
    "data_fr_in = fr_tokenizer.texts_to_sequences(raw_data_fr_in)\n",
    "data_fr_in = tf.keras.preprocessing.sequence.pad_sequences(data_fr_in,\n",
    "                                                           padding='post')\n",
    "\n",
    "data_fr_out = fr_tokenizer.texts_to_sequences(raw_data_fr_out)\n",
    "data_fr_out = tf.keras.preprocessing.sequence.pad_sequences(data_fr_out,\n",
    "                                                            padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (data_en, data_fr_in, data_fr_out))\n",
    "\n",
    "dataset = dataset.shuffle(20).batch(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, lstm_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.lstm_size = lstm_size\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.lstm = tf.keras.layers.LSTM(\n",
    "            lstm_size, return_sequences=True, return_state=True)\n",
    "\n",
    "    def __call__(self, sequence, states):\n",
    "        embed = self.embedding(sequence)\n",
    "        output, state_h, state_c = self.lstm(embed, initial_state=states)\n",
    "\n",
    "        return output, state_h, state_c\n",
    "\n",
    "    def init_states(self, batch_size):\n",
    "        return (tf.zeros([batch_size, self.lstm_size]),\n",
    "                tf.zeros([batch_size, self.lstm_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, lstm_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.lstm_size = lstm_size\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.lstm = tf.keras.layers.LSTM(\n",
    "            lstm_size, return_sequences=True, return_state=True)\n",
    "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def __call__(self, sequence, state):\n",
    "        embed = self.embedding(sequence)\n",
    "        lstm_out, state_h, state_c = self.lstm(embed, state)\n",
    "        logits = self.dense(lstm_out)\n",
    "\n",
    "        return logits, state_h, state_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source sequences (1, 8)\n",
      "Encoder outputs (1, 8, 64)\n",
      "Encoder state_h (1, 64)\n",
      "Encoder state_c (1, 64)\n",
      "\n",
      "Destination vocab size 110\n",
      "Destination sequences (1, 7)\n",
      "Decoder outputs (1, 7, 110)\n",
      "Decoder state_h (1, 64)\n",
      "Decoder state_c (1, 64)\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_SIZE = 32\n",
    "LSTM_SIZE = 64\n",
    "\n",
    "en_vocab_size = len(en_tokenizer.word_index) + 1\n",
    "encoder = Encoder(en_vocab_size, EMBEDDING_SIZE, LSTM_SIZE)\n",
    "\n",
    "fr_vocab_size = len(fr_tokenizer.word_index) + 1\n",
    "decoder = Decoder(fr_vocab_size, EMBEDDING_SIZE, LSTM_SIZE)\n",
    "\n",
    "source_input = tf.constant([[1, 3, 5, 7, 2, 0, 0, 0]])\n",
    "initial_state = encoder.init_states(1)\n",
    "encoder_output, en_state_h, en_state_c = encoder(source_input, initial_state)\n",
    "\n",
    "target_input = tf.constant([[1, 4, 6, 9, 2, 0, 0]])\n",
    "decoder_output, de_state_h, de_state_c = decoder(target_input, (en_state_h, en_state_c))\n",
    "\n",
    "print('Source sequences', source_input.shape)\n",
    "print('Encoder outputs', encoder_output.shape)\n",
    "print('Encoder state_h', en_state_h.shape)\n",
    "print('Encoder state_c', en_state_c.shape)\n",
    "\n",
    "print('\\nDestination vocab size', fr_vocab_size)\n",
    "print('Destination sequences', target_input.shape)\n",
    "print('Decoder outputs', decoder_output.shape)\n",
    "print('Decoder state_h', de_state_h.shape)\n",
    "print('Decoder state_c', de_state_c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(targets, logits):\n",
    "    crossentropy = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True)\n",
    "    mask = tf.math.logical_not(tf.math.equal(targets, 0))\n",
    "    mask = tf.cast(mask, dtype=tf.int64)\n",
    "    loss = crossentropy(targets, logits, sample_weight=mask)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(source_seq, target_seq_in, target_seq_out, en_initial_states):\n",
    "    with tf.GradientTape() as tape:\n",
    "        en_outputs = encoder(source_seq, en_initial_states)\n",
    "        en_states = en_outputs[1:]\n",
    "        de_states = en_states\n",
    "\n",
    "        de_outputs = decoder(target_seq_in, de_states)\n",
    "        logits = de_outputs[0]\n",
    "        loss = loss_func(target_seq_out, logits)\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "    test_source_text = raw_data_en[np.random.choice(len(raw_data_en))]\n",
    "    print(test_source_text)\n",
    "    test_source_seq = en_tokenizer.texts_to_sequences([test_source_text])\n",
    "    print(test_source_seq)\n",
    "\n",
    "    en_initial_states = encoder.init_states(1)\n",
    "    en_outputs = encoder(tf.constant(test_source_seq), en_initial_states)\n",
    "\n",
    "    de_input = tf.constant([[fr_tokenizer.word_index['<start>']]])\n",
    "    de_state_h, de_state_c = en_outputs[1:]\n",
    "    out_words = []\n",
    "\n",
    "    while True:\n",
    "        de_output, de_state_h, de_state_c = decoder(\n",
    "            de_input, (de_state_h, de_state_c))\n",
    "        de_input = tf.argmax(de_output, -1)\n",
    "        out_words.append(fr_tokenizer.index_word[de_input.numpy()[0][0]])\n",
    "\n",
    "        if out_words[-1] == '<end>' or len(out_words) >= 20:\n",
    "            break\n",
    "\n",
    "    print(' '.join(out_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 3.7591\n",
      "Both Tom and Mary work as models .\n",
      "[[44, 45, 46, 47, 48, 49, 50, 1]]\n",
      "vous . vous vous . vous . vous . vous <end>\n",
      "Epoch 2 Loss 3.5504\n",
      "I can t believe you re giving up .\n",
      "[[16, 11, 12, 95, 2, 96, 14, 97, 1]]\n",
      ". vous vous . vous . <end>\n",
      "Epoch 3 Loss 3.7408\n",
      "Germany produced many scientists .\n",
      "[[73, 74, 75, 76, 1]]\n",
      "vous . . <end>\n",
      "Epoch 4 Loss 3.3280\n",
      "Do you ever study in the library ?\n",
      "[[10, 2, 59, 60, 9, 4, 61, 3]]\n",
      "vous vous . . <end>\n",
      "Epoch 5 Loss 3.5749\n",
      "Can I have a few minutes please ?\n",
      "[[11, 16, 51, 5, 17, 52, 18, 3]]\n",
      "vous . . <end>\n",
      "Epoch 6 Loss 3.3318\n",
      "Both Tom and Mary work as models .\n",
      "[[44, 45, 46, 47, 48, 49, 50, 1]]\n",
      "vous vous . . <end>\n",
      "Epoch 7 Loss 2.9341\n",
      "How do we know this isn t a trap ?\n",
      "[[91, 10, 92, 20, 19, 93, 12, 5, 94, 3]]\n",
      "vous vous . . . <end>\n",
      "Epoch 8 Loss 2.6459\n",
      "Do you ever study in the library ?\n",
      "[[10, 2, 59, 60, 9, 4, 61, 3]]\n",
      "vous . . . . <end>\n",
      "Epoch 9 Loss 2.9917\n",
      "Do you ever study in the library ?\n",
      "[[10, 2, 59, 60, 9, 4, 61, 3]]\n",
      "vous vous <end>\n",
      "Epoch 10 Loss 2.7934\n",
      "What he did is very wrong .\n",
      "[[8, 7, 13, 6, 33, 34, 1]]\n",
      "vous <end>\n",
      "Epoch 11 Loss 3.2089\n",
      "Can I have a few minutes please ?\n",
      "[[11, 16, 51, 5, 17, 52, 18, 3]]\n",
      "vous vous <end>\n",
      "Epoch 12 Loss 2.9983\n",
      "A man s worth lies in what he is .\n",
      "[[5, 29, 30, 31, 32, 9, 8, 7, 6, 1]]\n",
      "vous vous <end>\n",
      "Epoch 13 Loss 3.4711\n",
      "Your idea is not entirely crazy .\n",
      "[[24, 25, 6, 26, 27, 28, 1]]\n",
      "vous vous vous <end>\n",
      "Epoch 14 Loss 3.3166\n",
      "Don t be deceived by appearances .\n",
      "[[62, 12, 63, 64, 65, 66, 1]]\n",
      "vous vous vous vous <end>\n",
      "Epoch 15 Loss 2.7151\n",
      "Are you giving me another chance ?\n",
      "[[41, 2, 14, 15, 42, 43, 3]]\n",
      "vous vous vous vous <end>\n",
      "Epoch 16 Loss 2.9710\n",
      "Your idea is not entirely crazy .\n",
      "[[24, 25, 6, 26, 27, 28, 1]]\n",
      "vous vous vous vous <end>\n",
      "Epoch 17 Loss 3.1228\n",
      "What a ridiculous concept !\n",
      "[[8, 5, 21, 22, 23]]\n",
      "vous vous vous <end>\n",
      "Epoch 18 Loss 3.0621\n",
      "Don t be deceived by appearances .\n",
      "[[62, 12, 63, 64, 65, 66, 1]]\n",
      "vous vous vous vous vous <end>\n",
      "Epoch 19 Loss 2.9480\n",
      "Don t be deceived by appearances .\n",
      "[[62, 12, 63, 64, 65, 66, 1]]\n",
      "vous vous vous vous vous <end>\n",
      "Epoch 20 Loss 2.8541\n",
      "He acted like he owned the place .\n",
      "[[7, 82, 83, 7, 84, 4, 85, 1]]\n",
      "vous vous vous vous vous <end>\n",
      "Epoch 21 Loss 3.0971\n",
      "Did you plant pumpkins this year ?\n",
      "[[13, 2, 56, 57, 19, 58, 3]]\n",
      "vous vous vous vous vous . <end>\n",
      "Epoch 22 Loss 2.9482\n",
      "Guess whose birthday it is today .\n",
      "[[77, 78, 79, 80, 6, 81, 1]]\n",
      "vous vous vous vous . <end>\n",
      "Epoch 23 Loss 2.7836\n",
      "Germany produced many scientists .\n",
      "[[73, 74, 75, 76, 1]]\n",
      "vous vous vous vous . <end>\n",
      "Epoch 24 Loss 2.8181\n",
      "Germany produced many scientists .\n",
      "[[73, 74, 75, 76, 1]]\n",
      "vous vous vous . <end>\n",
      "Epoch 25 Loss 2.8809\n",
      "How do we know this isn t a trap ?\n",
      "[[91, 10, 92, 20, 19, 93, 12, 5, 94, 3]]\n",
      "vous vous vous vous vous vous vous . <end>\n",
      "Epoch 26 Loss 2.6357\n",
      "Don t be deceived by appearances .\n",
      "[[62, 12, 63, 64, 65, 66, 1]]\n",
      "vous vous vous vous . <end>\n",
      "Epoch 27 Loss 3.2406\n",
      "I can t believe you re giving up .\n",
      "[[16, 11, 12, 95, 2, 96, 14, 97, 1]]\n",
      "vous vous vous vous vous vous vous . <end>\n",
      "Epoch 28 Loss 3.0466\n",
      "A man s worth lies in what he is .\n",
      "[[5, 29, 30, 31, 32, 9, 8, 7, 6, 1]]\n",
      "vous vous . <end>\n",
      "Epoch 29 Loss 2.6026\n",
      "All three of you need to do that .\n",
      "[[35, 36, 37, 2, 38, 39, 10, 40, 1]]\n",
      "vous vous vous vous vous vous ? <end>\n",
      "Epoch 30 Loss 2.6202\n",
      "How do we know this isn t a trap ?\n",
      "[[91, 10, 92, 20, 19, 93, 12, 5, 94, 3]]\n",
      "vous vous vous vous vous vous vous vous ? <end>\n",
      "Epoch 31 Loss 2.7454\n",
      "Both Tom and Mary work as models .\n",
      "[[44, 45, 46, 47, 48, 49, 50, 1]]\n",
      "vous vous vous vous vous . <end>\n",
      "Epoch 32 Loss 2.7107\n",
      "Could you close the door please ?\n",
      "[[53, 2, 54, 4, 55, 18, 3]]\n",
      "vous vous vous vous vous . <end>\n",
      "Epoch 33 Loss 2.3946\n",
      "Both Tom and Mary work as models .\n",
      "[[44, 45, 46, 47, 48, 49, 50, 1]]\n",
      "vous vous vous vous a . <end>\n",
      "Epoch 34 Loss 2.7067\n",
      "Honesty will pay in the long run .\n",
      "[[86, 87, 88, 9, 4, 89, 90, 1]]\n",
      "vous vous vous vous . <end>\n",
      "Epoch 35 Loss 2.8795\n",
      "What he did is very wrong .\n",
      "[[8, 7, 13, 6, 33, 34, 1]]\n",
      "vous vous vous vous . <end>\n",
      "Epoch 36 Loss 2.4274\n",
      "Few people know the true meaning .\n",
      "[[17, 70, 20, 4, 71, 72, 1]]\n",
      "vous vous vous vous pas . <end>\n",
      "Epoch 37 Loss 2.1406\n",
      "Honesty will pay in the long run .\n",
      "[[86, 87, 88, 9, 4, 89, 90, 1]]\n",
      "vous vous vous vous . <end>\n",
      "Epoch 38 Loss 2.6279\n",
      "Could you close the door please ?\n",
      "[[53, 2, 54, 4, 55, 18, 3]]\n",
      "vous vous vous a vous . <end>\n",
      "Epoch 39 Loss 2.3914\n",
      "Your idea is not entirely crazy .\n",
      "[[24, 25, 6, 26, 27, 28, 1]]\n",
      "de vous vous vous . <end>\n",
      "Epoch 40 Loss 2.5397\n",
      "I can t believe you re giving up .\n",
      "[[16, 11, 12, 95, 2, 96, 14, 97, 1]]\n",
      "vous vous vous vous a vous vous ? <end>\n",
      "Epoch 41 Loss 2.2066\n",
      "Germany produced many scientists .\n",
      "[[73, 74, 75, 76, 1]]\n",
      "vous vous vous . <end>\n",
      "Epoch 42 Loss 2.6987\n",
      "Both Tom and Mary work as models .\n",
      "[[44, 45, 46, 47, 48, 49, 50, 1]]\n",
      "tom de de vous les les . <end>\n",
      "Epoch 43 Loss 2.2666\n",
      "Don t be deceived by appearances .\n",
      "[[62, 12, 63, 64, 65, 66, 1]]\n",
      "vous vous a a . <end>\n",
      "Epoch 44 Loss 1.9372\n",
      "Can I have a few minutes please ?\n",
      "[[11, 16, 51, 5, 17, 52, 18, 3]]\n",
      "vous vous vous a a . <end>\n",
      "Epoch 45 Loss 2.0582\n",
      "Germany produced many scientists .\n",
      "[[73, 74, 75, 76, 1]]\n",
      "vous vous vous . <end>\n",
      "Epoch 46 Loss 2.3347\n",
      "A man s worth lies in what he is .\n",
      "[[5, 29, 30, 31, 32, 9, 8, 7, 6, 1]]\n",
      "<end>\n",
      "Epoch 47 Loss 2.2232\n",
      "Few people know the true meaning .\n",
      "[[17, 70, 20, 4, 71, 72, 1]]\n",
      "de de de tous les les . <end>\n",
      "Epoch 48 Loss 2.1964\n",
      "He acted like he owned the place .\n",
      "[[7, 82, 83, 7, 84, 4, 85, 1]]\n",
      "vous vous vous a a la . <end>\n",
      "Epoch 49 Loss 2.1469\n",
      "What he did is very wrong .\n",
      "[[8, 7, 13, 6, 33, 34, 1]]\n",
      "vous a a . <end>\n",
      "Epoch 50 Loss 1.9639\n",
      "Honesty will pay in the long run .\n",
      "[[86, 87, 88, 9, 4, 89, 90, 1]]\n",
      "vous a a . <end>\n",
      "Epoch 51 Loss 2.4732\n",
      "Can I have a few minutes please ?\n",
      "[[11, 16, 51, 5, 17, 52, 18, 3]]\n",
      "vous vous vous vous pas des ? <end>\n",
      "Epoch 52 Loss 2.0259\n",
      "What he did is very wrong .\n",
      "[[8, 7, 13, 6, 33, 34, 1]]\n",
      "vous a a . <end>\n",
      "Epoch 53 Loss 1.9219\n",
      "Your idea is not entirely crazy .\n",
      "[[24, 25, 6, 26, 27, 28, 1]]\n",
      "tom mary mary les les . <end>\n",
      "Epoch 54 Loss 2.0353\n",
      "Are you giving me another chance ?\n",
      "[[41, 2, 14, 15, 42, 43, 3]]\n",
      "vous a a . <end>\n",
      "Epoch 55 Loss 2.2342\n",
      "Did you plant pumpkins this year ?\n",
      "[[13, 2, 56, 57, 19, 58, 3]]\n",
      "de de tous les . <end>\n",
      "Epoch 56 Loss 2.0923\n",
      "What he did is very wrong .\n",
      "[[8, 7, 13, 6, 33, 34, 1]]\n",
      "vous a a . <end>\n",
      "Epoch 57 Loss 1.9759\n",
      "Honesty will pay in the long run .\n",
      "[[86, 87, 88, 9, 4, 89, 90, 1]]\n",
      "l a a a . <end>\n",
      "Epoch 58 Loss 1.7760\n",
      "Don t be deceived by appearances .\n",
      "[[62, 12, 63, 64, 65, 66, 1]]\n",
      "vous a a . <end>\n",
      "Epoch 59 Loss 1.7146\n",
      "Your idea is not entirely crazy .\n",
      "[[24, 25, 6, 26, 27, 28, 1]]\n",
      "tom mary mary les les . <end>\n",
      "Epoch 60 Loss 1.6800\n",
      "Did you plant pumpkins this year ?\n",
      "[[13, 2, 56, 57, 19, 58, 3]]\n",
      "de de tous les les . <end>\n",
      "Epoch 61 Loss 1.8619\n",
      "What he did is very wrong .\n",
      "[[8, 7, 13, 6, 33, 34, 1]]\n",
      "vous a a . <end>\n",
      "Epoch 62 Loss 1.9570\n",
      "Few people know the true meaning .\n",
      "[[17, 70, 20, 4, 71, 72, 1]]\n",
      "de de de tous les les les . <end>\n",
      "Epoch 63 Loss 1.9193\n",
      "Guess whose birthday it is today .\n",
      "[[77, 78, 79, 80, 6, 81, 1]]\n",
      "tom mary mary les les les . <end>\n",
      "Epoch 64 Loss 1.7190\n",
      "Germany produced many scientists .\n",
      "[[73, 74, 75, 76, 1]]\n",
      "l est est . <end>\n",
      "Epoch 65 Loss 1.5622\n",
      "Can I have a few minutes please ?\n",
      "[[11, 16, 51, 5, 17, 52, 18, 3]]\n",
      "vous vous de de plante des ? <end>\n",
      "Epoch 66 Loss 1.6450\n",
      "Few people know the true meaning .\n",
      "[[17, 70, 20, 4, 71, 72, 1]]\n",
      "de de de tous les les les . <end>\n",
      "Epoch 67 Loss 1.9877\n",
      "Can I have a few minutes please ?\n",
      "[[11, 16, 51, 5, 17, 52, 18, 3]]\n",
      "je vous vous pas plante des ? <end>\n",
      "Epoch 68 Loss 1.5300\n",
      "Guess whose birthday it is today .\n",
      "[[77, 78, 79, 80, 6, 81, 1]]\n",
      "tom mary travaillent tous les les . <end>\n",
      "Epoch 69 Loss 1.1562\n",
      "Excuse me . Can you speak English ?\n",
      "[[67, 15, 1, 11, 2, 68, 69, 3]]\n",
      "vous vous vous s s s il ? <end>\n",
      "Epoch 70 Loss 1.4817\n",
      "Honesty will pay in the long run .\n",
      "[[86, 87, 88, 9, 4, 89, 90, 1]]\n",
      "l a a . <end>\n",
      "Epoch 71 Loss 1.4783\n",
      "Germany produced many scientists .\n",
      "[[73, 74, 75, 76, 1]]\n",
      "l est est . <end>\n",
      "Epoch 72 Loss 1.7119\n",
      "Excuse me . Can you speak English ?\n",
      "[[67, 15, 1, 11, 2, 68, 69, 3]]\n",
      "vous vous vous s s s il ? <end>\n",
      "Epoch 73 Loss 1.8567\n",
      "Could you close the door please ?\n",
      "[[53, 2, 54, 4, 55, 18, 3]]\n",
      "vous vous a a la la ? <end>\n",
      "Epoch 74 Loss 1.3756\n",
      "Germany produced many scientists .\n",
      "[[73, 74, 75, 76, 1]]\n",
      "l est est . <end>\n",
      "Epoch 75 Loss 1.7225\n",
      "Excuse me . Can you speak English ?\n",
      "[[67, 15, 1, 11, 2, 68, 69, 3]]\n",
      "vous vous vous s s s il il . <end>\n",
      "Epoch 76 Loss 1.2694\n",
      "What a ridiculous concept !\n",
      "[[8, 5, 21, 22, 23]]\n",
      "<end>\n",
      "Epoch 77 Loss 1.4769\n",
      "Both Tom and Mary work as models .\n",
      "[[44, 45, 46, 47, 48, 49, 50, 1]]\n",
      "tom mary travaillent travaillent les deux deux . <end>\n",
      "Epoch 78 Loss 1.2115\n",
      "Could you close the door please ?\n",
      "[[53, 2, 54, 4, 55, 18, 3]]\n",
      "vous vous s a la la ? <end>\n",
      "Epoch 79 Loss 1.4411\n",
      "What a ridiculous concept !\n",
      "[[8, 5, 21, 22, 23]]\n",
      "<end>\n",
      "Epoch 80 Loss 1.2398\n",
      "Don t be deceived by appearances .\n",
      "[[62, 12, 63, 64, 65, 66, 1]]\n",
      "vous a a les . <end>\n",
      "Epoch 81 Loss 1.4506\n",
      "Can I have a few minutes please ?\n",
      "[[11, 16, 51, 5, 17, 52, 18, 3]]\n",
      "je vous vous minutes vous des ? <end>\n",
      "Epoch 82 Loss 1.1342\n",
      "Do you ever study in the library ?\n",
      "[[10, 2, 59, 60, 9, 4, 61, 3]]\n",
      "je vous vous s s il possedait . <end>\n",
      "Epoch 83 Loss 1.1067\n",
      "How do we know this isn t a trap ?\n",
      "[[91, 10, 92, 20, 19, 93, 12, 5, 94, 3]]\n",
      "vous vous vous vous s s agit agit agit un ? <end>\n",
      "Epoch 84 Loss 1.2399\n",
      "He acted like he owned the place .\n",
      "[[7, 82, 83, 7, 84, 4, 85, 1]]\n",
      "vous vous s s s il il . <end>\n",
      "Epoch 85 Loss 1.3317\n",
      "Can I have a few minutes please ?\n",
      "[[11, 16, 51, 5, 17, 52, 18, 3]]\n",
      "je vous de minutes vous des ? <end>\n",
      "Epoch 86 Loss 1.0961\n",
      "A man s worth lies in what he is .\n",
      "[[5, 29, 30, 31, 32, 9, 8, 7, 6, 1]]\n",
      "<end>\n",
      "Epoch 87 Loss 1.2759\n",
      "A man s worth lies in what he is .\n",
      "[[5, 29, 30, 31, 32, 9, 8, 7, 6, 1]]\n",
      "<end>\n",
      "Epoch 88 Loss 0.9203\n",
      "What a ridiculous concept !\n",
      "[[8, 5, 21, 22, 23]]\n",
      "quel <end>\n",
      "Epoch 89 Loss 1.1310\n",
      "All three of you need to do that .\n",
      "[[35, 36, 37, 2, 38, 39, 10, 40, 1]]\n",
      "vous de de faire cela cela les les . <end>\n",
      "Epoch 90 Loss 1.3206\n",
      "Did you plant pumpkins this year ?\n",
      "[[13, 2, 56, 57, 19, 58, 3]]\n",
      "avez vous plante des ? <end>\n",
      "Epoch 91 Loss 1.1976\n",
      "Both Tom and Mary work as models .\n",
      "[[44, 45, 46, 47, 48, 49, 50, 1]]\n",
      "tom mary travaillent travaillent les deux deux . <end>\n",
      "Epoch 92 Loss 1.1783\n",
      "Could you close the door please ?\n",
      "[[53, 2, 54, 4, 55, 18, 3]]\n",
      "vous donnez vous une autre chance ? <end>\n",
      "Epoch 93 Loss 0.8492\n",
      "Both Tom and Mary work as models .\n",
      "[[44, 45, 46, 47, 48, 49, 50, 1]]\n",
      "tom mary travaillent travaillent les deux deux . <end>\n",
      "Epoch 94 Loss 1.0237\n",
      "Could you close the door please ?\n",
      "[[53, 2, 54, 4, 55, 18, 3]]\n",
      "vous fermer s s il il . <end>\n",
      "Epoch 95 Loss 1.0719\n",
      "Can I have a few minutes please ?\n",
      "[[11, 16, 51, 5, 17, 52, 18, 3]]\n",
      "je vous quelques minutes vous prie ? <end>\n",
      "Epoch 96 Loss 1.1029\n",
      "Don t be deceived by appearances .\n",
      "[[62, 12, 63, 64, 65, 66, 1]]\n",
      "vous a pas les . <end>\n",
      "Epoch 97 Loss 1.0625\n",
      "Your idea is not entirely crazy .\n",
      "[[24, 25, 6, 26, 27, 28, 1]]\n",
      "votre idee est pas completement . <end>\n",
      "Epoch 98 Loss 1.1592\n",
      "What a ridiculous concept !\n",
      "[[8, 5, 21, 22, 23]]\n",
      "quel <end>\n",
      "Epoch 99 Loss 1.0296\n",
      "Guess whose birthday it is today .\n",
      "[[77, 78, 79, 80, 6, 81, 1]]\n",
      "tom mary travaillent tous les deux . <end>\n",
      "Epoch 100 Loss 0.8647\n",
      "All three of you need to do that .\n",
      "[[35, 36, 37, 2, 38, 39, 10, 40, 1]]\n",
      "vous de de faire cela cela tous les . <end>\n",
      "Epoch 101 Loss 0.7497\n",
      "A man s worth lies in what he is .\n",
      "[[5, 29, 30, 31, 32, 9, 8, 7, 6, 1]]\n",
      "<end>\n",
      "Epoch 102 Loss 0.6875\n",
      "Don t be deceived by appearances .\n",
      "[[62, 12, 63, 64, 65, 66, 1]]\n",
      "vous a pas les . <end>\n",
      "Epoch 103 Loss 0.8082\n",
      "Can I have a few minutes please ?\n",
      "[[11, 16, 51, 5, 17, 52, 18, 3]]\n",
      "je vous quelques minutes vous prie ? <end>\n",
      "Epoch 104 Loss 0.6914\n",
      "A man s worth lies in what he is .\n",
      "[[5, 29, 30, 31, 32, 9, 8, 7, 6, 1]]\n",
      "<end>\n",
      "Epoch 105 Loss 1.0430\n",
      "What a ridiculous concept !\n",
      "[[8, 5, 21, 22, 23]]\n",
      "quel <end>\n",
      "Epoch 106 Loss 0.9574\n",
      "A man s worth lies in what he is .\n",
      "[[5, 29, 30, 31, 32, 9, 8, 7, 6, 1]]\n",
      "<end>\n",
      "Epoch 107 Loss 0.7889\n",
      "All three of you need to do that .\n",
      "[[35, 36, 37, 2, 38, 39, 10, 40, 1]]\n",
      "vous de de faire cela cela tous les trois . <end>\n",
      "Epoch 108 Loss 0.7835\n",
      "Germany produced many scientists .\n",
      "[[73, 74, 75, 76, 1]]\n",
      "l a ! <end>\n",
      "Epoch 109 Loss 0.6599\n",
      "Few people know the true meaning .\n",
      "[[17, 70, 20, 4, 71, 72, 1]]\n",
      "de de savent tous cela les les . <end>\n",
      "Epoch 110 Loss 0.6330\n",
      "A man s worth lies in what he is .\n",
      "[[5, 29, 30, 31, 32, 9, 8, 7, 6, 1]]\n",
      "<end>\n",
      "Epoch 111 Loss 0.8446\n",
      "What a ridiculous concept !\n",
      "[[8, 5, 21, 22, 23]]\n",
      "quel <end>\n",
      "Epoch 112 Loss 0.8563\n",
      "All three of you need to do that .\n",
      "[[35, 36, 37, 2, 38, 39, 10, 40, 1]]\n",
      "vous avez de faire cela tous les les . <end>\n",
      "Epoch 113 Loss 0.6926\n",
      "Few people know the true meaning .\n",
      "[[17, 70, 20, 4, 71, 72, 1]]\n",
      "de de savent tous cela les trois . <end>\n",
      "Epoch 114 Loss 0.7350\n",
      "Both Tom and Mary work as models .\n",
      "[[44, 45, 46, 47, 48, 49, 50, 1]]\n",
      "tom mary travaillent tous les deux deux . <end>\n",
      "Epoch 115 Loss 0.7760\n",
      "Could you close the door please ?\n",
      "[[53, 2, 54, 4, 55, 18, 3]]\n",
      "pourriez vous la porte vous plait ? <end>\n",
      "Epoch 116 Loss 0.6907\n",
      "Germany produced many scientists .\n",
      "[[73, 74, 75, 76, 1]]\n",
      "l a beaucoup . <end>\n",
      "Epoch 117 Loss 0.5987\n",
      "Germany produced many scientists .\n",
      "[[73, 74, 75, 76, 1]]\n",
      "l a beaucoup . <end>\n",
      "Epoch 118 Loss 0.6432\n",
      "Did you plant pumpkins this year ?\n",
      "[[13, 2, 56, 57, 19, 58, 3]]\n",
      "avez vous plante des citrouilles ? <end>\n",
      "Epoch 119 Loss 0.7773\n",
      "Excuse me . Can you speak English ?\n",
      "[[67, 15, 1, 11, 2, 68, 69, 3]]\n",
      "vous vous etudiez a la bibliotheque des des ? <end>\n",
      "Epoch 120 Loss 0.5796\n",
      "How do we know this isn t a trap ?\n",
      "[[91, 10, 92, 20, 19, 93, 12, 5, 94, 3]]\n",
      "comment vous vous qu il s pas agit agit d un piege ? <end>\n",
      "Epoch 121 Loss 0.7616\n",
      "Both Tom and Mary work as models .\n",
      "[[44, 45, 46, 47, 48, 49, 50, 1]]\n",
      "tom mary travaillent tous les deux deux . <end>\n",
      "Epoch 122 Loss 0.5406\n",
      "He acted like he owned the place .\n",
      "[[7, 82, 83, 7, 84, 4, 85, 1]]\n",
      "vous vous comporte s s il possedait l . <end>\n",
      "Epoch 123 Loss 0.7458\n",
      "I can t believe you re giving up .\n",
      "[[16, 11, 12, 95, 2, 96, 14, 97, 1]]\n",
      "je n arrive a a croire que vous . <end>\n",
      "Epoch 124 Loss 0.5764\n",
      "What he did is very wrong .\n",
      "[[8, 7, 13, 6, 33, 34, 1]]\n",
      "vous a beaucoup . <end>\n",
      "Epoch 125 Loss 0.6894\n",
      "All three of you need to do that .\n",
      "[[35, 36, 37, 2, 38, 39, 10, 40, 1]]\n",
      "vous avez de faire cela tous les trois . <end>\n",
      "Epoch 126 Loss 0.6142\n",
      "Both Tom and Mary work as models .\n",
      "[[44, 45, 46, 47, 48, 49, 50, 1]]\n",
      "tom mary travaillent tous les deux deux . <end>\n",
      "Epoch 127 Loss 0.6773\n",
      "Excuse me . Can you speak English ?\n",
      "[[67, 15, 1, 11, 2, 68, 69, 3]]\n",
      "vous vous etudiez a la bibliotheque des des ? <end>\n",
      "Epoch 128 Loss 0.7106\n",
      "Germany produced many scientists .\n",
      "[[73, 74, 75, 76, 1]]\n",
      "l a beaucoup . <end>\n",
      "Epoch 129 Loss 0.6687\n",
      "Do you ever study in the library ?\n",
      "[[10, 2, 59, 60, 9, 4, 61, 3]]\n",
      "je vous de m excuser ! vous anglais ? <end>\n",
      "Epoch 130 Loss 0.5813\n",
      "What he did is very wrong .\n",
      "[[8, 7, 13, 6, 33, 34, 1]]\n",
      "vous a fait . <end>\n",
      "Epoch 131 Loss 0.6319\n",
      "Excuse me . Can you speak English ?\n",
      "[[67, 15, 1, 11, 2, 68, 69, 3]]\n",
      "vous vous etudiez a etudiez la bibliotheque des fois ? <end>\n",
      "Epoch 132 Loss 0.7013\n",
      "Both Tom and Mary work as models .\n",
      "[[44, 45, 46, 47, 48, 49, 50, 1]]\n",
      "tom et mary travaillent les deux deux mannequins . <end>\n",
      "Epoch 133 Loss 0.6640\n",
      "How do we know this isn t a trap ?\n",
      "[[91, 10, 92, 20, 19, 93, 12, 5, 94, 3]]\n",
      "comment savez vous qu il ne s agit pas d un piege ? <end>\n",
      "Epoch 134 Loss 0.6391\n",
      "Your idea is not entirely crazy .\n",
      "[[24, 25, 6, 26, 27, 28, 1]]\n",
      "votre idee est pas completement . <end>\n",
      "Epoch 135 Loss 0.3809\n",
      "Did you plant pumpkins this year ?\n",
      "[[13, 2, 56, 57, 19, 58, 3]]\n",
      "avez vous plante des citrouilles ? <end>\n",
      "Epoch 136 Loss 0.4322\n",
      "Excuse me . Can you speak English ?\n",
      "[[67, 15, 1, 11, 2, 68, 69, 3]]\n",
      "vous vous etudiez a etudiez la bibliotheque des fois ? <end>\n",
      "Epoch 137 Loss 0.3866\n",
      "Are you giving me another chance ?\n",
      "[[41, 2, 14, 15, 42, 43, 3]]\n",
      "me vous une autre ? <end>\n",
      "Epoch 138 Loss 0.4169\n",
      "Don t be deceived by appearances .\n",
      "[[62, 12, 63, 64, 65, 66, 1]]\n",
      "vous pas abuser les apparences . <end>\n",
      "Epoch 139 Loss 0.5880\n",
      "Don t be deceived by appearances .\n",
      "[[62, 12, 63, 64, 65, 66, 1]]\n",
      "vous pas abuser les apparences . <end>\n",
      "Epoch 140 Loss 0.4797\n",
      "I can t believe you re giving up .\n",
      "[[16, 11, 12, 95, 2, 96, 14, 97, 1]]\n",
      "je n arrive a a croire que vous abandonniez . <end>\n",
      "Epoch 141 Loss 0.4084\n",
      "Do you ever study in the library ?\n",
      "[[10, 2, 59, 60, 9, 4, 61, 3]]\n",
      "je vous de m excuser plante des ? <end>\n",
      "Epoch 142 Loss 0.5203\n",
      "Both Tom and Mary work as models .\n",
      "[[44, 45, 46, 47, 48, 49, 50, 1]]\n",
      "tom et travaillent tous les deux comme mannequins . <end>\n",
      "Epoch 143 Loss 0.5217\n",
      "What a ridiculous concept !\n",
      "[[8, 5, 21, 22, 23]]\n",
      "<end>\n",
      "Epoch 144 Loss 0.5495\n",
      "What a ridiculous concept !\n",
      "[[8, 5, 21, 22, 23]]\n",
      "<end>\n",
      "Epoch 145 Loss 0.4348\n",
      "I can t believe you re giving up .\n",
      "[[16, 11, 12, 95, 2, 96, 14, 97, 1]]\n",
      "je n arrive pas a croire que vous abandonniez . <end>\n",
      "Epoch 146 Loss 0.3456\n",
      "Excuse me . Can you speak English ?\n",
      "[[67, 15, 1, 11, 2, 68, 69, 3]]\n",
      "vous vous etudiez a etudiez a bibliotheque des fois ? <end>\n",
      "Epoch 147 Loss 0.4758\n",
      "Could you close the door please ?\n",
      "[[53, 2, 54, 4, 55, 18, 3]]\n",
      "pourriez vous la porte vous plait ? <end>\n",
      "Epoch 148 Loss 0.5281\n",
      "A man s worth lies in what he is .\n",
      "[[5, 29, 30, 31, 32, 9, 8, 7, 6, 1]]\n",
      "la valeur d un homme reside dans ce qu il est . <end>\n",
      "Epoch 149 Loss 0.4440\n",
      "Both Tom and Mary work as models .\n",
      "[[44, 45, 46, 47, 48, 49, 50, 1]]\n",
      "tom et travaillent tous les deux comme mannequins . <end>\n",
      "Epoch 150 Loss 0.4145\n",
      "Are you giving me another chance ?\n",
      "[[41, 2, 14, 15, 42, 43, 3]]\n",
      "me vous une autre ? <end>\n",
      "Epoch 151 Loss 0.3626\n",
      "Can I have a few minutes please ?\n",
      "[[11, 16, 51, 5, 17, 52, 18, 3]]\n",
      "je avoir quelques minutes je vous prie ? <end>\n",
      "Epoch 152 Loss 0.3695\n",
      "Could you close the door please ?\n",
      "[[53, 2, 54, 4, 55, 18, 3]]\n",
      "pourriez vous la porte vous plait ? <end>\n",
      "Epoch 153 Loss 0.2952\n",
      "All three of you need to do that .\n",
      "[[35, 36, 37, 2, 38, 39, 10, 40, 1]]\n",
      "vous avez besoin de faire cela tous les trois . <end>\n",
      "Epoch 154 Loss 0.4412\n",
      "What a ridiculous concept !\n",
      "[[8, 5, 21, 22, 23]]\n",
      "<end>\n",
      "Epoch 155 Loss 0.3693\n",
      "How do we know this isn t a trap ?\n",
      "[[91, 10, 92, 20, 19, 93, 12, 5, 94, 3]]\n",
      "comment savez vous qu il ne s agit pas d un piege ? <end>\n",
      "Epoch 156 Loss 0.3185\n",
      "Did you plant pumpkins this year ?\n",
      "[[13, 2, 56, 57, 19, 58, 3]]\n",
      "cette avez vous plante des ? <end>\n",
      "Epoch 157 Loss 0.4208\n",
      "Don t be deceived by appearances .\n",
      "[[62, 12, 63, 64, 65, 66, 1]]\n",
      "vous laissez pas par les . <end>\n",
      "Epoch 158 Loss 0.3847\n",
      "Germany produced many scientists .\n",
      "[[73, 74, 75, 76, 1]]\n",
      "l produit de scientifiques . <end>\n",
      "Epoch 159 Loss 0.3988\n",
      "Could you close the door please ?\n",
      "[[53, 2, 54, 4, 55, 18, 3]]\n",
      "pourriez vous fermer la porte vous plait ? <end>\n",
      "Epoch 160 Loss 0.2922\n",
      "I can t believe you re giving up .\n",
      "[[16, 11, 12, 95, 2, 96, 14, 97, 1]]\n",
      "je n arrive pas a croire que vous abandonniez . <end>\n",
      "Epoch 161 Loss 0.4246\n",
      "He acted like he owned the place .\n",
      "[[7, 82, 83, 7, 84, 4, 85, 1]]\n",
      "il est comporte comme s il possedait l endroit . <end>\n",
      "Epoch 162 Loss 0.3591\n",
      "He acted like he owned the place .\n",
      "[[7, 82, 83, 7, 84, 4, 85, 1]]\n",
      "il est comporte comme s il possedait l endroit . <end>\n",
      "Epoch 163 Loss 0.3423\n",
      "I can t believe you re giving up .\n",
      "[[16, 11, 12, 95, 2, 96, 14, 97, 1]]\n",
      "je n arrive pas a croire que vous abandonniez . <end>\n",
      "Epoch 164 Loss 0.2882\n",
      "Don t be deceived by appearances .\n",
      "[[62, 12, 63, 64, 65, 66, 1]]\n",
      "vous laissez pas par les . <end>\n",
      "Epoch 165 Loss 0.3484\n",
      "Both Tom and Mary work as models .\n",
      "[[44, 45, 46, 47, 48, 49, 50, 1]]\n",
      "tom et travaillent tous les deux comme mannequins . <end>\n",
      "Epoch 166 Loss 0.3440\n",
      "Your idea is not entirely crazy .\n",
      "[[24, 25, 6, 26, 27, 28, 1]]\n",
      "votre idee est pas completement folle . <end>\n",
      "Epoch 167 Loss 0.2734\n",
      "A man s worth lies in what he is .\n",
      "[[5, 29, 30, 31, 32, 9, 8, 7, 6, 1]]\n",
      "la valeur d un homme reside dans ce qu il est . <end>\n",
      "Epoch 168 Loss 0.3092\n",
      "He acted like he owned the place .\n",
      "[[7, 82, 83, 7, 84, 4, 85, 1]]\n",
      "il s est comme s il possedait l endroit . <end>\n",
      "Epoch 169 Loss 0.2184\n",
      "All three of you need to do that .\n",
      "[[35, 36, 37, 2, 38, 39, 10, 40, 1]]\n",
      "vous avez besoin de faire cela tous les trois . <end>\n",
      "Epoch 170 Loss 0.4120\n",
      "He acted like he owned the place .\n",
      "[[7, 82, 83, 7, 84, 4, 85, 1]]\n",
      "il s est comme s il possedait l endroit . <end>\n",
      "Epoch 171 Loss 0.3374\n",
      "He acted like he owned the place .\n",
      "[[7, 82, 83, 7, 84, 4, 85, 1]]\n",
      "il s est comme s il possedait l endroit . <end>\n",
      "Epoch 172 Loss 0.2300\n",
      "He acted like he owned the place .\n",
      "[[7, 82, 83, 7, 84, 4, 85, 1]]\n",
      "il s est comme s il possedait l endroit . <end>\n",
      "Epoch 173 Loss 0.3111\n",
      "Your idea is not entirely crazy .\n",
      "[[24, 25, 6, 26, 27, 28, 1]]\n",
      "votre idee est pas completement folle . <end>\n",
      "Epoch 174 Loss 0.2561\n",
      "Your idea is not entirely crazy .\n",
      "[[24, 25, 6, 26, 27, 28, 1]]\n",
      "votre idee est pas completement folle . <end>\n",
      "Epoch 175 Loss 0.3476\n",
      "All three of you need to do that .\n",
      "[[35, 36, 37, 2, 38, 39, 10, 40, 1]]\n",
      "vous avez besoin de faire cela tous les trois . <end>\n",
      "Epoch 176 Loss 0.3031\n",
      "What a ridiculous concept !\n",
      "[[8, 5, 21, 22, 23]]\n",
      "<end>\n",
      "Epoch 177 Loss 0.2536\n",
      "What a ridiculous concept !\n",
      "[[8, 5, 21, 22, 23]]\n",
      "<end>\n",
      "Epoch 178 Loss 0.2323\n",
      "How do we know this isn t a trap ?\n",
      "[[91, 10, 92, 20, 19, 93, 12, 5, 94, 3]]\n",
      "comment savez vous qu il ne s agit pas d un piege ? <end>\n",
      "Epoch 179 Loss 0.2185\n",
      "Your idea is not entirely crazy .\n",
      "[[24, 25, 6, 26, 27, 28, 1]]\n",
      "votre idee est pas completement folle . <end>\n",
      "Epoch 180 Loss 0.2180\n",
      "Don t be deceived by appearances .\n",
      "[[62, 12, 63, 64, 65, 66, 1]]\n",
      "ne vous pas par les apparences . <end>\n",
      "Epoch 181 Loss 0.2832\n",
      "Are you giving me another chance ?\n",
      "[[41, 2, 14, 15, 42, 43, 3]]\n",
      "me vous une autre chance ? <end>\n",
      "Epoch 182 Loss 0.2520\n",
      "What he did is very wrong .\n",
      "[[8, 7, 13, 6, 33, 34, 1]]\n",
      "ce a fait est mal . <end>\n",
      "Epoch 183 Loss 0.2802\n",
      "Do you ever study in the library ?\n",
      "[[10, 2, 59, 60, 9, 4, 61, 3]]\n",
      "est ce que vous etudiez a la des fois ? <end>\n",
      "Epoch 184 Loss 0.2927\n",
      "He acted like he owned the place .\n",
      "[[7, 82, 83, 7, 84, 4, 85, 1]]\n",
      "il est comporte comme s il possedait l endroit . <end>\n",
      "Epoch 185 Loss 0.2226\n",
      "Are you giving me another chance ?\n",
      "[[41, 2, 14, 15, 42, 43, 3]]\n",
      "me vous une autre chance ? <end>\n",
      "Epoch 186 Loss 0.2285\n",
      "All three of you need to do that .\n",
      "[[35, 36, 37, 2, 38, 39, 10, 40, 1]]\n",
      "vous avez besoin de faire cela tous les trois . <end>\n",
      "Epoch 187 Loss 0.2329\n",
      "I can t believe you re giving up .\n",
      "[[16, 11, 12, 95, 2, 96, 14, 97, 1]]\n",
      "je n arrive pas a croire que vous abandonniez . <end>\n",
      "Epoch 188 Loss 0.1646\n",
      "Your idea is not entirely crazy .\n",
      "[[24, 25, 6, 26, 27, 28, 1]]\n",
      "votre idee est pas completement folle . <end>\n",
      "Epoch 189 Loss 0.2433\n",
      "Are you giving me another chance ?\n",
      "[[41, 2, 14, 15, 42, 43, 3]]\n",
      "me vous une autre chance ? <end>\n",
      "Epoch 190 Loss 0.2550\n",
      "Do you ever study in the library ?\n",
      "[[10, 2, 59, 60, 9, 4, 61, 3]]\n",
      "est ce que vous etudiez a la des fois ? <end>\n",
      "Epoch 191 Loss 0.2209\n",
      "Guess whose birthday it is today .\n",
      "[[77, 78, 79, 80, 6, 81, 1]]\n",
      "de qui c est l anniversaire aujourd hui ! <end>\n",
      "Epoch 192 Loss 0.1757\n",
      "Guess whose birthday it is today .\n",
      "[[77, 78, 79, 80, 6, 81, 1]]\n",
      "devine de c est anniversaire aujourd hui ! <end>\n",
      "Epoch 193 Loss 0.2593\n",
      "What a ridiculous concept !\n",
      "[[8, 5, 21, 22, 23]]\n",
      "la valeur d un homme dans ce qu il est . <end>\n",
      "Epoch 194 Loss 0.1200\n",
      "Could you close the door please ?\n",
      "[[53, 2, 54, 4, 55, 18, 3]]\n",
      "pourriez vous fermer la porte vous plait ? <end>\n",
      "Epoch 195 Loss 0.1914\n",
      "Are you giving me another chance ?\n",
      "[[41, 2, 14, 15, 42, 43, 3]]\n",
      "me vous une autre chance ? <end>\n",
      "Epoch 196 Loss 0.2907\n",
      "Guess whose birthday it is today .\n",
      "[[77, 78, 79, 80, 6, 81, 1]]\n",
      "de qui c est l anniversaire aujourd hui ! <end>\n",
      "Epoch 197 Loss 0.2110\n",
      "A man s worth lies in what he is .\n",
      "[[5, 29, 30, 31, 32, 9, 8, 7, 6, 1]]\n",
      "la valeur d un homme reside dans ce qu il est . <end>\n",
      "Epoch 198 Loss 0.1164\n",
      "I can t believe you re giving up .\n",
      "[[16, 11, 12, 95, 2, 96, 14, 97, 1]]\n",
      "je n arrive pas a croire que vous abandonniez . <end>\n",
      "Epoch 199 Loss 0.1724\n",
      "What he did is very wrong .\n",
      "[[8, 7, 13, 6, 33, 34, 1]]\n",
      "ce a fait est mal . <end>\n",
      "Epoch 200 Loss 0.1353\n",
      "How do we know this isn t a trap ?\n",
      "[[91, 10, 92, 20, 19, 93, 12, 5, 94, 3]]\n",
      "comment savez vous qu il ne s agit pas d un piege ? <end>\n",
      "Epoch 201 Loss 0.2122\n",
      "A man s worth lies in what he is .\n",
      "[[5, 29, 30, 31, 32, 9, 8, 7, 6, 1]]\n",
      "la valeur d un homme reside dans ce qu il est . <end>\n",
      "Epoch 202 Loss 0.2006\n",
      "How do we know this isn t a trap ?\n",
      "[[91, 10, 92, 20, 19, 93, 12, 5, 94, 3]]\n",
      "comment savez vous qu il ne s agit pas d un piege ? <end>\n",
      "Epoch 203 Loss 0.1554\n",
      "I can t believe you re giving up .\n",
      "[[16, 11, 12, 95, 2, 96, 14, 97, 1]]\n",
      "je n arrive pas a croire que vous abandonniez . <end>\n",
      "Epoch 204 Loss 0.1858\n",
      "Both Tom and Mary work as models .\n",
      "[[44, 45, 46, 47, 48, 49, 50, 1]]\n",
      "tom et mary travaillent tous les deux comme mannequins . <end>\n",
      "Epoch 205 Loss 0.2019\n",
      "I can t believe you re giving up .\n",
      "[[16, 11, 12, 95, 2, 96, 14, 97, 1]]\n",
      "je n arrive pas a croire que vous abandonniez . <end>\n",
      "Epoch 206 Loss 0.1592\n",
      "Could you close the door please ?\n",
      "[[53, 2, 54, 4, 55, 18, 3]]\n",
      "pourriez vous fermer la porte vous plait ? <end>\n",
      "Epoch 207 Loss 0.1083\n",
      "What a ridiculous concept !\n",
      "[[8, 5, 21, 22, 23]]\n",
      "la valeur d un homme dans ce qu il est . <end>\n",
      "Epoch 208 Loss 0.2103\n",
      "Can I have a few minutes please ?\n",
      "[[11, 16, 51, 5, 17, 52, 18, 3]]\n",
      "puis je avoir quelques minutes je vous ? <end>\n",
      "Epoch 209 Loss 0.1937\n",
      "Both Tom and Mary work as models .\n",
      "[[44, 45, 46, 47, 48, 49, 50, 1]]\n",
      "tom et mary travaillent tous les deux comme mannequins . <end>\n",
      "Epoch 210 Loss 0.1898\n",
      "Honesty will pay in the long run .\n",
      "[[86, 87, 88, 9, 4, 89, 90, 1]]\n",
      "l paye a la longue . <end>\n",
      "Epoch 211 Loss 0.1691\n",
      "Can I have a few minutes please ?\n",
      "[[11, 16, 51, 5, 17, 52, 18, 3]]\n",
      "je avoir quelques minutes je vous prie ? <end>\n",
      "Epoch 212 Loss 0.1434\n",
      "What a ridiculous concept !\n",
      "[[8, 5, 21, 22, 23]]\n",
      "la valeur d un homme dans ce qu il est . <end>\n",
      "Epoch 213 Loss 0.2107\n",
      "Do you ever study in the library ?\n",
      "[[10, 2, 59, 60, 9, 4, 61, 3]]\n",
      "est ce que vous etudiez a la bibliotheque des fois ? <end>\n",
      "Epoch 214 Loss 0.1303\n",
      "Honesty will pay in the long run .\n",
      "[[86, 87, 88, 9, 4, 89, 90, 1]]\n",
      "l paye a la longue . <end>\n",
      "Epoch 215 Loss 0.1705\n",
      "Did you plant pumpkins this year ?\n",
      "[[13, 2, 56, 57, 19, 58, 3]]\n",
      "cette avez vous plante des citrouilles ? <end>\n",
      "Epoch 216 Loss 0.1583\n",
      "A man s worth lies in what he is .\n",
      "[[5, 29, 30, 31, 32, 9, 8, 7, 6, 1]]\n",
      "la valeur d un homme reside dans ce qu il est . <end>\n",
      "Epoch 217 Loss 0.1522\n",
      "Both Tom and Mary work as models .\n",
      "[[44, 45, 46, 47, 48, 49, 50, 1]]\n",
      "tom et mary travaillent tous les deux comme mannequins . <end>\n",
      "Epoch 218 Loss 0.1492\n",
      "Guess whose birthday it is today .\n",
      "[[77, 78, 79, 80, 6, 81, 1]]\n",
      "devine de c est anniversaire aujourd hui ! <end>\n",
      "Epoch 219 Loss 0.1349\n",
      "Guess whose birthday it is today .\n",
      "[[77, 78, 79, 80, 6, 81, 1]]\n",
      "devine de c est anniversaire aujourd hui ! <end>\n",
      "Epoch 220 Loss 0.1418\n",
      "I can t believe you re giving up .\n",
      "[[16, 11, 12, 95, 2, 96, 14, 97, 1]]\n",
      "je n arrive pas a croire que vous abandonniez . <end>\n",
      "Epoch 221 Loss 0.1401\n",
      "He acted like he owned the place .\n",
      "[[7, 82, 83, 7, 84, 4, 85, 1]]\n",
      "il s est comporte comme s il possedait l . <end>\n",
      "Epoch 222 Loss 0.1345\n",
      "Your idea is not entirely crazy .\n",
      "[[24, 25, 6, 26, 27, 28, 1]]\n",
      "votre idee n est pas folle . <end>\n",
      "Epoch 223 Loss 0.1388\n",
      "What a ridiculous concept !\n",
      "[[8, 5, 21, 22, 23]]\n",
      "la valeur d un homme dans ce qu il est . <end>\n",
      "Epoch 224 Loss 0.1255\n",
      "Guess whose birthday it is today .\n",
      "[[77, 78, 79, 80, 6, 81, 1]]\n",
      "devine de c est anniversaire aujourd hui ! <end>\n",
      "Epoch 225 Loss 0.1500\n",
      "Don t be deceived by appearances .\n",
      "[[62, 12, 63, 64, 65, 66, 1]]\n",
      "ne vous abuser par les apparences . <end>\n",
      "Epoch 226 Loss 0.0810\n",
      "All three of you need to do that .\n",
      "[[35, 36, 37, 2, 38, 39, 10, 40, 1]]\n",
      "vous avez besoin de faire cela tous les trois . <end>\n",
      "Epoch 227 Loss 0.1284\n",
      "All three of you need to do that .\n",
      "[[35, 36, 37, 2, 38, 39, 10, 40, 1]]\n",
      "vous avez besoin de faire cela tous les trois . <end>\n",
      "Epoch 228 Loss 0.1576\n",
      "Could you close the door please ?\n",
      "[[53, 2, 54, 4, 55, 18, 3]]\n",
      "pourriez vous fermer la porte vous plait ? <end>\n",
      "Epoch 229 Loss 0.1562\n",
      "Could you close the door please ?\n",
      "[[53, 2, 54, 4, 55, 18, 3]]\n",
      "pourriez vous fermer la porte vous plait ? <end>\n",
      "Epoch 230 Loss 0.1421\n",
      "A man s worth lies in what he is .\n",
      "[[5, 29, 30, 31, 32, 9, 8, 7, 6, 1]]\n",
      "la valeur d un homme reside dans ce qu il est . <end>\n",
      "Epoch 231 Loss 0.1429\n",
      "How do we know this isn t a trap ?\n",
      "[[91, 10, 92, 20, 19, 93, 12, 5, 94, 3]]\n",
      "comment savez vous qu il ne s agit pas d un piege ? <end>\n",
      "Epoch 232 Loss 0.1186\n",
      "Guess whose birthday it is today .\n",
      "[[77, 78, 79, 80, 6, 81, 1]]\n",
      "devine de c est l anniversaire aujourd hui ! <end>\n",
      "Epoch 233 Loss 0.0985\n",
      "Guess whose birthday it is today .\n",
      "[[77, 78, 79, 80, 6, 81, 1]]\n",
      "devine de c est l anniversaire aujourd hui ! <end>\n",
      "Epoch 234 Loss 0.0913\n",
      "A man s worth lies in what he is .\n",
      "[[5, 29, 30, 31, 32, 9, 8, 7, 6, 1]]\n",
      "la valeur d un homme reside dans ce qu il est . <end>\n",
      "Epoch 235 Loss 0.0990\n",
      "I can t believe you re giving up .\n",
      "[[16, 11, 12, 95, 2, 96, 14, 97, 1]]\n",
      "je n arrive pas a croire que vous abandonniez . <end>\n",
      "Epoch 236 Loss 0.1187\n",
      "What a ridiculous concept !\n",
      "[[8, 5, 21, 22, 23]]\n",
      "la valeur d un homme dans ce qu il est . <end>\n",
      "Epoch 237 Loss 0.0879\n",
      "I can t believe you re giving up .\n",
      "[[16, 11, 12, 95, 2, 96, 14, 97, 1]]\n",
      "je n arrive pas a croire que vous abandonniez . <end>\n",
      "Epoch 238 Loss 0.1046\n",
      "Do you ever study in the library ?\n",
      "[[10, 2, 59, 60, 9, 4, 61, 3]]\n",
      "est ce que vous etudiez a la bibliotheque des fois ? <end>\n",
      "Epoch 239 Loss 0.1258\n",
      "He acted like he owned the place .\n",
      "[[7, 82, 83, 7, 84, 4, 85, 1]]\n",
      "il s est comporte comme s il possedait l . <end>\n",
      "Epoch 240 Loss 0.1125\n",
      "Can I have a few minutes please ?\n",
      "[[11, 16, 51, 5, 17, 52, 18, 3]]\n",
      "puis je avoir quelques minutes je vous ? <end>\n",
      "Epoch 241 Loss 0.1230\n",
      "What he did is very wrong .\n",
      "[[8, 7, 13, 6, 33, 34, 1]]\n",
      "ce a fait est tres mal . <end>\n",
      "Epoch 242 Loss 0.1104\n",
      "Are you giving me another chance ?\n",
      "[[41, 2, 14, 15, 42, 43, 3]]\n",
      "me donnez vous une autre ? <end>\n",
      "Epoch 243 Loss 0.0941\n",
      "Can I have a few minutes please ?\n",
      "[[11, 16, 51, 5, 17, 52, 18, 3]]\n",
      "puis je avoir quelques minutes je vous prie ? <end>\n",
      "Epoch 244 Loss 0.0943\n",
      "I can t believe you re giving up .\n",
      "[[16, 11, 12, 95, 2, 96, 14, 97, 1]]\n",
      "je n arrive pas a croire que vous abandonniez . <end>\n",
      "Epoch 245 Loss 0.0988\n",
      "A man s worth lies in what he is .\n",
      "[[5, 29, 30, 31, 32, 9, 8, 7, 6, 1]]\n",
      "la valeur d un homme reside dans ce qu il est . <end>\n",
      "Epoch 246 Loss 0.0991\n",
      "Guess whose birthday it is today .\n",
      "[[77, 78, 79, 80, 6, 81, 1]]\n",
      "devine de c est l anniversaire aujourd hui ! <end>\n",
      "Epoch 247 Loss 0.1000\n",
      "A man s worth lies in what he is .\n",
      "[[5, 29, 30, 31, 32, 9, 8, 7, 6, 1]]\n",
      "la valeur d un homme reside dans ce qu il est . <end>\n",
      "Epoch 248 Loss 0.1314\n",
      "Honesty will pay in the long run .\n",
      "[[86, 87, 88, 9, 4, 89, 90, 1]]\n",
      "l paye a la longue . <end>\n",
      "Epoch 249 Loss 0.1121\n",
      "Few people know the true meaning .\n",
      "[[17, 70, 20, 4, 71, 72, 1]]\n",
      "peu de gens savent ce que veut reellement dire . <end>\n",
      "Epoch 250 Loss 0.1107\n",
      "Honesty will pay in the long run .\n",
      "[[86, 87, 88, 9, 4, 89, 90, 1]]\n",
      "l paye a la longue . <end>\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 250\n",
    "BATCH_SIZE = 5\n",
    "\n",
    "for e in range(NUM_EPOCHS):\n",
    "    en_initial_states = encoder.init_states(BATCH_SIZE)\n",
    "\n",
    "    for batch, (source_seq, target_seq_in, target_seq_out) in enumerate(dataset.take(-1)):\n",
    "        loss = train_step(source_seq, target_seq_in,\n",
    "                          target_seq_out, en_initial_states)\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(e + 1, loss.numpy()))\n",
    "    \n",
    "    try:\n",
    "        predict()\n",
    "    except Exception:\n",
    "      continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
